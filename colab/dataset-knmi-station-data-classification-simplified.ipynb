{"cells":[{"cell_type":"markdown","source":["# SETUP"],"metadata":{"id":"-qBgUvBkLY2D"},"id":"-qBgUvBkLY2D"},{"cell_type":"code","source":["!cat /proc/cpuinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_UVd5KpkRzI","executionInfo":{"status":"ok","timestamp":1749504041619,"user_tz":-120,"elapsed":168,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"09908d11-5838-4ddb-8b17-3e45521795b5"},"id":"a_UVd5KpkRzI","execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["processor\t: 0\n","vendor_id\t: AuthenticAMD\n","cpu family\t: 23\n","model\t\t: 49\n","model name\t: AMD EPYC 7B12\n","stepping\t: 0\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2249.998\n","cache size\t: 512 KB\n","physical id\t: 0\n","siblings\t: 8\n","core id\t\t: 0\n","cpu cores\t: 4\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n","bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb srso ibpb_no_ret\n","bogomips\t: 4499.99\n","TLB size\t: 3072 4K pages\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 48 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: AuthenticAMD\n","cpu family\t: 23\n","model\t\t: 49\n","model name\t: AMD EPYC 7B12\n","stepping\t: 0\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2249.998\n","cache size\t: 512 KB\n","physical id\t: 0\n","siblings\t: 8\n","core id\t\t: 1\n","cpu cores\t: 4\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n","bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb srso ibpb_no_ret\n","bogomips\t: 4499.99\n","TLB size\t: 3072 4K pages\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 48 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: AuthenticAMD\n","cpu family\t: 23\n","model\t\t: 49\n","model name\t: AMD EPYC 7B12\n","stepping\t: 0\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2249.998\n","cache size\t: 512 KB\n","physical id\t: 0\n","siblings\t: 8\n","core id\t\t: 2\n","cpu cores\t: 4\n","apicid\t\t: 4\n","initial apicid\t: 4\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n","bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb srso ibpb_no_ret\n","bogomips\t: 4499.99\n","TLB size\t: 3072 4K pages\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 48 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: AuthenticAMD\n","cpu family\t: 23\n","model\t\t: 49\n","model name\t: AMD EPYC 7B12\n","stepping\t: 0\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2249.998\n","cache size\t: 512 KB\n","physical id\t: 0\n","siblings\t: 8\n","core id\t\t: 3\n","cpu cores\t: 4\n","apicid\t\t: 6\n","initial apicid\t: 6\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n","bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb srso ibpb_no_ret\n","bogomips\t: 4499.99\n","TLB size\t: 3072 4K pages\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 48 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 4\n","vendor_id\t: AuthenticAMD\n","cpu family\t: 23\n","model\t\t: 49\n","model name\t: AMD EPYC 7B12\n","stepping\t: 0\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2249.998\n","cache size\t: 512 KB\n","physical id\t: 0\n","siblings\t: 8\n","core id\t\t: 0\n","cpu cores\t: 4\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n","bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb srso ibpb_no_ret\n","bogomips\t: 4499.99\n","TLB size\t: 3072 4K pages\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 48 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 5\n","vendor_id\t: AuthenticAMD\n","cpu family\t: 23\n","model\t\t: 49\n","model name\t: AMD EPYC 7B12\n","stepping\t: 0\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2249.998\n","cache size\t: 512 KB\n","physical id\t: 0\n","siblings\t: 8\n","core id\t\t: 1\n","cpu cores\t: 4\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n","bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb srso ibpb_no_ret\n","bogomips\t: 4499.99\n","TLB size\t: 3072 4K pages\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 48 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 6\n","vendor_id\t: AuthenticAMD\n","cpu family\t: 23\n","model\t\t: 49\n","model name\t: AMD EPYC 7B12\n","stepping\t: 0\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2249.998\n","cache size\t: 512 KB\n","physical id\t: 0\n","siblings\t: 8\n","core id\t\t: 2\n","cpu cores\t: 4\n","apicid\t\t: 5\n","initial apicid\t: 5\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n","bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb srso ibpb_no_ret\n","bogomips\t: 4499.99\n","TLB size\t: 3072 4K pages\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 48 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 7\n","vendor_id\t: AuthenticAMD\n","cpu family\t: 23\n","model\t\t: 49\n","model name\t: AMD EPYC 7B12\n","stepping\t: 0\n","microcode\t: 0xffffffff\n","cpu MHz\t\t: 2249.998\n","cache size\t: 512 KB\n","physical id\t: 0\n","siblings\t: 8\n","core id\t\t: 3\n","cpu cores\t: 4\n","apicid\t\t: 7\n","initial apicid\t: 7\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n","bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb srso ibpb_no_ret\n","bogomips\t: 4499.99\n","TLB size\t: 3072 4K pages\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 48 bits physical, 48 bits virtual\n","power management:\n","\n"]}]},{"cell_type":"code","source":["!lscpu"],"metadata":{"id":"8GOVZBcYkX-J","executionInfo":{"status":"ok","timestamp":1749504067677,"user_tz":-120,"elapsed":114,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"81e1f3be-281c-4fc2-f2aa-7c70bea7c932","colab":{"base_uri":"https://localhost:8080/"}},"id":"8GOVZBcYkX-J","execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Architecture:             x86_64\n","  CPU op-mode(s):         32-bit, 64-bit\n","  Address sizes:          48 bits physical, 48 bits virtual\n","  Byte Order:             Little Endian\n","CPU(s):                   8\n","  On-line CPU(s) list:    0-7\n","Vendor ID:                AuthenticAMD\n","  Model name:             AMD EPYC 7B12\n","    CPU family:           23\n","    Model:                49\n","    Thread(s) per core:   2\n","    Core(s) per socket:   4\n","    Socket(s):            1\n","    Stepping:             0\n","    BogoMIPS:             4499.99\n","    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n","                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall\n","                           nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep\n","                          _good nopl nonstop_tsc cpuid extd_apicid tsc_known_fre\n","                          q pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic mo\n","                          vbe popcnt aes xsave avx f16c rdrand hypervisor lahf_l\n","                          m cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowpre\n","                          fetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsba\n","                          se tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clfl\n","                          ushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsav\n","                          eerptr arat npt nrip_save umip rdpid\n","Virtualization features:  \n","  Hypervisor vendor:      KVM\n","  Virtualization type:    full\n","Caches (sum of all):      \n","  L1d:                    128 KiB (4 instances)\n","  L1i:                    128 KiB (4 instances)\n","  L2:                     2 MiB (4 instances)\n","  L3:                     16 MiB (1 instance)\n","NUMA:                     \n","  NUMA node(s):           1\n","  NUMA node0 CPU(s):      0-7\n","Vulnerabilities:          \n","  Gather data sampling:   Not affected\n","  Itlb multihit:          Not affected\n","  L1tf:                   Not affected\n","  Mds:                    Not affected\n","  Meltdown:               Not affected\n","  Mmio stale data:        Not affected\n","  Reg file data sampling: Not affected\n","  Retbleed:               Vulnerable\n","  Spec rstack overflow:   Vulnerable\n","  Spec store bypass:      Vulnerable\n","  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n","                          arriers only; no swapgs barriers\n","  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n","                          RS: Not affected; BHI: Not affected\n","  Srbds:                  Not affected\n","  Tsx async abort:        Not affected\n"]}]},{"cell_type":"markdown","source":["## SETUP"],"metadata":{"id":"V3Xstv5G2ZfG"},"id":"V3Xstv5G2ZfG"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"escKWVvzL3iO","executionInfo":{"status":"ok","timestamp":1749495097158,"user_tz":-120,"elapsed":21336,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"39b3731a-841d-4ce8-e1f5-9d2d195aba6a"},"id":"escKWVvzL3iO","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["!pip install -U \"ray[tune]\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrWK-fHAPuJn","executionInfo":{"status":"ok","timestamp":1749495105443,"user_tz":-120,"elapsed":8282,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"600f9e17-6a48-4241-e498-e7da5c1f670c"},"id":"PrWK-fHAPuJn","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ray[tune]\n","  Downloading ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (8.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (3.18.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (4.24.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (1.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (24.2)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (5.29.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.32.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2.2.2)\n","Collecting tensorboardX>=1.9 (from ray[tune])\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (18.1.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from ray[tune]) (2025.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=1.9->ray[tune]) (2.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray[tune]) (0.25.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ray[tune]) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray[tune]) (2025.4.26)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.17.0)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->ray[tune]) (4.14.0)\n","Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl (68.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboardX, ray\n","Successfully installed ray-2.46.0 tensorboardX-2.6.2.2\n"]}]},{"cell_type":"code","source":["import torch\n","\n","!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install pypots"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGtNd10GLXiZ","executionInfo":{"status":"ok","timestamp":1749495202027,"user_tz":-120,"elapsed":96582,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"c8fd5890-6d6f-4d6a-f293-566e78cafaa0"},"id":"WGtNd10GLXiZ","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt26cu124\n","Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n","Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.18+pt26cu124\n","Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","Collecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.15.3)\n","Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt26cu124\n","Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n","  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-mcfz4_z8\n","  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-mcfz4_z8\n","  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 0d013cf488a722d5a5b3bf657302fa7ca8b6d120\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.11.15)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2025.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2025.4.26)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1219268 sha256=46e674cd728c4768b666b3a16a9c298491b4131cda50cde617c49251a17be74d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-z5m0bkty/wheels/93/bb/85/bfec4ee59b2563f74ec87cc2c91c6a4d3e40d3dcdec8ee5afe\n","Successfully built torch-geometric\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.7.0\n","Collecting pypots\n","  Downloading pypots-0.19-py3-none-any.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from pypots) (3.13.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pypots) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pypots) (1.15.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from pypots) (1.13.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from pypots) (0.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pypots) (2.2.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from pypots) (0.13.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pypots) (3.10.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from pypots) (2.18.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pypots) (1.6.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from pypots) (4.52.4)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from pypots) (2.6.0+cu124)\n","Collecting tsdb>=0.7.1 (from pypots)\n","  Downloading tsdb-0.7.1-py3-none-any.whl.metadata (13 kB)\n","Collecting pygrinder>=0.7 (from pypots)\n","  Downloading pygrinder-0.7-py3-none-any.whl.metadata (10 kB)\n","Collecting benchpots>=0.4 (from pypots)\n","  Downloading benchpots-0.4-py3-none-any.whl.metadata (9.5 kB)\n","Collecting ai4ts (from pypots)\n","  Downloading ai4ts-0.0.3-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->pypots)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pypots) (3.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->pypots) (1.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tsdb>=0.7.1->pypots) (4.67.1)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tsdb>=0.7.1->pypots) (18.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tsdb>=0.7.1->pypots) (2.32.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypots) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypots) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypots) (4.58.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypots) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypots) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypots) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypots) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pypots) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pypots) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pypots) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pypots) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pypots) (3.6.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->pypots) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->pypots) (1.72.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->pypots) (3.8)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->pypots) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->pypots) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->pypots) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->pypots) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->pypots) (3.1.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->pypots) (0.32.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->pypots) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->pypots) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->pypots) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->pypots) (0.5.3)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->pypots) (1.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->pypots) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tsdb>=0.7.1->pypots) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tsdb>=0.7.1->pypots) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tsdb>=0.7.1->pypots) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tsdb>=0.7.1->pypots) (2025.4.26)\n","Downloading pypots-0.19-py3-none-any.whl (741 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.7/741.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading benchpots-0.4-py3-none-any.whl (30 kB)\n","Downloading pygrinder-0.7-py3-none-any.whl (24 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tsdb-0.7.1-py3-none-any.whl (32 kB)\n","Downloading ai4ts-0.0.3-py3-none-any.whl (13 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ai4ts, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tsdb, nvidia-cusolver-cu12, pygrinder, benchpots, pypots\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed ai4ts-0.0.3 benchpots-0.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pygrinder-0.7 pypots-0.19 tsdb-0.7.1\n"]}]},{"cell_type":"code","source":["!pip install pytorch-forecasting"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inYEIT4GviWz","executionInfo":{"status":"ok","timestamp":1749495208318,"user_tz":-120,"elapsed":6281,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"09724c3f-54cd-4355-c95c-651ad517be07"},"id":"inYEIT4GviWz","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-forecasting\n","  Downloading pytorch_forecasting-1.3.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.0.2)\n","Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.6.0+cu124)\n","Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n","  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n","Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.15.3)\n","Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (2.2.2)\n","Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-forecasting) (1.6.1)\n","Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.2)\n","Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2025.3.2)\n","Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.2)\n","Collecting torchmetrics<3.0,>=0.7.0 (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n","  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.67.1)\n","Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.14.0)\n","Collecting pytorch-lightning (from lightning<3.0.0,>=2.0.0->pytorch-forecasting)\n","  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (75.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.20.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.10)\n","Downloading pytorch_forecasting-1.3.0-py3-none-any.whl (197 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.7/197.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning, pytorch-forecasting\n","Successfully installed lightning-2.5.1.post0 lightning-utilities-0.14.3 pytorch-forecasting-1.3.0 pytorch-lightning-2.5.1.post0 torchmetrics-1.7.2\n"]}]},{"cell_type":"code","source":["!pip install pytorch_optimizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXd_m7RHEvrG","executionInfo":{"status":"ok","timestamp":1749495212142,"user_tz":-120,"elapsed":3813,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"cd5d5614-073e-4d1e-b272-c2ce50f02dc3"},"id":"PXd_m7RHEvrG","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_optimizer\n","  Downloading pytorch_optimizer-3.6.0-py3-none-any.whl.metadata (74 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_optimizer) (2.0.2)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from pytorch_optimizer) (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->pytorch_optimizer) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->pytorch_optimizer) (3.0.2)\n","Downloading pytorch_optimizer-3.6.0-py3-none-any.whl (252 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/252.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytorch_optimizer\n","Successfully installed pytorch_optimizer-3.6.0\n"]}]},{"cell_type":"code","source":["!mkdir -p datasets/knmi_station_data\n","!cp -r /content/drive/MyDrive/MAGISTERKA/datasets/knmi_station_data ./datasets/"],"metadata":{"id":"tcdz_f2RL_6d","executionInfo":{"status":"ok","timestamp":1749495224499,"user_tz":-120,"elapsed":12348,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"tcdz_f2RL_6d","execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"gv1G4oRp2bqE"},"id":"gv1G4oRp2bqE"},{"cell_type":"code","execution_count":7,"id":"3efc4a10","metadata":{"id":"3efc4a10","executionInfo":{"status":"ok","timestamp":1749495252501,"user_tz":-120,"elapsed":27992,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b0c8822-b279-442a-d3d9-1f59b5d0a905"},"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-09 18:53:47 [WARNING]: ‼️ PyPOTS Ecosystem configuration file does not exist.\n","2025-06-09 18:53:47 [INFO]: Wrote new configs to config.ini successfully.\n","2025-06-09 18:53:47 [INFO]: 💫 Initialized PyPOTS Ecosystem configuration file /root/.pypots/config.ini successfully.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\n","████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n","╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n","   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n","   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n","   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n","   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n","ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n","\n"]}],"source":["from collections import Counter\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from pypots.utils.random import set_random_seed\n","from pypots.optim import Adam\n","from pypots.classification import Raindrop, BRITS, GRUD\n","from pypots.nn.functional import calc_binary_classification_metrics, calc_mse, calc_rmse, calc_mae\n","from pypots.nn.modules.loss import Criterion, MSE, MAE\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.transforms import v2\n","from torch.utils.data import WeightedRandomSampler\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from pytorch_forecasting.data.timeseries import TimeSeriesDataSet\n","from pytorch_forecasting.data.encoders import NaNLabelEncoder\n","from pytorch_forecasting.models import Baseline, TemporalFusionTransformer\n","from pytorch_forecasting.metrics import MAE, RMSE, MASE\n","\n","import lightning as L\n","from lightning.pytorch.loggers import TensorBoardLogger\n","from lightning.pytorch.tuner import Tuner\n","from torchmetrics import Metric\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n","from typing import Any, TypeVar\n","from collections import namedtuple\n","\n","\n","from ray.tune.schedulers import ASHAScheduler\n","import os\n","import tempfile\n","\n","\n","import ray\n","from ray import tune"]},{"cell_type":"code","source":["BASE_PATH = Path(\"/content\")\n","DRIVE_PATH = Path(\"/content/drive/MyDrive/MAGISTERKA\")\n","SAVE_DIR = DRIVE_PATH / \"lightning_logs/runs/forecast\""],"metadata":{"id":"8xYfVERnDxza","executionInfo":{"status":"ok","timestamp":1749495252520,"user_tz":-120,"elapsed":9,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"8xYfVERnDxza","execution_count":8,"outputs":[]},{"cell_type":"markdown","id":"5783352d","metadata":{"id":"5783352d"},"source":["# Prepare df"]},{"cell_type":"code","execution_count":9,"id":"e475cc95","metadata":{"id":"e475cc95","executionInfo":{"status":"ok","timestamp":1749495252547,"user_tz":-120,"elapsed":24,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"outputs":[],"source":["stations = '249','323', '377'\n","# stations = '323',\n","test_station = '215'"]},{"cell_type":"code","execution_count":10,"id":"d560178e","metadata":{"id":"d560178e","executionInfo":{"status":"ok","timestamp":1749495252561,"user_tz":-120,"elapsed":11,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"outputs":[],"source":["def _convert_vv_to_meters(vv_code):\n","    if pd.isna(vv_code):\n","        return np.nan\n","\n","    vv_code = int(vv_code)\n","\n","    if 0 <= vv_code <= 49:\n","        return vv_code * 100 + 50\n","    elif vv_code == 50:\n","        return 5500\n","    elif 51 <= vv_code <= 55:\n","        return np.nan\n","    elif 56 <= vv_code <= 79:\n","        return int((vv_code - 56 + 6.5) * 1000)\n","    elif vv_code == 80:\n","        return 32500\n","    elif 81 <= vv_code <= 88:\n","        return int(32500 + (vv_code - 81) * 5000)\n","    elif vv_code == 89:\n","        return 70000\n","    else:\n","        return np.nan\n","\n","def _convert_vvm_to_simple(vv_m):\n","    if pd.isna(vv_m):\n","        return np.nan\n","\n","    if vv_m < 500:\n","      return 0\n","    elif vv_m < 1000:\n","      return 1\n","    elif vv_m < 2000:\n","      return 2\n","    elif vv_m < 5000:\n","      return 3\n","    elif vv_m < 10000:\n","      return 4\n","    else:\n","      return 5\n","\n","def _get_valid_vv_codes() -> list[int]:\n","    valid_codes = list(range(0, 51))\n","    valid_codes += list(range(56, 90))\n","    return valid_codes\n","\n","def get_vv_one_hot_encoder() -> OneHotEncoder:\n","    valid_codes = _get_valid_vv_codes()\n","    categories = [np.array(valid_codes, dtype=np.int32)]\n","    encoder = OneHotEncoder(categories=categories, handle_unknown='ignore', dtype=np.float32, sparse_output=False)\n","    encoder.fit(categories[0].reshape(-1, 1))\n","    return encoder\n","\n","def prepare_df(path: str) -> pd.DataFrame:\n","    try:\n","        header_line_index = -1\n","        column_names = []\n","        data_lines_start_index = -1\n","\n","        # Find the header and its index more efficiently\n","        with open(path, 'r') as f:\n","            for i, line in enumerate(f):\n","                if line.strip().startswith('# STN,YYYYMMDD,'):\n","                    header_line_index = i\n","                    column_names = [col.strip() for col in line.strip().lstrip('#').split(',')]\n","                    data_lines_start_index = header_line_index + 1\n","                    break\n","\n","        if header_line_index == -1:\n","            raise ValueError(\"Header line not found.\")\n","\n","        # Use pandas.read_csv directly with skiprows and comment character\n","        # This avoids reading the whole file into a list first for data lines\n","        # and then joining them back.\n","        df = pd.read_csv(\n","            path,\n","            names=column_names,\n","            skiprows=data_lines_start_index,\n","            comment='#',  # Lines starting with '#' will be ignored as comments\n","            skipinitialspace=True,\n","            na_values=['       ', '     '] # Add other common missing value representations if needed\n","        )\n","\n","        if df.empty:\n","            raise ValueError(\"No data found after the header or all data was commented out.\")\n","\n","        # Convert 'HH' to string and zfill, then create 'Timestamp'\n","        # It's crucial to handle potential NaN values in 'YYYYMMDD' or 'HH'\n","        # if they are not guaranteed to be present or valid in all rows.\n","        df['HH'] = df['HH'].astype(int) - 1\n","        df['HH'] = df['HH'].astype(str).str.zfill(2)\n","        df['Timestamp'] = pd.to_datetime(df['YYYYMMDD'].astype(str) + df['HH'].astype(str), format=\"%Y%m%d%H\", errors='coerce')\n","\n","        df.set_index('Timestamp', inplace=True)\n","\n","        # Columns to drop\n","        cols_to_drop = ['YYYYMMDD', 'HH']\n","        df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n","\n","        # Convert remaining columns to numeric, efficiently\n","        # Identify numeric columns once and convert\n","        # Exclude already processed or known non-numeric columns if necessary\n","        for col in df.columns:\n","            # This check is slightly redundant if YYYYMMDD and HH are already dropped,\n","            # but good for safety if they weren't or if other non-numeric columns exist.\n","            if df[col].dtype == 'object': # Only attempt conversion if the column is of object type\n","                try:\n","                    df[col] = pd.to_numeric(df[col], downcast='signed')\n","                except ValueError:\n","                    # Handle or log cases where a column expected to be numeric isn't\n","                    # For now, we'll coerce, which turns unparseable into NaT/NaN\n","                    df[col] = pd.to_numeric(df[col], errors='coerce', downcast='signed')\n","        df['VV_m'] = df['VV'].apply(_convert_vv_to_meters)\n","        df['VV_s'] = df['VV_m'].apply(_convert_vvm_to_simple)\n","\n","        return df\n","\n","    except FileNotFoundError:\n","        print(f\"Error: The file '{path}' was not found.\")\n","        raise\n","    except ValueError as ve:\n","        print(f\"ValueError: {ve}\")\n","        raise\n","    except Exception as e:\n","        print(f\"An unexpected error occurred: {e}\")\n","        raise"]},{"cell_type":"code","execution_count":11,"id":"8bdccf26","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"8bdccf26","executionInfo":{"status":"ok","timestamp":1749495254109,"user_tz":-120,"elapsed":1546,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"094e149e-4b8d-44e9-c9ed-17b5f9557286"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Timestamp  STN   DD  FH  FF  FX   T  T10N  TD  SQ  ...   U  WW  \\\n","0 2000-01-01 00:00:00  377  220  30  30  50  46   NaN  39   0  ...  95 NaN   \n","1 2000-01-01 01:00:00  377  210  30  30  50  47   NaN  41   0  ...  96 NaN   \n","2 2000-01-01 02:00:00  377  210  30  30  50  48   NaN  44   0  ...  97 NaN   \n","3 2000-01-01 03:00:00  377  200  30  30  50  49   NaN  45   0  ...  97 NaN   \n","4 2000-01-01 04:00:00  377  200  30  30  50  50   NaN  46   0  ...  97 NaN   \n","\n","   IX   M   R   S   O   Y  VV_m  VV_s  \n","0   6 NaN NaN NaN NaN NaN   NaN   NaN  \n","1   6 NaN NaN NaN NaN NaN   NaN   NaN  \n","2   6 NaN NaN NaN NaN NaN   NaN   NaN  \n","3   6 NaN NaN NaN NaN NaN   NaN   NaN  \n","4   6 NaN NaN NaN NaN NaN   NaN   NaN  \n","\n","[5 rows x 26 columns]"],"text/html":["\n","  <div id=\"df-5e9239a8-c369-46fe-b76d-d1863f6a0352\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>STN</th>\n","      <th>DD</th>\n","      <th>FH</th>\n","      <th>FF</th>\n","      <th>FX</th>\n","      <th>T</th>\n","      <th>T10N</th>\n","      <th>TD</th>\n","      <th>SQ</th>\n","      <th>...</th>\n","      <th>U</th>\n","      <th>WW</th>\n","      <th>IX</th>\n","      <th>M</th>\n","      <th>R</th>\n","      <th>S</th>\n","      <th>O</th>\n","      <th>Y</th>\n","      <th>VV_m</th>\n","      <th>VV_s</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2000-01-01 00:00:00</td>\n","      <td>377</td>\n","      <td>220</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>46</td>\n","      <td>NaN</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>95</td>\n","      <td>NaN</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2000-01-01 01:00:00</td>\n","      <td>377</td>\n","      <td>210</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>47</td>\n","      <td>NaN</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>96</td>\n","      <td>NaN</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2000-01-01 02:00:00</td>\n","      <td>377</td>\n","      <td>210</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>48</td>\n","      <td>NaN</td>\n","      <td>44</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>97</td>\n","      <td>NaN</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2000-01-01 03:00:00</td>\n","      <td>377</td>\n","      <td>200</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>49</td>\n","      <td>NaN</td>\n","      <td>45</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>97</td>\n","      <td>NaN</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2000-01-01 04:00:00</td>\n","      <td>377</td>\n","      <td>200</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>50</td>\n","      <td>NaN</td>\n","      <td>46</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>97</td>\n","      <td>NaN</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e9239a8-c369-46fe-b76d-d1863f6a0352')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5e9239a8-c369-46fe-b76d-d1863f6a0352 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5e9239a8-c369-46fe-b76d-d1863f6a0352');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-d45456ee-9710-450b-b02e-44852025b7ea\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d45456ee-9710-450b-b02e-44852025b7ea')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-d45456ee-9710-450b-b02e-44852025b7ea button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df"}},"metadata":{},"execution_count":11}],"source":["dfs = []\n","for station in stations:\n","    df = prepare_df(f\"./datasets/knmi_station_data/{station}.txt\")\n","    df = df.set_index('STN', append=True)\n","    # Check whether VV column has any noy nulls\n","    nulls = df['VV'].isna().sum()\n","    dfs.append(df)\n","\n","train_df = pd.concat(dfs)\n","train_df = df.reset_index()\n","train_df.head()"]},{"cell_type":"code","source":["train_df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xP_YOnqfrNBU","executionInfo":{"status":"ok","timestamp":1749495254120,"user_tz":-120,"elapsed":17,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"570590b1-ed86-4821-d7df-a55e4359d06f"},"id":"xP_YOnqfrNBU","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 88104 entries, 0 to 88103\n","Data columns (total 26 columns):\n"," #   Column     Non-Null Count  Dtype         \n","---  ------     --------------  -----         \n"," 0   Timestamp  88104 non-null  datetime64[ns]\n"," 1   STN        88104 non-null  int64         \n"," 2   DD         88104 non-null  int64         \n"," 3   FH         88104 non-null  int64         \n"," 4   FF         88104 non-null  int64         \n"," 5   FX         88104 non-null  int64         \n"," 6   T          88104 non-null  int64         \n"," 7   T10N       14682 non-null  float64       \n"," 8   TD         88104 non-null  int64         \n"," 9   SQ         88104 non-null  int64         \n"," 10  Q          88104 non-null  int64         \n"," 11  DR         88104 non-null  int64         \n"," 12  RH         88104 non-null  int64         \n"," 13  P          0 non-null      float64       \n"," 14  VV         77850 non-null  float64       \n"," 15  N          77775 non-null  float64       \n"," 16  U          88104 non-null  int64         \n"," 17  WW         35056 non-null  float64       \n"," 18  IX         88104 non-null  int64         \n"," 19  M          77847 non-null  float64       \n"," 20  R          77847 non-null  float64       \n"," 21  S          77847 non-null  float64       \n"," 22  O          77847 non-null  float64       \n"," 23  Y          77847 non-null  float64       \n"," 24  VV_m       77850 non-null  float64       \n"," 25  VV_s       77850 non-null  float64       \n","dtypes: datetime64[ns](1), float64(12), int64(13)\n","memory usage: 17.5 MB\n"]}]},{"cell_type":"code","execution_count":13,"id":"845b4bf1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"845b4bf1","executionInfo":{"status":"ok","timestamp":1749495254345,"user_tz":-120,"elapsed":222,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"59b4f89d-b7cf-4cf5-b238-6d18061727ab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Timestamp  STN     DD    FH    FF    FX   T  T10N  TD  SQ  ...  \\\n","0 2015-01-01 00:00:00  215  210.0  50.0  50.0  70.0  27   NaN   8   0  ...   \n","1 2015-01-01 01:00:00  215  220.0  50.0  50.0  70.0  26   NaN   4   0  ...   \n","2 2015-01-01 02:00:00  215  200.0  50.0  40.0  80.0  23   NaN   2   0  ...   \n","3 2015-01-01 03:00:00  215  210.0  40.0  40.0  70.0  21   NaN   1   0  ...   \n","4 2015-01-01 04:00:00  215  190.0  50.0  50.0  80.0  19   NaN   2   0  ...   \n","\n","    U    WW  IX    M    R    S    O    Y     VV_m  VV_s  \n","0  87  10.0   7  0.0  0.0  0.0  0.0  0.0   4250.0   3.0  \n","1  85  10.0   7  0.0  0.0  0.0  0.0  0.0   7500.0   4.0  \n","2  86   NaN   5  0.0  0.0  0.0  0.0  0.0  10500.0   5.0  \n","3  87   NaN   5  0.0  0.0  0.0  0.0  0.0  10500.0   5.0  \n","4  88   NaN   5  0.0  0.0  0.0  0.0  0.0  10500.0   5.0  \n","\n","[5 rows x 26 columns]"],"text/html":["\n","  <div id=\"df-e40fb089-10de-4886-8436-7019f2916dd0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>STN</th>\n","      <th>DD</th>\n","      <th>FH</th>\n","      <th>FF</th>\n","      <th>FX</th>\n","      <th>T</th>\n","      <th>T10N</th>\n","      <th>TD</th>\n","      <th>SQ</th>\n","      <th>...</th>\n","      <th>U</th>\n","      <th>WW</th>\n","      <th>IX</th>\n","      <th>M</th>\n","      <th>R</th>\n","      <th>S</th>\n","      <th>O</th>\n","      <th>Y</th>\n","      <th>VV_m</th>\n","      <th>VV_s</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2015-01-01 00:00:00</td>\n","      <td>215</td>\n","      <td>210.0</td>\n","      <td>50.0</td>\n","      <td>50.0</td>\n","      <td>70.0</td>\n","      <td>27</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>87</td>\n","      <td>10.0</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4250.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2015-01-01 01:00:00</td>\n","      <td>215</td>\n","      <td>220.0</td>\n","      <td>50.0</td>\n","      <td>50.0</td>\n","      <td>70.0</td>\n","      <td>26</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>85</td>\n","      <td>10.0</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7500.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2015-01-01 02:00:00</td>\n","      <td>215</td>\n","      <td>200.0</td>\n","      <td>50.0</td>\n","      <td>40.0</td>\n","      <td>80.0</td>\n","      <td>23</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>86</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10500.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2015-01-01 03:00:00</td>\n","      <td>215</td>\n","      <td>210.0</td>\n","      <td>40.0</td>\n","      <td>40.0</td>\n","      <td>70.0</td>\n","      <td>21</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>87</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10500.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2015-01-01 04:00:00</td>\n","      <td>215</td>\n","      <td>190.0</td>\n","      <td>50.0</td>\n","      <td>50.0</td>\n","      <td>80.0</td>\n","      <td>19</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>88</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>10500.0</td>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e40fb089-10de-4886-8436-7019f2916dd0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e40fb089-10de-4886-8436-7019f2916dd0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e40fb089-10de-4886-8436-7019f2916dd0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-f1b9eaf8-3596-4e9b-bb8d-dd6e180d14a6\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1b9eaf8-3596-4e9b-bb8d-dd6e180d14a6')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-f1b9eaf8-3596-4e9b-bb8d-dd6e180d14a6 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_df"}},"metadata":{},"execution_count":13}],"source":["dfs = []\n","for station in [test_station]:\n","    df = prepare_df(f\"./datasets/knmi_station_data/{station}.txt\")\n","    df = df.set_index('STN', append=True)\n","    # Check whether VV column has any noy nulls\n","    nulls = df['VV'].isna().sum()\n","    dfs.append(df)\n","\n","test_df = pd.concat(dfs)\n","test_df = df.reset_index()\n","test_df.head()"]},{"cell_type":"code","execution_count":14,"id":"f5c65cef","metadata":{"id":"f5c65cef","executionInfo":{"status":"ok","timestamp":1749495254348,"user_tz":-120,"elapsed":1,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"outputs":[],"source":["SEQUENCE_LENGTH = 12\n","STEP_SIZE = 1\n","TARGET_COLUMN = 'VV_s'\n","NUMERICAL_COLS = [\n","    \"FH\", \"FF\", \"FX\", \"T\", \"T10N\", \"TD\", \"SQ\", \"Q\", \"DR\", \"RH\", \"P\", \"U\",\n","    # \"DD\"\n","]\n","CATEGORICAL_COLS = {\n","    # \"WW\", \"IX\", \"VV\"\n","}\n","\n","vv_encoder = get_vv_one_hot_encoder()\n"]},{"cell_type":"markdown","source":["# Pytorch forecasting dataset"],"metadata":{"id":"UvP5lRyZv7TD"},"id":"UvP5lRyZv7TD"},{"cell_type":"code","source":["def prepare_forecasting_df(df: pd.DataFrame) -> pd.DataFrame:\n","  df = df.copy()\n","  df = df[df[TARGET_COLUMN].notna()]\n","\n","  prepared_dfs = []\n","  for station in df['STN'].unique():\n","    station_df = df[df['STN'] == station]\n","    station_df = station_df.sort_values('Timestamp').reset_index(drop=True)\n","    valid_times = station_df['Timestamp'].sort_values().reset_index(drop=True)\n","    time_diffs = valid_times.diff().fillna(pd.Timedelta(seconds=0))\n","    group = (time_diffs > pd.Timedelta(hours=1)).cumsum()\n","    station_df['TimeGroup'] = group\n","    station_df['TimeIdx'] = station_df.groupby('TimeGroup').cumcount()\n","    prepared_dfs.append(station_df)\n","  return pd.concat(prepared_dfs, axis=0).fillna(-1)"],"metadata":{"id":"J_Nftg3d8hPR","executionInfo":{"status":"ok","timestamp":1749495254352,"user_tz":-120,"elapsed":1,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"J_Nftg3d8hPR","execution_count":15,"outputs":[]},{"cell_type":"code","source":["train_df_v2 = prepare_forecasting_df(train_df)\n","test_df_v2 = prepare_forecasting_df(test_df)"],"metadata":{"id":"XVT2JSQ-wj00","executionInfo":{"status":"ok","timestamp":1749495254369,"user_tz":-120,"elapsed":14,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"XVT2JSQ-wj00","execution_count":16,"outputs":[]},{"cell_type":"code","source":["train_df_v2.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"id":"xA0sZgCqZqjz","executionInfo":{"status":"ok","timestamp":1749495254496,"user_tz":-120,"elapsed":62,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"5e3cb726-0d59-47fa-cfaf-07df0847c6e2"},"id":"xA0sZgCqZqjz","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Timestamp  STN   DD  FH  FF  FX   T  T10N  TD  SQ  ...  IX    M  \\\n","0 2003-01-01 00:00:00  377   70  20  20  30   6  -1.0 -12   0  ...   7  0.0   \n","1 2003-01-01 01:00:00  377    0  10   0  20   9  -1.0  -8   0  ...   7  0.0   \n","2 2003-01-01 02:00:00  377    0   0   0  10  10  -1.0  -5   0  ...   7  0.0   \n","3 2003-01-01 03:00:00  377  220  10  30  40  15  -1.0  -2   0  ...   7  0.0   \n","4 2003-01-01 04:00:00  377  220  30  30  50  15  -1.0   2   0  ...   7  0.0   \n","\n","     R    S    O    Y    VV_m  VV_s  TimeGroup  TimeIdx  \n","0  0.0  0.0  0.0  0.0  7500.0   4.0          0        0  \n","1  0.0  0.0  0.0  0.0  6500.0   4.0          0        1  \n","2  0.0  0.0  0.0  0.0  6500.0   4.0          0        2  \n","3  0.0  0.0  0.0  0.0  7500.0   4.0          0        3  \n","4  0.0  0.0  0.0  0.0  6500.0   4.0          0        4  \n","\n","[5 rows x 28 columns]"],"text/html":["\n","  <div id=\"df-86a04d4a-dd03-4747-b390-59c1ce6e3236\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>STN</th>\n","      <th>DD</th>\n","      <th>FH</th>\n","      <th>FF</th>\n","      <th>FX</th>\n","      <th>T</th>\n","      <th>T10N</th>\n","      <th>TD</th>\n","      <th>SQ</th>\n","      <th>...</th>\n","      <th>IX</th>\n","      <th>M</th>\n","      <th>R</th>\n","      <th>S</th>\n","      <th>O</th>\n","      <th>Y</th>\n","      <th>VV_m</th>\n","      <th>VV_s</th>\n","      <th>TimeGroup</th>\n","      <th>TimeIdx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2003-01-01 00:00:00</td>\n","      <td>377</td>\n","      <td>70</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>30</td>\n","      <td>6</td>\n","      <td>-1.0</td>\n","      <td>-12</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2003-01-01 01:00:00</td>\n","      <td>377</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>9</td>\n","      <td>-1.0</td>\n","      <td>-8</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2003-01-01 02:00:00</td>\n","      <td>377</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>-1.0</td>\n","      <td>-5</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2003-01-01 03:00:00</td>\n","      <td>377</td>\n","      <td>220</td>\n","      <td>10</td>\n","      <td>30</td>\n","      <td>40</td>\n","      <td>15</td>\n","      <td>-1.0</td>\n","      <td>-2</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2003-01-01 04:00:00</td>\n","      <td>377</td>\n","      <td>220</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>15</td>\n","      <td>-1.0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 28 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86a04d4a-dd03-4747-b390-59c1ce6e3236')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-86a04d4a-dd03-4747-b390-59c1ce6e3236 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-86a04d4a-dd03-4747-b390-59c1ce6e3236');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-b2ab33c5-81d3-4658-99a7-4f4508a3f9a2\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2ab33c5-81d3-4658-99a7-4f4508a3f9a2')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-b2ab33c5-81d3-4658-99a7-4f4508a3f9a2 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df_v2"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["TRAIN_CUTOFF = pd.to_datetime('2021-01-01')\n","train_dataset = TimeSeriesDataSet(\n","    data=train_df_v2[train_df_v2['Timestamp'] < TRAIN_CUTOFF],\n","    time_idx='TimeIdx',\n","    target=TARGET_COLUMN,\n","    group_ids=['STN', 'TimeGroup'],\n","    min_encoder_length=8,\n","    max_encoder_length=8,\n","    min_prediction_length=1,\n","    max_prediction_length=1,\n","    time_varying_known_reals=NUMERICAL_COLS,\n","    add_relative_time_idx=False,\n","    categorical_encoders={\n","        'TimeGroup': NaNLabelEncoder(add_nan=True, warn=False),\n","        'STN': NaNLabelEncoder(add_nan=True, warn=False),\n","    }\n",")\n","validation_dataset = TimeSeriesDataSet.from_dataset(\n","    train_dataset,\n","    train_df_v2[train_df_v2['Timestamp'] >= TRAIN_CUTOFF],\n","    stop_randomization=True,\n",")\n","train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6G1JeETv9Bb","executionInfo":{"status":"ok","timestamp":1749495256952,"user_tz":-120,"elapsed":2456,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"c2d1e94e-1cb8-40db-a208-f347ca672cd0"},"id":"W6G1JeETv9Bb","execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TimeSeriesDataSet[length=60786](\n","\ttime_idx='TimeIdx',\n","\ttarget='VV_s',\n","\tgroup_ids=['STN', 'TimeGroup'],\n","\tweight=None,\n","\tmax_encoder_length=8,\n","\tmin_encoder_length=8,\n","\tmin_prediction_idx=0,\n","\tmin_prediction_length=1,\n","\tmax_prediction_length=1,\n","\tstatic_categoricals=None,\n","\tstatic_reals=None,\n","\ttime_varying_known_categoricals=None,\n","\ttime_varying_known_reals=['FH', 'FF', 'FX', 'T', 'T10N', 'TD', 'SQ', 'Q', 'DR', 'RH', 'P', 'U'],\n","\ttime_varying_unknown_categoricals=None,\n","\ttime_varying_unknown_reals=None,\n","\tvariable_groups=None,\n","\tconstant_fill_strategy=None,\n","\tallow_missing_timesteps=False,\n","\tlags=None,\n","\tadd_relative_time_idx=False,\n","\tadd_target_scales=False,\n","\tadd_encoder_length=False,\n","\ttarget_normalizer=GroupNormalizer(\n","\tmethod='standard',\n","\tgroups=None,\n","\tcenter=True,\n","\tscale_by_group=False,\n","\ttransformation=None,\n","\tmethod_kwargs={}\n","),\n","\tcategorical_encoders={'TimeGroup': NaNLabelEncoder(add_nan=True, warn=False), 'STN': NaNLabelEncoder(add_nan=True, warn=False), '__group_id__STN': NaNLabelEncoder(add_nan=False, warn=True), '__group_id__TimeGroup': NaNLabelEncoder(add_nan=False, warn=True)},\n","\tscalers={'FH': StandardScaler(), 'FF': StandardScaler(), 'FX': StandardScaler(), 'T': StandardScaler(), 'T10N': StandardScaler(), 'TD': StandardScaler(), 'SQ': StandardScaler(), 'Q': StandardScaler(), 'DR': StandardScaler(), 'RH': StandardScaler(), 'P': StandardScaler(), 'U': StandardScaler()},\n","\trandomize_length=None,\n","\tpredict_mode=False\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["target = train_df_v2.loc[train_dataset.index.index, TARGET_COLUMN].to_numpy()\n","# probabilities = np.ones_like(target)\n","# probabilities[target < 5000] = 3\n","# probabilities[target < 3000] = 5\n","# probabilities[target < 1000] = 10\n","\n","train_dl = train_dataset.to_dataloader(\n","  batch_size=64,\n","  # sampler=WeightedRandomSampler(weights=probabilities, num_samples=len(probabilities), replacement=True),\n","  shuffle=False,\n","  num_workers=0\n",")"],"metadata":{"id":"4_32DlyhzPRq","executionInfo":{"status":"ok","timestamp":1749495256963,"user_tz":-120,"elapsed":3,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"4_32DlyhzPRq","execution_count":19,"outputs":[]},{"cell_type":"code","source":["# target = train_df_v2.loc[validation_dataset.index.index, \"VV_m\"].to_numpy()\n","# probabilities = np.ones_like(target)\n","# probabilities[target < 5000] = 3\n","# probabilities[target < 3000] = 5\n","# probabilities[target < 1000] = 10\n","\n","validation_dl = validation_dataset.to_dataloader(\n","  batch_size=64 * 10,\n","  # sampler=WeightedRandomSampler(weights=probabilities, num_samples=len(probabilities), replacement=True),\n","  shuffle=False,\n","  num_workers=0,\n","  drop_last=True\n",")"],"metadata":{"id":"emJlD-bFAdMx","executionInfo":{"status":"ok","timestamp":1749495256994,"user_tz":-120,"elapsed":24,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"emJlD-bFAdMx","execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# Pypots dataset"],"metadata":{"id":"BqWRrfGlZ2dX"},"id":"BqWRrfGlZ2dX"},{"cell_type":"code","source":["train_df_v2 = prepare_forecasting_df(train_df)\n","test_df_v2 = prepare_forecasting_df(test_df)\n","\n","train_df_v2.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"id":"Gmge1IXhZ3pS","executionInfo":{"status":"ok","timestamp":1749495257101,"user_tz":-120,"elapsed":101,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"4002dfb3-6f5c-453d-b632-fa5a06bad81d"},"id":"Gmge1IXhZ3pS","execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Timestamp  STN   DD  FH  FF  FX   T  T10N  TD  SQ  ...  IX    M  \\\n","0 2003-01-01 00:00:00  377   70  20  20  30   6  -1.0 -12   0  ...   7  0.0   \n","1 2003-01-01 01:00:00  377    0  10   0  20   9  -1.0  -8   0  ...   7  0.0   \n","2 2003-01-01 02:00:00  377    0   0   0  10  10  -1.0  -5   0  ...   7  0.0   \n","3 2003-01-01 03:00:00  377  220  10  30  40  15  -1.0  -2   0  ...   7  0.0   \n","4 2003-01-01 04:00:00  377  220  30  30  50  15  -1.0   2   0  ...   7  0.0   \n","\n","     R    S    O    Y    VV_m  VV_s  TimeGroup  TimeIdx  \n","0  0.0  0.0  0.0  0.0  7500.0   4.0          0        0  \n","1  0.0  0.0  0.0  0.0  6500.0   4.0          0        1  \n","2  0.0  0.0  0.0  0.0  6500.0   4.0          0        2  \n","3  0.0  0.0  0.0  0.0  7500.0   4.0          0        3  \n","4  0.0  0.0  0.0  0.0  6500.0   4.0          0        4  \n","\n","[5 rows x 28 columns]"],"text/html":["\n","  <div id=\"df-aca1c232-4b72-4e0a-be66-ba343481c1f1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Timestamp</th>\n","      <th>STN</th>\n","      <th>DD</th>\n","      <th>FH</th>\n","      <th>FF</th>\n","      <th>FX</th>\n","      <th>T</th>\n","      <th>T10N</th>\n","      <th>TD</th>\n","      <th>SQ</th>\n","      <th>...</th>\n","      <th>IX</th>\n","      <th>M</th>\n","      <th>R</th>\n","      <th>S</th>\n","      <th>O</th>\n","      <th>Y</th>\n","      <th>VV_m</th>\n","      <th>VV_s</th>\n","      <th>TimeGroup</th>\n","      <th>TimeIdx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2003-01-01 00:00:00</td>\n","      <td>377</td>\n","      <td>70</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>30</td>\n","      <td>6</td>\n","      <td>-1.0</td>\n","      <td>-12</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2003-01-01 01:00:00</td>\n","      <td>377</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>9</td>\n","      <td>-1.0</td>\n","      <td>-8</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2003-01-01 02:00:00</td>\n","      <td>377</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>-1.0</td>\n","      <td>-5</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2003-01-01 03:00:00</td>\n","      <td>377</td>\n","      <td>220</td>\n","      <td>10</td>\n","      <td>30</td>\n","      <td>40</td>\n","      <td>15</td>\n","      <td>-1.0</td>\n","      <td>-2</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2003-01-01 04:00:00</td>\n","      <td>377</td>\n","      <td>220</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>15</td>\n","      <td>-1.0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6500.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 28 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aca1c232-4b72-4e0a-be66-ba343481c1f1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-aca1c232-4b72-4e0a-be66-ba343481c1f1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-aca1c232-4b72-4e0a-be66-ba343481c1f1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-1c84f3d5-150c-4fd4-a6c3-20e9790438dc\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c84f3d5-150c-4fd4-a6c3-20e9790438dc')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-1c84f3d5-150c-4fd4-a6c3-20e9790438dc button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df_v2"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def df_to_pypots(df: pd.DataFrame, prev_values: int=8, cols: list[str]=NUMERICAL_COLS, target_col: str = 'VV_s'):\n","  df = df.copy()\n","  X = []\n","  y = []\n","  for _, group in df.groupby(['TimeGroup', 'STN']):\n","    if len(group) < prev_values:\n","      continue\n","    # Sliding window over group and add to X, y\n","    for i in range(len(group) - prev_values):\n","      X.append(group.iloc[i:i+prev_values][cols].values)\n","      y.append(group.iloc[i+prev_values][target_col])\n","  X = np.array(X)\n","  y = np.array(y)\n","  print(X.shape, y.shape)\n","  return X, y\n","\n","\n","X_train, y_train = df_to_pypots(\n","    train_df_v2[train_df_v2['Timestamp'] < TRAIN_CUTOFF],\n","    prev_values=8,\n","    target_col=TARGET_COLUMN,\n","    cols=NUMERICAL_COLS + ['VV_m', 'VV'],\n",")\n","\n","X_val, y_val = df_to_pypots(\n","    train_df_v2[train_df_v2['Timestamp'] >= TRAIN_CUTOFF],\n","    prev_values=8,\n","    target_col=TARGET_COLUMN,\n","    cols=NUMERICAL_COLS + ['VV_m', 'VV'],\n",")\n","\n","X_test, y_test = df_to_pypots(\n","    test_df_v2,\n","    prev_values=8,\n","    target_col=TARGET_COLUMN,\n","    cols=NUMERICAL_COLS + ['VV_m', 'VV'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZ3tdAN7Z5ZX","executionInfo":{"status":"ok","timestamp":1749495312508,"user_tz":-120,"elapsed":55407,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"df7fe4c1-8dc3-41e5-af23-76cd8cc505dd"},"id":"CZ3tdAN7Z5ZX","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["(60786, 8, 14) (60786,)\n","(16856, 8, 14) (16856,)\n","(36929, 8, 14) (36929,)\n"]}]},{"cell_type":"code","source":["def balance_dataset(X, y, up_to: int=2000):\n","  Xs = []\n","  ys = []\n","  for v, c in zip(*np.unique(y, return_counts=True)):\n","    if c < up_to:\n","      Xs.append(X[y == v])\n","      ys.append(y[y == v])\n","    else:\n","      # shuffle\n","      indexes = np.random.choice(c, up_to, replace=False)\n","      Xs.append(X[y == v][indexes])\n","      ys.append(y[y == v][indexes])\n","  return np.concatenate(Xs), np.concatenate(ys)"],"metadata":{"id":"QkxZ4PSjdDSA","executionInfo":{"status":"ok","timestamp":1749495312523,"user_tz":-120,"elapsed":5,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"QkxZ4PSjdDSA","execution_count":23,"outputs":[]},{"cell_type":"code","source":["np.unique(y_train, return_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrMrnKIfFcIU","executionInfo":{"status":"ok","timestamp":1749495312535,"user_tz":-120,"elapsed":10,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"b6d956d6-a679-49c6-8079-6b6d096a0a11"},"id":"qrMrnKIfFcIU","execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0., 1., 2., 3., 4., 5.]),\n"," array([  930,   400,  1401,  6329, 10673, 41053]))"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["np.unique(y_val, return_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srsl4PwJojtG","executionInfo":{"status":"ok","timestamp":1749495312544,"user_tz":-120,"elapsed":7,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"eb6e4691-6b48-4626-a323-871129821df1"},"id":"srsl4PwJojtG","execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0., 1., 2., 3., 4., 5.]),\n"," array([  323,    99,   173,   893,  1436, 13932]))"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["np.unique(y_test, return_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aq-YUdItFj23","executionInfo":{"status":"ok","timestamp":1749495312564,"user_tz":-120,"elapsed":19,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"4be6901c-7acc-41e5-862f-688e8f616f55"},"id":"Aq-YUdItFj23","execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0., 1., 2., 3., 4., 5.]),\n"," array([ 1029,   263,   536,  2384,  4725, 27992]))"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["X_train_bal, y_train_bal = balance_dataset(X_train, y_train, up_to=1000)\n","X_val_bal, y_val_bal = balance_dataset(X_val, y_val, up_to=400)\n","X_test_bal, y_test_bal = balance_dataset(X_test, y_test, up_to=1000)"],"metadata":{"id":"2pYgGEBIdd-x","executionInfo":{"status":"ok","timestamp":1749495312586,"user_tz":-120,"elapsed":20,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"2pYgGEBIdd-x","execution_count":27,"outputs":[]},{"cell_type":"code","source":["np.unique(y_train_bal, return_counts=True), len(y_train_bal)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUwfpDKii7fG","executionInfo":{"status":"ok","timestamp":1749495312607,"user_tz":-120,"elapsed":4,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"ba77872e-b196-4593-d8a6-02e1c5a28514"},"id":"SUwfpDKii7fG","execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((array([0., 1., 2., 3., 4., 5.]),\n","  array([ 930,  400, 1000, 1000, 1000, 1000])),\n"," 5330)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["np.unique(y_val_bal, return_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzmYSeT1dsas","executionInfo":{"status":"ok","timestamp":1749495312626,"user_tz":-120,"elapsed":13,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"8f283ea9-2771-4961-ba30-7a3df674d3c8"},"id":"UzmYSeT1dsas","execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0., 1., 2., 3., 4., 5.]), array([323,  99, 173, 400, 400, 400]))"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# Shuffle datasets\n","indexes = np.random.permutation(len(X_train_bal))\n","X_train_bal = X_train_bal[indexes]\n","y_train_bal = y_train_bal[indexes]\n","\n","indexes = np.random.permutation(len(X_val_bal))\n","X_val_bal = X_val_bal[indexes]\n","y_val_bal = y_val_bal[indexes]\n","\n","indexes = np.random.permutation(len(X_test_bal))\n","X_test_bal = X_test_bal[indexes]\n","y_test_bal = y_test_bal[indexes]\n","\n"],"metadata":{"id":"XN8bySmLkal-","executionInfo":{"status":"ok","timestamp":1749495312639,"user_tz":-120,"elapsed":11,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"XN8bySmLkal-","execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["# Deep models"],"metadata":{"id":"IQ_i0w5weEYv"},"id":"IQ_i0w5weEYv"},{"cell_type":"code","source":["from time import time\n","\n","def _get_formatted_metric(values: list[float]):\n","  avg = sum(values) / len(values)\n","  std = (sum([(v - avg) ** 2 for v in values]) / len(values)) ** 0.5\n","  return f\"{avg:.4f} ± {std:.4f}\"\n","\n","def evaluate_deep_model(model, X, y):\n","    y_pred = model.predict({'X': X, 'y': y})\n","    y_pred = y_pred['classification']\n","    accuracy = accuracy_score(y, y_pred)\n","    f1 = f1_score(y, y_pred, average='macro')\n","    precision = precision_score(y, y_pred, average='macro')\n","    recall = recall_score(y, y_pred, average='macro')\n","    confusion = confusion_matrix(y, y_pred)\n","    return namedtuple('Evaluation', ['accuracy', 'f1', 'precision', 'recall', 'confusion'])(accuracy, f1, precision, recall, confusion)\n","\n","\n","\n","def run_model(get_model, name: str, X_train, y_train, X_val, y_val, X_test, y_test, repeat: int = 5):\n","  final_res = {\n","      'accuracy': [],\n","      'f1': [],\n","      'precision': [],\n","      'recall': []\n","  }\n","  training_times = []\n","  for _ in range(repeat):\n","    model = get_model()\n","    _start = time()\n","    model.fit({'X': X_train, 'y': y_train}, {'X': X_val, 'y': y_val})\n","    _end = time()\n","    training_times.append(_end - _start)\n","    metrics = evaluate_deep_model(model, X_test, y_test)\n","    final_res['accuracy'].append(metrics.accuracy)\n","    final_res['f1'].append(metrics.f1)\n","    final_res['precision'].append(metrics.precision)\n","    final_res['recall'].append(metrics.recall)\n","\n","  print(\n","    f\"{name} & {_get_formatted_metric(final_res['accuracy'])} & {_get_formatted_metric(final_res['f1'])} & {_get_formatted_metric(final_res['precision'])} & {_get_formatted_metric(final_res['recall'])} \\\\\"\n","  )\n","  print(training_times)\n","  print(_get_formatted_metric(training_times))\n"],"metadata":{"id":"ljSezGDBYxxE"},"id":"ljSezGDBYxxE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_pypots_model(config, model_base_params, model_cls, X_train, y_train, X_val, y_val):\n","    if \"lr\" in config:\n","      optimizer = Adam(lr=config[\"lr\"])\n","      del config[\"lr\"]\n","    else:\n","      optimizer = Adam()\n","\n","    if \"epochs\" in config:\n","      epochs = config[\"epochs\"]\n","      del config[\"epochs\"]\n","    else:\n","      epochs = 10\n","    model = model_cls(\n","        **config,\n","        **model_base_params,\n","        optimizer=optimizer,\n","        epochs=1\n","    )\n","    if cp := tune.get_checkpoint():\n","      with cp.as_directory() as cp_directory:\n","        model.load(\n","            os.path.join(cp_directory, \"checkpoint.pypots\")\n","        )\n","    for _ in range(epochs):\n","      model.fit(train_set={'X': X_train, 'y': y_train}, val_set={'X': X_val, 'y': y_val})\n","      metrics = evaluate_deep_model(model, X_test, y_test)\n","\n","      with tempfile.TemporaryDirectory() as tmp_dir:\n","        path = os.path.join(tmp_dir, \"checkpoint.pypots\")\n","        model.save(path)\n","        checkpoint = tune.Checkpoint.from_directory(tmp_dir)\n","        tune.report(\n","            metrics={\n","              \"accuracy\": metrics.accuracy,\n","              \"f1\": metrics.f1,\n","              \"precision\": metrics.precision,\n","              \"recall\": metrics.recall,\n","            },\n","            checkpoint=checkpoint\n","        )"],"metadata":{"id":"V4b01h3IA9GI"},"id":"V4b01h3IA9GI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["scheduler = ASHAScheduler(\n","    time_attr='training_iteration',\n","    max_t=10,\n","    grace_period=2,\n","    reduction_factor=2\n",")\n","\n","tuner = tune.Tuner(\n","    tune.with_resources(\n","      tune.with_parameters(\n","          train_pypots_model,\n","          model_cls=Raindrop,\n","          model_base_params={\n","            \"n_steps\": X_train_bal.shape[1],\n","            \"n_features\": X_train_bal.shape[2],\n","            \"n_classes\": len(np.unique(y_train_bal)),\n","            \"batch_size\": 64,\n","            # \"patience\": 6,\n","            \"num_workers\": 0,\n","            \"device\": None,\n","            \"model_saving_strategy\": None,\n","            \"verbose\": True\n","          },\n","          X_train=X_train_bal,\n","          y_train=y_train_bal,\n","          X_val=X_val_bal,\n","          y_val=y_val_bal,\n","      ),\n","      resources={\"cpu\": 1}\n","    ),\n","    param_space={\n","        \"n_layers\": tune.choice([1, 2]),\n","        \"d_ffn\": tune.choice([32, 64, 128, 256]),\n","        \"n_heads\": tune.choice([1, 2]),\n","        \"d_model\": tune.choice([X_train_bal.shape[2] * i for i in range(1, 4+1)]),\n","        \"dropout\": tune.choice([0.1, 0.2, 0.3]),\n","        \"lr\": tune.loguniform(1e-4, 1e-1),\n","    },\n","    tune_config=tune.TuneConfig(\n","        num_samples=5,\n","        metric=\"accuracy\",\n","        mode=\"max\",\n","        scheduler=scheduler,\n","    )\n",")\n","\n","results = tuner.fit()\n","best_results = results.get_best_result(metric='accuracy', mode='max')\n","best_metrics = best_results.metrics\n","print(f\"Best params: {best_results.config}\")\n","for k, v in best_metrics.items():\n","  if isinstance(v, float):\n","    print(f\"{k}: {v:.4f}\")\n","  else:\n","    print(f\"{k}: {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2GfM1OkZBsXB","executionInfo":{"status":"ok","timestamp":1749310975769,"user_tz":-120,"elapsed":473376,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"6ad51344-3685-430f-f32b-6f39cf3141f9"},"id":"2GfM1OkZBsXB","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 15:35:04,743\tINFO worker.py:1888 -- Started a local Ray instance.\n","2025-06-07 15:35:05,967\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n"]},{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------------------------------+\n","| Configuration for experiment     train_pypots_model_2025-06-07_15-35-02   |\n","+---------------------------------------------------------------------------+\n","| Search algorithm                 BasicVariantGenerator                    |\n","| Scheduler                        AsyncHyperBandScheduler                  |\n","| Number of trials                 5                                        |\n","+---------------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/train_pypots_model_2025-06-07_15-35-02\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-07_15-35-02_772195_1623/artifacts/2025-06-07_15-35-06/train_pypots_model_2025-06-07_15-35-02/driver_artifacts`\n","\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (63 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n","\n","Trial status: 5 PENDING\n","Current time: 2025-06-07 15:35:09. Total running time: 3s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","+--------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status       n_layers     d_ffn     n_heads     d_model     dropout            lr |\n","+--------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   PENDING             1       256           2          56         0.1   0.000457075 |\n","| train_pypots_model_fce98_00001   PENDING             1        32           2          56         0.2   0.0260515   |\n","| train_pypots_model_fce98_00002   PENDING             1       128           1          14         0.1   0.00697881  |\n","| train_pypots_model_fce98_00003   PENDING             2        64           1          14         0.3   0.01154     |\n","| train_pypots_model_fce98_00004   PENDING             2        64           1          28         0.1   0.0103761   |\n","+--------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(pid=67625)\u001b[0m 2025-06-07 15:35:17.889983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(pid=67625)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(pid=67625)\u001b[0m E0000 00:00:1749310517.950974   67625 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(pid=67625)\u001b[0m E0000 00:00:1749310517.971924   67625 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(pid=67626)\u001b[0m \u001b[34m\n","\u001b[36m(pid=67626)\u001b[0m ████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n","\u001b[36m(pid=67626)\u001b[0m ╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n","\u001b[36m(pid=67626)\u001b[0m    ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n","\u001b[36m(pid=67626)\u001b[0m    ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n","\u001b[36m(pid=67626)\u001b[0m    ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n","\u001b[36m(pid=67626)\u001b[0m    ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n","\u001b[36m(pid=67626)\u001b[0m ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n","\u001b[36m(pid=67626)\u001b[0m \n","\n","Trial train_pypots_model_fce98_00004 started with configuration:\n","+---------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00004 config             |\n","+---------------------------------------------------------+\n","| d_ffn                                                64 |\n","| d_model                                              28 |\n","| dropout                                             0.1 |\n","| lr                                              0.01038 |\n","| n_heads                                               1 |\n","| n_layers                                              2 |\n","+---------------------------------------------------------+\n","\n","Trial train_pypots_model_fce98_00001 started with configuration:\n","+---------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00001 config             |\n","+---------------------------------------------------------+\n","| d_ffn                                                32 |\n","| d_model                                              56 |\n","| dropout                                             0.2 |\n","| lr                                              0.02605 |\n","| n_heads                                               2 |\n","| n_layers                                              1 |\n","+---------------------------------------------------------+\n","\u001b[36m(pid=67622)\u001b[0m \u001b[34m\n","\u001b[36m(pid=67622)\u001b[0m \n","\u001b[36m(pid=67625)\u001b[0m \u001b[34m\n","\u001b[36m(pid=67625)\u001b[0m \n","\u001b[36m(pid=67621)\u001b[0m \u001b[34m\n","\u001b[36m(pid=67621)\u001b[0m \n","\n","Trial train_pypots_model_fce98_00000 started with configuration:\n","+---------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00000 config             |\n","+---------------------------------------------------------+\n","| d_ffn                                               256 |\n","| d_model                                              56 |\n","| dropout                                             0.1 |\n","| lr                                              0.00046 |\n","| n_heads                                               2 |\n","| n_layers                                              1 |\n","+---------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:35:26 [INFO]: No given device, using default device: cpu\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:35:26 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:35:26 [INFO]: Using customized CrossEntropy as the training loss function.\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:35:26 [INFO]: Using customized CrossEntropy as the validation metric function.\n","\u001b[36m(pid=67626)\u001b[0m 2025-06-07 15:35:17.889687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(pid=67626)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(pid=67626)\u001b[0m E0000 00:00:1749310517.951424   67626 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(pid=67626)\u001b[0m E0000 00:00:1749310517.974483   67626 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 4x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_pypots_model_fce98_00003 started with configuration:\n","+---------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00003 config             |\n","+---------------------------------------------------------+\n","| d_ffn                                                64 |\n","| d_model                                              14 |\n","| dropout                                             0.3 |\n","| lr                                              0.01154 |\n","| n_heads                                               1 |\n","| n_layers                                              2 |\n","+---------------------------------------------------------+\n","\u001b[36m(pid=67624)\u001b[0m \u001b[34m\n","\u001b[36m(pid=67624)\u001b[0m \n","\n","Trial train_pypots_model_fce98_00002 started with configuration:\n","+---------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00002 config             |\n","+---------------------------------------------------------+\n","| d_ffn                                               128 |\n","| d_model                                              14 |\n","| dropout                                             0.1 |\n","| lr                                              0.00698 |\n","| n_heads                                               1 |\n","| n_layers                                              1 |\n","+---------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   warnings.warn(\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:35:27 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 20,548\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/pypots/data/utils.py:26: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   data = torch.from_numpy(data) if dtype == \"tensor\" else data\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:35:37 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5700, validation CrossEntropy: 1.4416\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:35:37 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:35:26 [INFO]: No given device, using default device: cpu\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:35:26 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:35:26 [INFO]: Using customized CrossEntropy as the training loss function.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:35:26 [INFO]: Using customized CrossEntropy as the validation metric function.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m /usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m   nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:35:27 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 101,940\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m /usr/local/lib/python3.11/dist-packages/pypots/data/utils.py:26: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m   data = torch.from_numpy(data) if dtype == \"tensor\" else data\u001b[32m [repeated 4x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 5 RUNNING\n","Current time: 2025-06-07 15:35:39. Total running time: 33s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","+--------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status       n_layers     d_ffn     n_heads     d_model     dropout            lr |\n","+--------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   RUNNING             1       256           2          56         0.1   0.000457075 |\n","| train_pypots_model_fce98_00001   RUNNING             1        32           2          56         0.2   0.0260515   |\n","| train_pypots_model_fce98_00002   RUNNING             1       128           1          14         0.1   0.00697881  |\n","| train_pypots_model_fce98_00003   RUNNING             2        64           1          14         0.3   0.01154     |\n","| train_pypots_model_fce98_00004   RUNNING             2        64           1          28         0.1   0.0103761   |\n","+--------------------------------------------------------------------------------------------------------------------+\n","Trial status: 5 RUNNING\n","Current time: 2025-06-07 15:36:09. Total running time: 1min 3s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","+--------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status       n_layers     d_ffn     n_heads     d_model     dropout            lr |\n","+--------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   RUNNING             1       256           2          56         0.1   0.000457075 |\n","| train_pypots_model_fce98_00001   RUNNING             1        32           2          56         0.2   0.0260515   |\n","| train_pypots_model_fce98_00002   RUNNING             1       128           1          14         0.1   0.00697881  |\n","| train_pypots_model_fce98_00003   RUNNING             2        64           1          14         0.3   0.01154     |\n","| train_pypots_model_fce98_00004   RUNNING             2        64           1          28         0.1   0.0103761   |\n","+--------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:35:41 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.6238, validation CrossEntropy: 1.3131\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:35:41 [INFO]: Finished training. The best model is from epoch#1.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:36:11 [INFO]: Saved the model to /tmp/tmpmm2mdcn0/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000000)\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:36:19 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4667, validation CrossEntropy: 1.4737\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:36:19 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m 2025-06-07 15:36:14 [INFO]: Saved the model to /tmp/tmpkgr06z9l/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00001_1_d_ffn=32,d_model=56,dropout=0.2000,lr=0.0261,n_heads=2,n_layers=1_2025-06-07_15-35-08/checkpoint_000000)\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:36:20 [INFO]: Saved the model to /tmp/tmpmz7vgzrq/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00004_4_d_ffn=64,d_model=28,dropout=0.1000,lr=0.0104,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000000)\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m 2025-06-07 15:36:25 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.2155, validation CrossEntropy: 1.0770\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m 2025-06-07 15:36:25 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:36:28 [INFO]: Saved the model to /tmp/tmp8ymlphgw/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000000)\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:36:30 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.2610, validation CrossEntropy: 1.1671\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:36:30 [INFO]: Finished training. The best model is from epoch#1.\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 5 RUNNING\n","Current time: 2025-06-07 15:36:39. Total running time: 1min 33s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7877548809878415 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status       n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   RUNNING             1       256           2          56         0.1   0.000457075        1            62.0513    0.561185    0.255137      0.260766     0.363729 |\n","| train_pypots_model_fce98_00001   RUNNING             1        32           2          56         0.2   0.0260515          1            48.2109    0.0278914   0.0100169     0.00516759   0.166978 |\n","| train_pypots_model_fce98_00002   RUNNING             1       128           1          14         0.1   0.00697881         1            44.539     0.127975    0.0382293     0.226447     0.166777 |\n","| train_pypots_model_fce98_00003   RUNNING             2        64           1          14         0.3   0.01154            1            61.7643    0.787755    0.299129      0.337439     0.31947  |\n","| train_pypots_model_fce98_00004   RUNNING             2        64           1          28         0.1   0.0103761          1            53.7312    0.0278643   0.00918145    0.0820096    0.166107 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:36:41 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3354, validation CrossEntropy: 1.2242\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:36:41 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:36:28 [INFO]: Saved the model to /tmp/tmp80pfafjn/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00000_0_d_ffn=256,d_model=56,dropout=0.1000,lr=0.0005,n_heads=2,n_layers=1_2025-06-07_15-35-07/checkpoint_000000)\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:36:59 [INFO]: Saved the model to /tmp/tmpjdz6wm9a/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000001)\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:36:43 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4232, validation CrossEntropy: 1.1879\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:36:43 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m 2025-06-07 15:37:04 [INFO]: Saved the model to /tmp/tmp7_vd4cog/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00001_1_d_ffn=32,d_model=56,dropout=0.2000,lr=0.0261,n_heads=2,n_layers=1_2025-06-07_15-35-08/checkpoint_000001)\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:37:07 [INFO]: Saved the model to /tmp/tmps0fl8nxv/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00004_4_d_ffn=64,d_model=28,dropout=0.1000,lr=0.0104,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000001)\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 5 RUNNING\n","Current time: 2025-06-07 15:37:09. Total running time: 2min 3s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7877548809878415 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status       n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   RUNNING             1       256           2          56         0.1   0.000457075        1            62.0513    0.561185    0.255137      0.260766     0.363729 |\n","| train_pypots_model_fce98_00001   RUNNING             1        32           2          56         0.2   0.0260515          2            98.4177    0.0278643   0.0090363     0.00464405   0.166667 |\n","| train_pypots_model_fce98_00002   RUNNING             1       128           1          14         0.1   0.00697881         2            92.2728    0.0149205   0.00586469    0.00485019   0.166644 |\n","| train_pypots_model_fce98_00003   RUNNING             2        64           1          14         0.3   0.01154            1            61.7643    0.787755    0.299129      0.337439     0.31947  |\n","| train_pypots_model_fce98_00004   RUNNING             2        64           1          28         0.1   0.0103761          2           101.533     0.0816161   0.0314057     0.14134      0.178486 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:37:12 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4323, validation CrossEntropy: 1.3692\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:37:12 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:37:17 [INFO]: Saved the model to /tmp/tmpaaner_o5/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00000_0_d_ffn=256,d_model=56,dropout=0.1000,lr=0.0005,n_heads=2,n_layers=1_2025-06-07_15-35-07/checkpoint_000001)\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:37:19 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.2989, validation CrossEntropy: 1.3098\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:37:19 [INFO]: Finished training. The best model is from epoch#1.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:37:22 [INFO]: Saved the model to /tmp/tmprzjy_ndp/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000001)\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:37:27 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.2048, validation CrossEntropy: 1.0930\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:37:27 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:37:32 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3410, validation CrossEntropy: 1.2746\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:37:32 [INFO]: Finished training. The best model is from epoch#1.\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 5 RUNNING\n","Current time: 2025-06-07 15:37:40. Total running time: 2min 33s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7761650735194563 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status       n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   RUNNING             1       256           2          56         0.1   0.000457075        2           110.641     0.116575    0.0876628     0.198378     0.198693 |\n","| train_pypots_model_fce98_00001   RUNNING             1        32           2          56         0.2   0.0260515          2            98.4177    0.0278643   0.0090363     0.00464405   0.166667 |\n","| train_pypots_model_fce98_00002   RUNNING             1       128           1          14         0.1   0.00697881         2            92.2728    0.0149205   0.00586469    0.00485019   0.166644 |\n","| train_pypots_model_fce98_00003   RUNNING             2        64           1          14         0.3   0.01154            2           115.574     0.776165    0.411257      0.401174     0.446053 |\n","| train_pypots_model_fce98_00004   RUNNING             2        64           1          28         0.1   0.0103761          2           101.533     0.0816161   0.0314057     0.14134      0.178486 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67622)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m 2025-06-07 15:37:51 [INFO]: Saved the model to /tmp/tmpvkrx028_/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00001_1_d_ffn=32,d_model=56,dropout=0.2000,lr=0.0261,n_heads=2,n_layers=1_2025-06-07_15-35-08/checkpoint_000002)\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:37:58 [INFO]: Saved the model to /tmp/tmp8g3xufzi/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000002)\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:38:02 [INFO]: Saved the model to /tmp/tmpgysp9zz8/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00004_4_d_ffn=64,d_model=28,dropout=0.1000,lr=0.0104,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000002)\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m 2025-06-07 15:38:07 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3973, validation CrossEntropy: 1.2347\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m 2025-06-07 15:38:07 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:38:03 [INFO]: Saved the model to /tmp/tmphh5ldzb7/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67625)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00000_0_d_ffn=256,d_model=56,dropout=0.1000,lr=0.0005,n_heads=2,n_layers=1_2025-06-07_15-35-07/checkpoint_000002)\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 5 RUNNING\n","Current time: 2025-06-07 15:38:10. Total running time: 3min 3s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7761650735194563 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status       n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy          f1     precision     recall |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   RUNNING             1       256           2          56         0.1   0.000457075        3            157.329    0.0292995   0.0496456    0.196112     0.177244 |\n","| train_pypots_model_fce98_00001   RUNNING             1        32           2          56         0.2   0.0260515          3            145.179    0.0278643   0.0090363    0.00464405   0.166667 |\n","| train_pypots_model_fce98_00002   RUNNING             1       128           1          14         0.1   0.00697881         3            151.521    0.0249939   0.0190859    0.0139234    0.181822 |\n","| train_pypots_model_fce98_00003   RUNNING             2        64           1          14         0.3   0.01154            2            115.574    0.776165    0.411257     0.401174     0.446053 |\n","| train_pypots_model_fce98_00004   RUNNING             2        64           1          28         0.1   0.0103761          3            155.758    0.230171    0.0704218    0.10254      0.111924 |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:38:11 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3621, validation CrossEntropy: 1.3237\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:38:11 [INFO]: Finished training. The best model is from epoch#1.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:38:13 [INFO]: Saved the model to /tmp/tmp5m2yylk8/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000002)\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:38:26 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3369, validation CrossEntropy: 1.1112\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:38:26 [INFO]: Finished training. The best model is from epoch#1.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 5 RUNNING\n","Current time: 2025-06-07 15:38:40. Total running time: 3min 33s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7998862682444691 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status       n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy          f1     precision     recall |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   RUNNING             1       256           2          56         0.1   0.000457075        3            157.329    0.0292995   0.0496456    0.196112     0.177244 |\n","| train_pypots_model_fce98_00001   RUNNING             1        32           2          56         0.2   0.0260515          3            145.179    0.0278643   0.0090363    0.00464405   0.166667 |\n","| train_pypots_model_fce98_00002   RUNNING             1       128           1          14         0.1   0.00697881         3            151.521    0.0249939   0.0190859    0.0139234    0.181822 |\n","| train_pypots_model_fce98_00003   RUNNING             2        64           1          14         0.3   0.01154            3            166.595    0.799886    0.388734     0.430676     0.389651 |\n","| train_pypots_model_fce98_00004   RUNNING             2        64           1          28         0.1   0.0103761          3            155.758    0.230171    0.0704218    0.10254      0.111924 |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:38:43 [INFO]: Saved the model to /tmp/tmpsh1zd97m/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000003)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_pypots_model_fce98_00004 completed after 4 iterations at 2025-06-07 15:38:46. Total running time: 3min 39s\n","+-------------------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00004 result                       |\n","+-------------------------------------------------------------------+\n","| checkpoint_dir_name                             checkpoint_000003 |\n","| time_this_iter_s                                         44.08036 |\n","| time_total_s                                            199.83787 |\n","| training_iteration                                              4 |\n","| accuracy                                                  0.20618 |\n","| f1                                                        0.08474 |\n","| precision                                                 0.16592 |\n","| recall                                                    0.16742 |\n","+-------------------------------------------------------------------+\n","\n","Trial train_pypots_model_fce98_00001 completed after 4 iterations at 2025-06-07 15:38:46. Total running time: 3min 39s\n","+-------------------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00001 result                       |\n","+-------------------------------------------------------------------+\n","| checkpoint_dir_name                             checkpoint_000003 |\n","| time_this_iter_s                                         55.01863 |\n","| time_total_s                                            200.19755 |\n","| training_iteration                                              4 |\n","| accuracy                                                  0.02786 |\n","| f1                                                        0.00904 |\n","| precision                                                 0.00464 |\n","| recall                                                    0.16667 |\n","+-------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67622)\u001b[0m 2025-06-07 15:38:46 [INFO]: Saved the model to /tmp/tmpnbez_uqy/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:38:51 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4078, validation CrossEntropy: 1.4070\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:38:51 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67626)\u001b[0m 2025-06-07 15:38:46 [INFO]: Saved the model to /tmp/tmpd4hqx1rt/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67622)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00001_1_d_ffn=32,d_model=56,dropout=0.2000,lr=0.0261,n_heads=2,n_layers=1_2025-06-07_15-35-08/checkpoint_000003)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_pypots_model_fce98_00000 completed after 4 iterations at 2025-06-07 15:38:54. Total running time: 3min 48s\n","+-------------------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00000 result                       |\n","+-------------------------------------------------------------------+\n","| checkpoint_dir_name                             checkpoint_000003 |\n","| time_this_iter_s                                         50.86583 |\n","| time_total_s                                            208.19517 |\n","| training_iteration                                              4 |\n","| accuracy                                                  0.02881 |\n","| f1                                                        0.06739 |\n","| precision                                                 0.20985 |\n","| recall                                                    0.18241 |\n","+-------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67625)\u001b[0m 2025-06-07 15:38:54 [INFO]: Saved the model to /tmp/tmp2824cdx9/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000003)\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:39:06 [INFO]: Saved the model to /tmp/tmpnji0opgv/checkpoint.pypots\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 3 TERMINATED | 2 RUNNING\n","Current time: 2025-06-07 15:39:10. Total running time: 4min 3s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7018332475832002 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00002   RUNNING               1       128           1          14         0.1   0.00697881         4            196.742    0.467546    0.155593      0.197131     0.207945 |\n","| train_pypots_model_fce98_00003   RUNNING               2        64           1          14         0.3   0.01154            4            219.811    0.701833    0.409748      0.400018     0.475903 |\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:39:14 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3006, validation CrossEntropy: 1.1491\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:39:14 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:39:22 [INFO]: Saved the model to /tmp/tmpe181ntmp/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000004)\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:39:30 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4048, validation CrossEntropy: 1.4704\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:39:30 [INFO]: Finished training. The best model is from epoch#1.\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 2 RUNNING\n","Current time: 2025-06-07 15:39:40. Total running time: 4min 33s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00002 with accuracy=0.7204365133093233 and params={'n_layers': 1, 'd_ffn': 128, 'n_heads': 1, 'd_model': 14, 'dropout': 0.1}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00002   RUNNING               1       128           1          14         0.1   0.00697881         5            235.281    0.720437    0.179651      0.18347      0.189209 |\n","| train_pypots_model_fce98_00003   RUNNING               2        64           1          14         0.3   0.01154            4            219.811    0.701833    0.409748      0.400018     0.475903 |\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:39:44 [INFO]: Saved the model to /tmp/tmpgzztj_tt/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000004)\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:39:52 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4560, validation CrossEntropy: 1.2668\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:39:52 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:39:59 [INFO]: Saved the model to /tmp/tmpqhf6ah85/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000005)\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:40:07 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3983, validation CrossEntropy: 1.3925\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:40:07 [INFO]: Finished training. The best model is from epoch#1.\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 2 RUNNING\n","Current time: 2025-06-07 15:40:10. Total running time: 5min 3s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7719407511711663 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00002   RUNNING               1       128           1          14         0.1   0.00697881         6            272.838    0.752769    0.154382      0.177924     0.170706 |\n","| train_pypots_model_fce98_00003   RUNNING               2        64           1          14         0.3   0.01154            5            257.888    0.771941    0.415261      0.402818     0.467927 |\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:40:22 [INFO]: Saved the model to /tmp/tmpjqom19d8/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000005)\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:40:31 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3790, validation CrossEntropy: 1.2503\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:40:31 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:40:38 [INFO]: Saved the model to /tmp/tmp3v36qnnh/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000006)\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 2 RUNNING\n","Current time: 2025-06-07 15:40:40. Total running time: 5min 33s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7806060277830431 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00002   RUNNING               1       128           1          14         0.1   0.00697881         7            311.24     0.3012      0.109983      0.270576     0.169718 |\n","| train_pypots_model_fce98_00003   RUNNING               2        64           1          14         0.3   0.01154            6            296.297    0.780606    0.305389      0.35941      0.2925   |\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:40:46 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4021, validation CrossEntropy: 1.4347\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:40:46 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:41:00 [INFO]: Saved the model to /tmp/tmpkh3jhgde/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000006)\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:41:09 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3838, validation CrossEntropy: 1.2119\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:41:09 [INFO]: Finished training. The best model is from epoch#1.\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 2 RUNNING\n","Current time: 2025-06-07 15:41:10. Total running time: 6min 3s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.5637845595602372 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00002   RUNNING               1       128           1          14         0.1   0.00697881         7            311.24     0.3012      0.109983      0.270576     0.169718 |\n","| train_pypots_model_fce98_00003   RUNNING               2        64           1          14         0.3   0.01154            7            334.335    0.563785    0.336889      0.370982     0.367122 |\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:41:17 [INFO]: Saved the model to /tmp/tmp4ajq1h0m/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000007)\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:41:25 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3855, validation CrossEntropy: 1.3700\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:41:25 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:41:40 [INFO]: Saved the model to /tmp/tmpju5g46us/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000007)\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 2 RUNNING\n","Current time: 2025-06-07 15:41:40. Total running time: 6min 33s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.760107232798072 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00002   RUNNING               1       128           1          14         0.1   0.00697881         8            350.313    0.235019    0.0913505     0.386554     0.174659 |\n","| train_pypots_model_fce98_00003   RUNNING               2        64           1          14         0.3   0.01154            8            373.692    0.760107    0.363453      0.357696     0.393619 |\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:41:48 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3570, validation CrossEntropy: 1.1858\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:41:48 [INFO]: Finished training. The best model is from epoch#1.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:41:55 [INFO]: Saved the model to /tmp/tmpkw3ju68u/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000008)\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:42:03 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3716, validation CrossEntropy: 1.4091\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:42:03 [INFO]: Finished training. The best model is from epoch#1.\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 2 RUNNING\n","Current time: 2025-06-07 15:42:10. Total running time: 7min 3s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.760107232798072 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00002   RUNNING               1       128           1          14         0.1   0.00697881         9            388.291    0.748707    0.165655      0.242148     0.176505 |\n","| train_pypots_model_fce98_00003   RUNNING               2        64           1          14         0.3   0.01154            8            373.692    0.760107    0.363453      0.357696     0.393619 |\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67621)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:42:18 [INFO]: Saved the model to /tmp/tmpgxm8bmnq/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00003_3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2_2025-06-07_15-35-08/checkpoint_000008)\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:42:26 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.3578, validation CrossEntropy: 1.1695\n","\u001b[36m(train_pypots_model pid=67621)\u001b[0m 2025-06-07 15:42:26 [INFO]: Finished training. The best model is from epoch#1.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_pypots_model_fce98_00002 completed after 10 iterations at 2025-06-07 15:42:33. Total running time: 7min 26s\n","+-------------------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00002 result                       |\n","+-------------------------------------------------------------------+\n","| checkpoint_dir_name                             checkpoint_000009 |\n","| time_this_iter_s                                         37.94453 |\n","| time_total_s                                            426.23506 |\n","| training_iteration                                             10 |\n","| accuracy                                                  0.75491 |\n","| f1                                                        0.15168 |\n","| precision                                                 0.17144 |\n","| recall                                                    0.16971 |\n","+-------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_pypots_model pid=67624)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m 2025-06-07 15:42:33 [INFO]: Saved the model to /tmp/tmpw1zgc1c7/checkpoint.pypots\n","\u001b[36m(train_pypots_model pid=67624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_pypots_model_2025-06-07_15-35-02/train_pypots_model_fce98_00002_2_d_ffn=128,d_model=14,dropout=0.1000,lr=0.0070,n_heads=1,n_layers=1_2025-06-07_15-35-08/checkpoint_000009)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 4 TERMINATED | 1 RUNNING\n","Current time: 2025-06-07 15:42:40. Total running time: 7min 33s\n","Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7795770261853827 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00003   RUNNING               2        64           1          14         0.3   0.01154            9            411.88     0.779577    0.374929      0.409191     0.38726  |\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00002   TERMINATED            1       128           1          14         0.1   0.00697881        10            426.235    0.754908    0.151677      0.171438     0.169711 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-07 15:42:55,884\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_pypots_model_2025-06-07_15-35-02' in 0.0042s.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_pypots_model_fce98_00003 completed after 10 iterations at 2025-06-07 15:42:55. Total running time: 7min 49s\n","+-------------------------------------------------------------------+\n","| Trial train_pypots_model_fce98_00003 result                       |\n","+-------------------------------------------------------------------+\n","| checkpoint_dir_name                             checkpoint_000009 |\n","| time_this_iter_s                                          37.3716 |\n","| time_total_s                                            449.25183 |\n","| training_iteration                                             10 |\n","| accuracy                                                  0.77175 |\n","| f1                                                        0.38801 |\n","| precision                                                 0.40507 |\n","| recall                                                    0.37911 |\n","+-------------------------------------------------------------------+\n","\n","Trial status: 5 TERMINATED\n","Current time: 2025-06-07 15:42:55. Total running time: 7min 49s\n","Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n","Current best trial: fce98_00003 with accuracy=0.7717511982452815 and params={'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                       status         n_layers     d_ffn     n_heads     d_model     dropout            lr     iter     total time (s)     accuracy           f1     precision     recall |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_pypots_model_fce98_00000   TERMINATED            1       256           2          56         0.1   0.000457075        4            208.195    0.028812    0.0673913     0.20985      0.182411 |\n","| train_pypots_model_fce98_00001   TERMINATED            1        32           2          56         0.2   0.0260515          4            200.198    0.0278643   0.00903702    0.00464442   0.166667 |\n","| train_pypots_model_fce98_00002   TERMINATED            1       128           1          14         0.1   0.00697881        10            426.235    0.754908    0.151677      0.171438     0.169711 |\n","| train_pypots_model_fce98_00003   TERMINATED            2        64           1          14         0.3   0.01154           10            449.252    0.771751    0.388014      0.40507      0.379113 |\n","| train_pypots_model_fce98_00004   TERMINATED            2        64           1          28         0.1   0.0103761          4            199.838    0.206179    0.0847375     0.165917     0.167419 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n","Best params: {'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","accuracy: 0.7718\n","f1: 0.3880\n","precision: 0.4051\n","recall: 0.3791\n","timestamp: 1749310975\n","checkpoint_dir_name: checkpoint_000009\n","should_checkpoint: True\n","done: True\n","training_iteration: 10\n","trial_id: fce98_00003\n","date: 2025-06-07_15-42-55\n","time_this_iter_s: 37.3716\n","time_total_s: 449.2518\n","pid: 67621\n","hostname: 1e219df6e28f\n","node_ip: 172.28.0.12\n","config: {'n_layers': 2, 'd_ffn': 64, 'n_heads': 1, 'd_model': 14, 'dropout': 0.3}\n","time_since_restore: 449.2518\n","iterations_since_restore: 10\n","experiment_tag: 3_d_ffn=64,d_model=14,dropout=0.3000,lr=0.0115,n_heads=1,n_layers=2\n"]}]},{"cell_type":"markdown","source":["## Raindrop"],"metadata":{"id":"BS7-SxVweFi7"},"id":"BS7-SxVweFi7"},{"cell_type":"code","source":["scheduler = ASHAScheduler(\n","    time_attr='training_iteration',\n","    max_t=50,\n","    grace_period=2,\n","    reduction_factor=2\n",")\n","\n","model_base_params={\n","  \"n_steps\": X_train_bal.shape[1],\n","  \"n_features\": X_train_bal.shape[2],\n","  \"n_classes\": len(np.unique(y_train_bal)),\n","  \"batch_size\": 64,\n","  # \"patience\": 6,\n","  \"num_workers\": 0,\n","  \"device\": None,\n","  \"model_saving_strategy\": None,\n","  \"verbose\": True\n","}\n","\n","tuner = tune.Tuner(\n","    tune.with_resources(\n","      tune.with_parameters(\n","          train_pypots_model,\n","          model_cls=Raindrop,\n","          model_base_params=model_base_params,\n","          X_train=X_train_bal,\n","          y_train=y_train_bal,\n","          X_val=X_val_bal,\n","          y_val=y_val_bal,\n","      ),\n","      resources={\"cpu\": 1}\n","    ),\n","    param_space={\n","        \"n_layers\": tune.grid_search([1, 2]),\n","        \"d_ffn\": tune.grid_search([32, 64, 128, 256]),\n","        \"n_heads\": tune.grid_search([1, 2]),\n","        \"d_model\": tune.grid_search([X_train_bal.shape[2] * i for i in range(1, 4+1)]),\n","        \"dropout\": tune.grid_search([0.1, 0.2, 0.3]),\n","        \"lr\": tune.grid_search([1e-4, 1e-3, 1e-2]),\n","    },\n","    tune_config=tune.TuneConfig(\n","        # num_samples=3,\n","        metric=\"accuracy\",\n","        mode=\"max\",\n","        scheduler=scheduler,\n","    )\n",")\n","\n","results = tuner.fit()\n","best_results = results.get_best_result(metric='accuracy', mode='max')\n","best_metrics = best_results.metrics\n","print(f\"Best params: {best_results.config}\")\n","for k, v in best_metrics.items():\n","  if isinstance(v, float):\n","    print(f\"{k}: {v:.4f}\")\n","  else:\n","    print(f\"{k}: {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1WQQq8yl5MoY047jpaSYWnH-6LHI_fddc"},"id":"bKOOoxrDCS-X","executionInfo":{"status":"error","timestamp":1749320351731,"user_tz":-120,"elapsed":9305856,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"254a8301-0594-44da-b7df-98c87a653da0"},"id":"bKOOoxrDCS-X","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["scheduler = ASHAScheduler(\n","    time_attr='training_iteration',\n","    max_t=10,\n","    grace_period=1,\n","    reduction_factor=3\n",")\n","\n","model_base_params={\n","  \"n_steps\": X_train_bal.shape[1],\n","  \"n_features\": X_train_bal.shape[2],\n","  \"n_classes\": len(np.unique(y_train_bal)),\n","  \"batch_size\": 64,\n","  # \"patience\": 6,\n","  \"num_workers\": 0,\n","  \"device\": None,\n","  \"model_saving_strategy\": None,\n","  \"verbose\": True\n","}\n","\n","tuner = tune.Tuner(\n","    tune.with_resources(\n","      tune.with_parameters(\n","          train_pypots_model,\n","          model_cls=Raindrop,\n","          model_base_params=model_base_params,\n","          X_train=X_train_bal,\n","          y_train=y_train_bal,\n","          X_val=X_val_bal,\n","          y_val=y_val_bal,\n","      ),\n","      resources={\"cpu\": 1}\n","    ),\n","    param_space={\n","        \"n_layers\": tune.grid_search([1, 2]),\n","        \"d_ffn\": tune.grid_search([32, 64, 128, 256]),\n","        \"n_heads\": tune.grid_search([1, 2]),\n","        \"d_model\": tune.grid_search([X_train_bal.shape[2] * i for i in range(1, 4+1)]),\n","        \"dropout\": tune.grid_search([0.1, 0.2, 0.3]),\n","        \"lr\": tune.grid_search([1e-4, 1e-3, 1e-2]),\n","    },\n","    tune_config=tune.TuneConfig(\n","        # num_samples=3,\n","        metric=\"f1\",\n","        mode=\"max\",\n","        scheduler=scheduler,\n","    )\n",")\n","\n","results = tuner.fit()\n","best_results = results.get_best_result(metric='f1', mode='max')\n","best_metrics = best_results.metrics\n","print(f\"Best params: {best_results.config}\")\n","for k, v in best_metrics.items():\n","  if isinstance(v, float):\n","    print(f\"{k}: {v:.4f}\")\n","  else:\n","    print(f\"{k}: {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1uIYK94iiujHvQT_eNZ1dJpxd_Rrvfzkc"},"id":"iXN7p3aLnoNK","executionInfo":{"status":"ok","timestamp":1749336271375,"user_tz":-120,"elapsed":15206015,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"7601d126-7bc3-443f-9476-6aa25b3586d1"},"id":"iXN7p3aLnoNK","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["best_results.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVhdYBrplHoX","executionInfo":{"status":"ok","timestamp":1749336497717,"user_tz":-120,"elapsed":22,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"6173809f-04d6-4072-9749-72b7b25c4f10"},"id":"VVhdYBrplHoX","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_layers': 2, 'd_ffn': 256, 'n_heads': 2, 'd_model': 56, 'dropout': 0.3}"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["best_results = results.get_best_result(metric='f1', mode='max')\n","config = best_results.config\n","\n","run_model(\n","    lambda: Raindrop(\n","        **config,\n","        **model_base_params,\n","        optimizer=Adam(lr=0.001),\n","        epochs=50\n","    ),\n","    f\"Raindrop\",\n","    X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwfDg9OpeN9K","executionInfo":{"status":"ok","timestamp":1749339088455,"user_tz":-120,"elapsed":2525195,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"4ae2337f-8651-44a7-afff-4faaadee4630"},"id":"lwfDg9OpeN9K","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 22:49:23 [INFO]: No given device, using default device: cpu\n","2025-06-07 22:49:23 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n","2025-06-07 22:49:23 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 22:49:23 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 22:49:24 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 22:49:37 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5625, validation CrossEntropy: 1.2152\n","2025-06-07 22:49:46 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.3501, validation CrossEntropy: 1.1487\n","2025-06-07 22:49:56 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.2641, validation CrossEntropy: 1.1292\n","2025-06-07 22:50:05 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2231, validation CrossEntropy: 1.1269\n","2025-06-07 22:50:15 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.2082, validation CrossEntropy: 1.0969\n","2025-06-07 22:50:25 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1666, validation CrossEntropy: 1.0689\n","2025-06-07 22:50:34 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1453, validation CrossEntropy: 1.1148\n","2025-06-07 22:50:44 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.1555, validation CrossEntropy: 1.1019\n","2025-06-07 22:51:01 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1305, validation CrossEntropy: 1.1029\n","2025-06-07 22:51:19 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.1155, validation CrossEntropy: 1.2195\n","2025-06-07 22:51:29 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0721, validation CrossEntropy: 1.0617\n","2025-06-07 22:51:39 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0325, validation CrossEntropy: 1.0473\n","2025-06-07 22:51:48 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0348, validation CrossEntropy: 1.1081\n","2025-06-07 22:51:58 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0326, validation CrossEntropy: 1.0291\n","2025-06-07 22:52:07 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0021, validation CrossEntropy: 0.9877\n","2025-06-07 22:52:17 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0037, validation CrossEntropy: 1.0793\n","2025-06-07 22:52:27 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0067, validation CrossEntropy: 1.0878\n","2025-06-07 22:52:37 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9909, validation CrossEntropy: 0.9639\n","2025-06-07 22:52:46 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9906, validation CrossEntropy: 1.1738\n","2025-06-07 22:52:56 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9797, validation CrossEntropy: 0.9973\n","2025-06-07 22:53:06 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9811, validation CrossEntropy: 1.1592\n","2025-06-07 22:53:15 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9783, validation CrossEntropy: 1.0080\n","2025-06-07 22:53:25 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9736, validation CrossEntropy: 1.0717\n","2025-06-07 22:53:35 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9642, validation CrossEntropy: 1.1082\n","2025-06-07 22:53:44 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.9610, validation CrossEntropy: 1.0789\n","2025-06-07 22:53:54 [INFO]: Epoch 026 - training loss (CrossEntropy): 0.9530, validation CrossEntropy: 1.0450\n","2025-06-07 22:54:04 [INFO]: Epoch 027 - training loss (CrossEntropy): 0.9641, validation CrossEntropy: 1.1232\n","2025-06-07 22:54:13 [INFO]: Epoch 028 - training loss (CrossEntropy): 0.9564, validation CrossEntropy: 1.1175\n","2025-06-07 22:54:23 [INFO]: Epoch 029 - training loss (CrossEntropy): 0.9580, validation CrossEntropy: 0.9825\n","2025-06-07 22:54:33 [INFO]: Epoch 030 - training loss (CrossEntropy): 0.9528, validation CrossEntropy: 1.0079\n","2025-06-07 22:54:42 [INFO]: Epoch 031 - training loss (CrossEntropy): 0.9462, validation CrossEntropy: 1.0662\n","2025-06-07 22:54:52 [INFO]: Epoch 032 - training loss (CrossEntropy): 0.9494, validation CrossEntropy: 1.0754\n","2025-06-07 22:55:01 [INFO]: Epoch 033 - training loss (CrossEntropy): 0.9459, validation CrossEntropy: 1.0565\n","2025-06-07 22:55:11 [INFO]: Epoch 034 - training loss (CrossEntropy): 0.9430, validation CrossEntropy: 1.1611\n","2025-06-07 22:55:21 [INFO]: Epoch 035 - training loss (CrossEntropy): 0.9386, validation CrossEntropy: 1.2610\n","2025-06-07 22:55:30 [INFO]: Epoch 036 - training loss (CrossEntropy): 0.9367, validation CrossEntropy: 1.1818\n","2025-06-07 22:55:40 [INFO]: Epoch 037 - training loss (CrossEntropy): 0.9479, validation CrossEntropy: 1.0712\n","2025-06-07 22:55:49 [INFO]: Epoch 038 - training loss (CrossEntropy): 0.9299, validation CrossEntropy: 1.2392\n","2025-06-07 22:55:59 [INFO]: Epoch 039 - training loss (CrossEntropy): 0.9262, validation CrossEntropy: 1.0546\n","2025-06-07 22:56:09 [INFO]: Epoch 040 - training loss (CrossEntropy): 0.9436, validation CrossEntropy: 1.1095\n","2025-06-07 22:56:18 [INFO]: Epoch 041 - training loss (CrossEntropy): 0.9264, validation CrossEntropy: 0.9878\n","2025-06-07 22:56:28 [INFO]: Epoch 042 - training loss (CrossEntropy): 0.9247, validation CrossEntropy: 1.3057\n","2025-06-07 22:56:38 [INFO]: Epoch 043 - training loss (CrossEntropy): 0.9267, validation CrossEntropy: 1.0555\n","2025-06-07 22:56:47 [INFO]: Epoch 044 - training loss (CrossEntropy): 0.9236, validation CrossEntropy: 1.0809\n","2025-06-07 22:56:57 [INFO]: Epoch 045 - training loss (CrossEntropy): 0.9161, validation CrossEntropy: 1.1522\n","2025-06-07 22:57:07 [INFO]: Epoch 046 - training loss (CrossEntropy): 0.9172, validation CrossEntropy: 1.1291\n","2025-06-07 22:57:16 [INFO]: Epoch 047 - training loss (CrossEntropy): 0.9453, validation CrossEntropy: 0.9589\n","2025-06-07 22:57:26 [INFO]: Epoch 048 - training loss (CrossEntropy): 0.9075, validation CrossEntropy: 1.0730\n","2025-06-07 22:57:35 [INFO]: Epoch 049 - training loss (CrossEntropy): 0.9210, validation CrossEntropy: 1.0872\n","2025-06-07 22:57:45 [INFO]: Epoch 050 - training loss (CrossEntropy): 0.9087, validation CrossEntropy: 1.1078\n","2025-06-07 22:57:45 [INFO]: Finished training. The best model is from epoch#47.\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 22:57:49 [INFO]: No given device, using default device: cpu\n","2025-06-07 22:57:49 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n","2025-06-07 22:57:49 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 22:57:49 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 22:57:49 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 22:58:01 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5734, validation CrossEntropy: 1.2402\n","2025-06-07 22:58:10 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.3562, validation CrossEntropy: 1.1445\n","2025-06-07 22:58:19 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.2888, validation CrossEntropy: 1.1256\n","2025-06-07 22:58:29 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2478, validation CrossEntropy: 1.0867\n","2025-06-07 22:58:39 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.2030, validation CrossEntropy: 1.1125\n","2025-06-07 22:58:48 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1465, validation CrossEntropy: 1.0559\n","2025-06-07 22:58:58 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1066, validation CrossEntropy: 1.0237\n","2025-06-07 22:59:07 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0709, validation CrossEntropy: 1.0258\n","2025-06-07 22:59:17 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0656, validation CrossEntropy: 1.1511\n","2025-06-07 22:59:27 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0532, validation CrossEntropy: 1.0617\n","2025-06-07 22:59:37 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0372, validation CrossEntropy: 1.0059\n","2025-06-07 22:59:46 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0182, validation CrossEntropy: 1.0433\n","2025-06-07 22:59:56 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0171, validation CrossEntropy: 1.0443\n","2025-06-07 23:00:06 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0227, validation CrossEntropy: 0.9840\n","2025-06-07 23:00:16 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0036, validation CrossEntropy: 1.0741\n","2025-06-07 23:00:25 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0093, validation CrossEntropy: 1.1009\n","2025-06-07 23:00:35 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9843, validation CrossEntropy: 0.9935\n","2025-06-07 23:00:44 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9868, validation CrossEntropy: 0.9688\n","2025-06-07 23:00:54 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0083, validation CrossEntropy: 1.2073\n","2025-06-07 23:01:04 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9793, validation CrossEntropy: 1.0943\n","2025-06-07 23:01:14 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9741, validation CrossEntropy: 1.0920\n","2025-06-07 23:01:24 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9752, validation CrossEntropy: 1.0239\n","2025-06-07 23:01:33 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9556, validation CrossEntropy: 1.2391\n","2025-06-07 23:01:43 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9633, validation CrossEntropy: 1.0798\n","2025-06-07 23:01:52 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.9532, validation CrossEntropy: 1.1513\n","2025-06-07 23:02:02 [INFO]: Epoch 026 - training loss (CrossEntropy): 0.9526, validation CrossEntropy: 1.0297\n","2025-06-07 23:02:11 [INFO]: Epoch 027 - training loss (CrossEntropy): 0.9521, validation CrossEntropy: 1.1080\n","2025-06-07 23:02:21 [INFO]: Epoch 028 - training loss (CrossEntropy): 0.9413, validation CrossEntropy: 1.1659\n","2025-06-07 23:02:31 [INFO]: Epoch 029 - training loss (CrossEntropy): 0.9323, validation CrossEntropy: 1.1167\n","2025-06-07 23:02:40 [INFO]: Epoch 030 - training loss (CrossEntropy): 0.9322, validation CrossEntropy: 1.1558\n","2025-06-07 23:02:50 [INFO]: Epoch 031 - training loss (CrossEntropy): 0.9323, validation CrossEntropy: 1.2182\n","2025-06-07 23:03:00 [INFO]: Epoch 032 - training loss (CrossEntropy): 0.9375, validation CrossEntropy: 1.2445\n","2025-06-07 23:03:10 [INFO]: Epoch 033 - training loss (CrossEntropy): 0.9373, validation CrossEntropy: 1.1046\n","2025-06-07 23:03:19 [INFO]: Epoch 034 - training loss (CrossEntropy): 0.9277, validation CrossEntropy: 1.2673\n","2025-06-07 23:03:29 [INFO]: Epoch 035 - training loss (CrossEntropy): 0.9230, validation CrossEntropy: 1.0619\n","2025-06-07 23:03:38 [INFO]: Epoch 036 - training loss (CrossEntropy): 0.9231, validation CrossEntropy: 1.0444\n","2025-06-07 23:03:48 [INFO]: Epoch 037 - training loss (CrossEntropy): 0.9191, validation CrossEntropy: 1.0961\n","2025-06-07 23:03:58 [INFO]: Epoch 038 - training loss (CrossEntropy): 0.9138, validation CrossEntropy: 1.1809\n","2025-06-07 23:04:07 [INFO]: Epoch 039 - training loss (CrossEntropy): 0.9195, validation CrossEntropy: 1.1702\n","2025-06-07 23:04:17 [INFO]: Epoch 040 - training loss (CrossEntropy): 0.9090, validation CrossEntropy: 1.2102\n","2025-06-07 23:04:26 [INFO]: Epoch 041 - training loss (CrossEntropy): 0.9028, validation CrossEntropy: 1.2144\n","2025-06-07 23:04:36 [INFO]: Epoch 042 - training loss (CrossEntropy): 0.9014, validation CrossEntropy: 1.1515\n","2025-06-07 23:04:45 [INFO]: Epoch 043 - training loss (CrossEntropy): 0.9157, validation CrossEntropy: 1.1879\n","2025-06-07 23:04:55 [INFO]: Epoch 044 - training loss (CrossEntropy): 0.9071, validation CrossEntropy: 1.0708\n","2025-06-07 23:05:05 [INFO]: Epoch 045 - training loss (CrossEntropy): 0.9096, validation CrossEntropy: 1.0545\n","2025-06-07 23:05:14 [INFO]: Epoch 046 - training loss (CrossEntropy): 0.8984, validation CrossEntropy: 1.0635\n","2025-06-07 23:05:24 [INFO]: Epoch 047 - training loss (CrossEntropy): 0.8978, validation CrossEntropy: 1.1543\n","2025-06-07 23:05:33 [INFO]: Epoch 048 - training loss (CrossEntropy): 0.8897, validation CrossEntropy: 1.2512\n","2025-06-07 23:05:43 [INFO]: Epoch 049 - training loss (CrossEntropy): 0.9090, validation CrossEntropy: 1.0606\n","2025-06-07 23:05:52 [INFO]: Epoch 050 - training loss (CrossEntropy): 0.8867, validation CrossEntropy: 1.1080\n","2025-06-07 23:05:52 [INFO]: Finished training. The best model is from epoch#18.\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 23:05:57 [INFO]: No given device, using default device: cpu\n","2025-06-07 23:05:57 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n","2025-06-07 23:05:57 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 23:05:57 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 23:05:57 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 23:06:08 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.6596, validation CrossEntropy: 1.4024\n","2025-06-07 23:06:17 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.4498, validation CrossEntropy: 1.2330\n","2025-06-07 23:06:27 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.3246, validation CrossEntropy: 1.1340\n","2025-06-07 23:06:37 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.3274, validation CrossEntropy: 1.1261\n","2025-06-07 23:06:47 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.2694, validation CrossEntropy: 1.1156\n","2025-06-07 23:06:57 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.2528, validation CrossEntropy: 1.1710\n","2025-06-07 23:07:06 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.2068, validation CrossEntropy: 1.1492\n","2025-06-07 23:07:16 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.2031, validation CrossEntropy: 1.0877\n","2025-06-07 23:07:26 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1672, validation CrossEntropy: 1.0522\n","2025-06-07 23:07:35 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.1715, validation CrossEntropy: 1.0851\n","2025-06-07 23:07:45 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.1461, validation CrossEntropy: 1.0827\n","2025-06-07 23:07:55 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.1196, validation CrossEntropy: 0.9963\n","2025-06-07 23:08:04 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.1412, validation CrossEntropy: 1.0121\n","2025-06-07 23:08:15 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.1110, validation CrossEntropy: 1.0992\n","2025-06-07 23:08:25 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.1149, validation CrossEntropy: 1.0800\n","2025-06-07 23:08:35 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.1082, validation CrossEntropy: 1.0223\n","2025-06-07 23:08:45 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.1099, validation CrossEntropy: 0.9891\n","2025-06-07 23:08:55 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0930, validation CrossEntropy: 1.0972\n","2025-06-07 23:09:06 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0835, validation CrossEntropy: 0.9813\n","2025-06-07 23:09:16 [INFO]: Epoch 020 - training loss (CrossEntropy): 1.0626, validation CrossEntropy: 0.9877\n","2025-06-07 23:09:26 [INFO]: Epoch 021 - training loss (CrossEntropy): 1.0618, validation CrossEntropy: 1.0004\n","2025-06-07 23:09:37 [INFO]: Epoch 022 - training loss (CrossEntropy): 1.0528, validation CrossEntropy: 1.0092\n","2025-06-07 23:09:46 [INFO]: Epoch 023 - training loss (CrossEntropy): 1.2212, validation CrossEntropy: 1.0859\n","2025-06-07 23:09:56 [INFO]: Epoch 024 - training loss (CrossEntropy): 1.1400, validation CrossEntropy: 1.0295\n","2025-06-07 23:10:06 [INFO]: Epoch 025 - training loss (CrossEntropy): 1.0750, validation CrossEntropy: 1.0017\n","2025-06-07 23:10:16 [INFO]: Epoch 026 - training loss (CrossEntropy): 1.0675, validation CrossEntropy: 1.0482\n","2025-06-07 23:10:26 [INFO]: Epoch 027 - training loss (CrossEntropy): 1.0724, validation CrossEntropy: 1.0079\n","2025-06-07 23:10:36 [INFO]: Epoch 028 - training loss (CrossEntropy): 1.0614, validation CrossEntropy: 1.0665\n","2025-06-07 23:10:47 [INFO]: Epoch 029 - training loss (CrossEntropy): 1.0569, validation CrossEntropy: 0.9931\n","2025-06-07 23:10:56 [INFO]: Epoch 030 - training loss (CrossEntropy): 1.0714, validation CrossEntropy: 1.0244\n","2025-06-07 23:11:07 [INFO]: Epoch 031 - training loss (CrossEntropy): 1.0403, validation CrossEntropy: 1.0162\n","2025-06-07 23:11:16 [INFO]: Epoch 032 - training loss (CrossEntropy): 1.0399, validation CrossEntropy: 0.9613\n","2025-06-07 23:11:26 [INFO]: Epoch 033 - training loss (CrossEntropy): 1.0452, validation CrossEntropy: 1.0135\n","2025-06-07 23:11:36 [INFO]: Epoch 034 - training loss (CrossEntropy): 1.0307, validation CrossEntropy: 0.9788\n","2025-06-07 23:11:46 [INFO]: Epoch 035 - training loss (CrossEntropy): 1.0207, validation CrossEntropy: 1.0039\n","2025-06-07 23:11:56 [INFO]: Epoch 036 - training loss (CrossEntropy): 1.0221, validation CrossEntropy: 0.9994\n","2025-06-07 23:12:06 [INFO]: Epoch 037 - training loss (CrossEntropy): 1.0191, validation CrossEntropy: 0.9781\n","2025-06-07 23:12:16 [INFO]: Epoch 038 - training loss (CrossEntropy): 1.0213, validation CrossEntropy: 1.1478\n","2025-06-07 23:12:26 [INFO]: Epoch 039 - training loss (CrossEntropy): 1.0360, validation CrossEntropy: 0.9747\n","2025-06-07 23:12:35 [INFO]: Epoch 040 - training loss (CrossEntropy): 1.0227, validation CrossEntropy: 0.9930\n","2025-06-07 23:12:45 [INFO]: Epoch 041 - training loss (CrossEntropy): 1.0002, validation CrossEntropy: 1.0295\n","2025-06-07 23:12:55 [INFO]: Epoch 042 - training loss (CrossEntropy): 0.9960, validation CrossEntropy: 0.9853\n","2025-06-07 23:13:05 [INFO]: Epoch 043 - training loss (CrossEntropy): 1.0011, validation CrossEntropy: 0.9629\n","2025-06-07 23:13:14 [INFO]: Epoch 044 - training loss (CrossEntropy): 0.9956, validation CrossEntropy: 0.9913\n","2025-06-07 23:13:24 [INFO]: Epoch 045 - training loss (CrossEntropy): 0.9949, validation CrossEntropy: 0.9935\n","2025-06-07 23:13:34 [INFO]: Epoch 046 - training loss (CrossEntropy): 1.0027, validation CrossEntropy: 0.9701\n","2025-06-07 23:13:44 [INFO]: Epoch 047 - training loss (CrossEntropy): 0.9798, validation CrossEntropy: 0.9661\n","2025-06-07 23:13:54 [INFO]: Epoch 048 - training loss (CrossEntropy): 0.9745, validation CrossEntropy: 0.9766\n","2025-06-07 23:14:04 [INFO]: Epoch 049 - training loss (CrossEntropy): 0.9671, validation CrossEntropy: 0.9756\n","2025-06-07 23:14:14 [INFO]: Epoch 050 - training loss (CrossEntropy): 0.9718, validation CrossEntropy: 0.9557\n","2025-06-07 23:14:14 [INFO]: Finished training. The best model is from epoch#50.\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 23:14:18 [INFO]: No given device, using default device: cpu\n","2025-06-07 23:14:18 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n","2025-06-07 23:14:18 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 23:14:18 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 23:14:18 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 23:14:29 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5756, validation CrossEntropy: 1.3328\n","2025-06-07 23:14:39 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.3842, validation CrossEntropy: 1.1884\n","2025-06-07 23:14:49 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.3075, validation CrossEntropy: 1.1162\n","2025-06-07 23:14:59 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2423, validation CrossEntropy: 1.0704\n","2025-06-07 23:15:10 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.2126, validation CrossEntropy: 1.1008\n","2025-06-07 23:15:20 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1963, validation CrossEntropy: 1.1114\n","2025-06-07 23:15:30 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1789, validation CrossEntropy: 1.0706\n","2025-06-07 23:15:40 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.1709, validation CrossEntropy: 1.0449\n","2025-06-07 23:15:50 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1406, validation CrossEntropy: 1.0363\n","2025-06-07 23:16:00 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.1531, validation CrossEntropy: 1.0736\n","2025-06-07 23:16:10 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.1209, validation CrossEntropy: 1.0295\n","2025-06-07 23:16:20 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.1028, validation CrossEntropy: 1.0207\n","2025-06-07 23:16:30 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0887, validation CrossEntropy: 0.9983\n","2025-06-07 23:16:40 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0910, validation CrossEntropy: 1.0425\n","2025-06-07 23:16:49 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.1128, validation CrossEntropy: 1.0445\n","2025-06-07 23:17:00 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.1016, validation CrossEntropy: 1.1087\n","2025-06-07 23:17:10 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0901, validation CrossEntropy: 1.0551\n","2025-06-07 23:17:19 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0791, validation CrossEntropy: 1.0498\n","2025-06-07 23:17:29 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0946, validation CrossEntropy: 1.0209\n","2025-06-07 23:17:39 [INFO]: Epoch 020 - training loss (CrossEntropy): 1.0994, validation CrossEntropy: 1.0221\n","2025-06-07 23:17:48 [INFO]: Epoch 021 - training loss (CrossEntropy): 1.0699, validation CrossEntropy: 1.0100\n","2025-06-07 23:17:58 [INFO]: Epoch 022 - training loss (CrossEntropy): 1.0680, validation CrossEntropy: 1.0475\n","2025-06-07 23:18:08 [INFO]: Epoch 023 - training loss (CrossEntropy): 1.0452, validation CrossEntropy: 1.0075\n","2025-06-07 23:18:17 [INFO]: Epoch 024 - training loss (CrossEntropy): 1.0641, validation CrossEntropy: 1.0177\n","2025-06-07 23:18:27 [INFO]: Epoch 025 - training loss (CrossEntropy): 1.0503, validation CrossEntropy: 0.9893\n","2025-06-07 23:18:36 [INFO]: Epoch 026 - training loss (CrossEntropy): 1.0475, validation CrossEntropy: 0.9584\n","2025-06-07 23:18:46 [INFO]: Epoch 027 - training loss (CrossEntropy): 1.0418, validation CrossEntropy: 1.0138\n","2025-06-07 23:18:55 [INFO]: Epoch 028 - training loss (CrossEntropy): 1.0314, validation CrossEntropy: 0.9657\n","2025-06-07 23:19:05 [INFO]: Epoch 029 - training loss (CrossEntropy): 1.0336, validation CrossEntropy: 0.9916\n","2025-06-07 23:19:15 [INFO]: Epoch 030 - training loss (CrossEntropy): 1.0239, validation CrossEntropy: 0.9839\n","2025-06-07 23:19:24 [INFO]: Epoch 031 - training loss (CrossEntropy): 1.0376, validation CrossEntropy: 0.9612\n","2025-06-07 23:19:34 [INFO]: Epoch 032 - training loss (CrossEntropy): 1.0268, validation CrossEntropy: 1.0258\n","2025-06-07 23:19:43 [INFO]: Epoch 033 - training loss (CrossEntropy): 1.0040, validation CrossEntropy: 0.9864\n","2025-06-07 23:19:53 [INFO]: Epoch 034 - training loss (CrossEntropy): 1.0074, validation CrossEntropy: 0.9695\n","2025-06-07 23:20:04 [INFO]: Epoch 035 - training loss (CrossEntropy): 1.0125, validation CrossEntropy: 1.0177\n","2025-06-07 23:20:14 [INFO]: Epoch 036 - training loss (CrossEntropy): 0.9984, validation CrossEntropy: 0.9476\n","2025-06-07 23:20:24 [INFO]: Epoch 037 - training loss (CrossEntropy): 0.9996, validation CrossEntropy: 0.9375\n","2025-06-07 23:20:34 [INFO]: Epoch 038 - training loss (CrossEntropy): 0.9937, validation CrossEntropy: 0.9774\n","2025-06-07 23:20:44 [INFO]: Epoch 039 - training loss (CrossEntropy): 0.9877, validation CrossEntropy: 0.9805\n","2025-06-07 23:20:54 [INFO]: Epoch 040 - training loss (CrossEntropy): 0.9843, validation CrossEntropy: 1.0248\n","2025-06-07 23:21:05 [INFO]: Epoch 041 - training loss (CrossEntropy): 0.9681, validation CrossEntropy: 0.9791\n","2025-06-07 23:21:15 [INFO]: Epoch 042 - training loss (CrossEntropy): 0.9695, validation CrossEntropy: 0.9553\n","2025-06-07 23:21:25 [INFO]: Epoch 043 - training loss (CrossEntropy): 0.9582, validation CrossEntropy: 1.0267\n","2025-06-07 23:21:36 [INFO]: Epoch 044 - training loss (CrossEntropy): 0.9620, validation CrossEntropy: 1.0281\n","2025-06-07 23:21:46 [INFO]: Epoch 045 - training loss (CrossEntropy): 0.9558, validation CrossEntropy: 0.9751\n","2025-06-07 23:21:57 [INFO]: Epoch 046 - training loss (CrossEntropy): 0.9480, validation CrossEntropy: 1.0863\n","2025-06-07 23:22:08 [INFO]: Epoch 047 - training loss (CrossEntropy): 0.9702, validation CrossEntropy: 0.9717\n","2025-06-07 23:22:19 [INFO]: Epoch 048 - training loss (CrossEntropy): 0.9553, validation CrossEntropy: 1.0052\n","2025-06-07 23:22:29 [INFO]: Epoch 049 - training loss (CrossEntropy): 0.9538, validation CrossEntropy: 0.9636\n","2025-06-07 23:22:40 [INFO]: Epoch 050 - training loss (CrossEntropy): 0.9360, validation CrossEntropy: 1.0546\n","2025-06-07 23:22:40 [INFO]: Finished training. The best model is from epoch#37.\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 23:22:45 [INFO]: No given device, using default device: cpu\n","2025-06-07 23:22:45 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n","2025-06-07 23:22:45 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 23:22:45 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 23:22:45 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 23:22:57 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.6209, validation CrossEntropy: 1.4465\n","2025-06-07 23:23:07 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.4069, validation CrossEntropy: 1.2230\n","2025-06-07 23:23:17 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.3176, validation CrossEntropy: 1.1766\n","2025-06-07 23:23:27 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2643, validation CrossEntropy: 1.0860\n","2025-06-07 23:23:37 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.2342, validation CrossEntropy: 1.0803\n","2025-06-07 23:23:48 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1940, validation CrossEntropy: 1.1223\n","2025-06-07 23:23:59 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1953, validation CrossEntropy: 1.0611\n","2025-06-07 23:24:09 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.1682, validation CrossEntropy: 1.0649\n","2025-06-07 23:24:20 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1408, validation CrossEntropy: 0.9982\n","2025-06-07 23:24:30 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.1434, validation CrossEntropy: 1.0838\n","2025-06-07 23:24:40 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.1412, validation CrossEntropy: 1.0234\n","2025-06-07 23:24:50 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.1313, validation CrossEntropy: 1.0081\n","2025-06-07 23:25:00 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.1037, validation CrossEntropy: 0.9712\n","2025-06-07 23:25:11 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.1035, validation CrossEntropy: 0.9734\n","2025-06-07 23:25:21 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0706, validation CrossEntropy: 0.9859\n","2025-06-07 23:25:31 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0867, validation CrossEntropy: 0.9637\n","2025-06-07 23:25:41 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0709, validation CrossEntropy: 0.9802\n","2025-06-07 23:25:51 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0757, validation CrossEntropy: 0.9654\n","2025-06-07 23:26:01 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0622, validation CrossEntropy: 0.9941\n","2025-06-07 23:26:12 [INFO]: Epoch 020 - training loss (CrossEntropy): 1.0421, validation CrossEntropy: 0.9939\n","2025-06-07 23:26:22 [INFO]: Epoch 021 - training loss (CrossEntropy): 1.0416, validation CrossEntropy: 0.9626\n","2025-06-07 23:26:32 [INFO]: Epoch 022 - training loss (CrossEntropy): 1.0461, validation CrossEntropy: 1.0120\n","2025-06-07 23:26:42 [INFO]: Epoch 023 - training loss (CrossEntropy): 1.0328, validation CrossEntropy: 0.9771\n","2025-06-07 23:26:53 [INFO]: Epoch 024 - training loss (CrossEntropy): 1.0498, validation CrossEntropy: 1.0308\n","2025-06-07 23:27:03 [INFO]: Epoch 025 - training loss (CrossEntropy): 1.0386, validation CrossEntropy: 1.0140\n","2025-06-07 23:27:14 [INFO]: Epoch 026 - training loss (CrossEntropy): 1.0237, validation CrossEntropy: 0.9866\n","2025-06-07 23:27:24 [INFO]: Epoch 027 - training loss (CrossEntropy): 1.0292, validation CrossEntropy: 1.0057\n","2025-06-07 23:27:35 [INFO]: Epoch 028 - training loss (CrossEntropy): 1.0104, validation CrossEntropy: 0.9964\n","2025-06-07 23:27:45 [INFO]: Epoch 029 - training loss (CrossEntropy): 1.0172, validation CrossEntropy: 0.9783\n","2025-06-07 23:27:55 [INFO]: Epoch 030 - training loss (CrossEntropy): 1.0151, validation CrossEntropy: 0.9653\n","2025-06-07 23:28:06 [INFO]: Epoch 031 - training loss (CrossEntropy): 0.9933, validation CrossEntropy: 0.9579\n","2025-06-07 23:28:16 [INFO]: Epoch 032 - training loss (CrossEntropy): 1.0057, validation CrossEntropy: 0.9760\n","2025-06-07 23:28:26 [INFO]: Epoch 033 - training loss (CrossEntropy): 0.9924, validation CrossEntropy: 0.9752\n","2025-06-07 23:28:36 [INFO]: Epoch 034 - training loss (CrossEntropy): 1.0026, validation CrossEntropy: 0.9982\n","2025-06-07 23:28:47 [INFO]: Epoch 035 - training loss (CrossEntropy): 0.9904, validation CrossEntropy: 1.0010\n","2025-06-07 23:28:57 [INFO]: Epoch 036 - training loss (CrossEntropy): 0.9784, validation CrossEntropy: 0.9908\n","2025-06-07 23:29:08 [INFO]: Epoch 037 - training loss (CrossEntropy): 0.9834, validation CrossEntropy: 0.9691\n","2025-06-07 23:29:17 [INFO]: Epoch 038 - training loss (CrossEntropy): 0.9688, validation CrossEntropy: 0.9691\n","2025-06-07 23:29:27 [INFO]: Epoch 039 - training loss (CrossEntropy): 0.9868, validation CrossEntropy: 0.9628\n","2025-06-07 23:29:37 [INFO]: Epoch 040 - training loss (CrossEntropy): 0.9817, validation CrossEntropy: 0.9778\n","2025-06-07 23:29:47 [INFO]: Epoch 041 - training loss (CrossEntropy): 0.9616, validation CrossEntropy: 1.0918\n","2025-06-07 23:29:57 [INFO]: Epoch 042 - training loss (CrossEntropy): 0.9608, validation CrossEntropy: 1.0436\n","2025-06-07 23:30:08 [INFO]: Epoch 043 - training loss (CrossEntropy): 0.9540, validation CrossEntropy: 0.9621\n","2025-06-07 23:30:17 [INFO]: Epoch 044 - training loss (CrossEntropy): 0.9584, validation CrossEntropy: 0.9944\n","2025-06-07 23:30:27 [INFO]: Epoch 045 - training loss (CrossEntropy): 0.9505, validation CrossEntropy: 0.9812\n","2025-06-07 23:30:37 [INFO]: Epoch 046 - training loss (CrossEntropy): 1.0123, validation CrossEntropy: 1.0177\n","2025-06-07 23:30:47 [INFO]: Epoch 047 - training loss (CrossEntropy): 1.0155, validation CrossEntropy: 1.0309\n","2025-06-07 23:30:57 [INFO]: Epoch 048 - training loss (CrossEntropy): 1.0157, validation CrossEntropy: 0.9951\n","2025-06-07 23:31:08 [INFO]: Epoch 049 - training loss (CrossEntropy): 1.0167, validation CrossEntropy: 1.0813\n","2025-06-07 23:31:18 [INFO]: Epoch 050 - training loss (CrossEntropy): 1.0052, validation CrossEntropy: 1.0393\n","2025-06-07 23:31:18 [INFO]: Finished training. The best model is from epoch#31.\n"]},{"output_type":"stream","name":"stdout","text":["Raindrop & 0.2753 ± 0.1339 & 0.1388 ± 0.1627 0.1224 ± 0.1752 0.2286 ± 0.1239 \\\n","[500.8116250038147, 483.0869686603546, 496.6789710521698, 501.9397792816162, 512.9421997070312]\n","499.0919 ± 9.6424\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["n_layers=2\n","d_ffn=256\n","n_heads=2\n","dropout=0.3\n","run_model(\n","  lambda: Raindrop(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    n_layers=2,\n","    d_model=X_train_bal.shape[2] * 4,\n","    d_ffn=256,\n","    n_heads=2,\n","    dropout=0.3,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/raindrop',\n","    model_saving_strategy='best'\n","  ),\n","  f\"Raindrop({n_layers=}, {d_ffn=}, {n_heads=}, {dropout=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rM0EFMOkeGb_","executionInfo":{"status":"ok","timestamp":1749296495562,"user_tz":-120,"elapsed":978640,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"a96557f4-f915-4c5c-c29a-4525a34f16d1"},"id":"rM0EFMOkeGb_","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 11:25:16 [INFO]: No given device, using default device: cpu\n","2025-06-07 11:25:16 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T112516\n","2025-06-07 11:25:16 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T112516/tensorboard\n","2025-06-07 11:25:16 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 11:25:16 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 11:25:16 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 11:25:27 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.6075, validation CrossEntropy: 1.2813\n","2025-06-07 11:25:37 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.3720, validation CrossEntropy: 1.1904\n","2025-06-07 11:25:46 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.3134, validation CrossEntropy: 1.1948\n","2025-06-07 11:25:55 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2582, validation CrossEntropy: 1.1892\n","2025-06-07 11:26:04 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.2216, validation CrossEntropy: 1.0892\n","2025-06-07 11:26:13 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.2055, validation CrossEntropy: 1.1088\n","2025-06-07 11:26:23 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1696, validation CrossEntropy: 1.1081\n","2025-06-07 11:26:32 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.1131, validation CrossEntropy: 1.0738\n","2025-06-07 11:26:42 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1047, validation CrossEntropy: 1.2439\n","2025-06-07 11:26:51 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0890, validation CrossEntropy: 1.0497\n","2025-06-07 11:27:00 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0651, validation CrossEntropy: 1.0624\n","2025-06-07 11:27:10 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0690, validation CrossEntropy: 1.0519\n","2025-06-07 11:27:19 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0408, validation CrossEntropy: 0.9835\n","2025-06-07 11:27:29 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0393, validation CrossEntropy: 1.0471\n","2025-06-07 11:27:39 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0271, validation CrossEntropy: 0.9981\n","2025-06-07 11:27:48 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0255, validation CrossEntropy: 0.9937\n","2025-06-07 11:27:58 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0079, validation CrossEntropy: 1.0682\n","2025-06-07 11:28:07 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0222, validation CrossEntropy: 1.0757\n","2025-06-07 11:28:17 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0201, validation CrossEntropy: 1.0251\n","2025-06-07 11:28:17 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 11:28:17 [INFO]: Finished training. The best model is from epoch#13.\n","2025-06-07 11:28:17 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T112516/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 11:28:22 [INFO]: No given device, using default device: cpu\n","2025-06-07 11:28:22 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T112822\n","2025-06-07 11:28:22 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T112822/tensorboard\n","2025-06-07 11:28:22 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 11:28:22 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 11:28:22 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 11:28:32 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.6152, validation CrossEntropy: 1.2361\n","2025-06-07 11:28:42 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.3612, validation CrossEntropy: 1.2623\n","2025-06-07 11:28:51 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.2897, validation CrossEntropy: 1.4437\n","2025-06-07 11:29:01 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2307, validation CrossEntropy: 1.1920\n","2025-06-07 11:29:10 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.1961, validation CrossEntropy: 1.4369\n","2025-06-07 11:29:19 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1746, validation CrossEntropy: 1.1092\n","2025-06-07 11:29:29 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1423, validation CrossEntropy: 1.1119\n","2025-06-07 11:29:38 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.1316, validation CrossEntropy: 1.0766\n","2025-06-07 11:29:48 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1158, validation CrossEntropy: 1.2126\n","2025-06-07 11:29:57 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0950, validation CrossEntropy: 1.3388\n","2025-06-07 11:30:07 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.1017, validation CrossEntropy: 1.1479\n","2025-06-07 11:30:16 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0814, validation CrossEntropy: 1.0936\n","2025-06-07 11:30:26 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0811, validation CrossEntropy: 1.3470\n","2025-06-07 11:30:35 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0858, validation CrossEntropy: 1.0545\n","2025-06-07 11:30:44 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0571, validation CrossEntropy: 1.3042\n","2025-06-07 11:30:53 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0665, validation CrossEntropy: 1.2054\n","2025-06-07 11:31:03 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0519, validation CrossEntropy: 1.1502\n","2025-06-07 11:31:12 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0358, validation CrossEntropy: 1.0998\n","2025-06-07 11:31:21 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0375, validation CrossEntropy: 1.1346\n","2025-06-07 11:31:31 [INFO]: Epoch 020 - training loss (CrossEntropy): 1.0297, validation CrossEntropy: 1.0197\n","2025-06-07 11:31:40 [INFO]: Epoch 021 - training loss (CrossEntropy): 1.0307, validation CrossEntropy: 1.2130\n","2025-06-07 11:31:50 [INFO]: Epoch 022 - training loss (CrossEntropy): 1.0234, validation CrossEntropy: 1.0826\n","2025-06-07 11:31:59 [INFO]: Epoch 023 - training loss (CrossEntropy): 1.0278, validation CrossEntropy: 1.1003\n","2025-06-07 11:32:08 [INFO]: Epoch 024 - training loss (CrossEntropy): 1.0179, validation CrossEntropy: 1.0420\n","2025-06-07 11:32:17 [INFO]: Epoch 025 - training loss (CrossEntropy): 1.0108, validation CrossEntropy: 1.1110\n","2025-06-07 11:32:27 [INFO]: Epoch 026 - training loss (CrossEntropy): 1.0173, validation CrossEntropy: 1.1035\n","2025-06-07 11:32:27 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 11:32:27 [INFO]: Finished training. The best model is from epoch#20.\n","2025-06-07 11:32:27 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T112822/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 11:32:31 [INFO]: No given device, using default device: cpu\n","2025-06-07 11:32:31 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113231\n","2025-06-07 11:32:31 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113231/tensorboard\n","2025-06-07 11:32:31 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 11:32:31 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 11:32:31 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 11:32:42 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5610, validation CrossEntropy: 1.2110\n","2025-06-07 11:32:52 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.3213, validation CrossEntropy: 1.2215\n","2025-06-07 11:33:02 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.2526, validation CrossEntropy: 1.1152\n","2025-06-07 11:33:12 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2250, validation CrossEntropy: 1.0815\n","2025-06-07 11:33:22 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.1961, validation CrossEntropy: 1.2283\n","2025-06-07 11:33:32 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1908, validation CrossEntropy: 1.0756\n","2025-06-07 11:33:41 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1586, validation CrossEntropy: 1.0521\n","2025-06-07 11:33:51 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.1339, validation CrossEntropy: 1.0587\n","2025-06-07 11:34:01 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1258, validation CrossEntropy: 1.0315\n","2025-06-07 11:34:10 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0987, validation CrossEntropy: 1.0065\n","2025-06-07 11:34:19 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0913, validation CrossEntropy: 1.0268\n","2025-06-07 11:34:29 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0678, validation CrossEntropy: 1.0020\n","2025-06-07 11:34:38 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0776, validation CrossEntropy: 0.9974\n","2025-06-07 11:34:48 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0476, validation CrossEntropy: 1.0278\n","2025-06-07 11:34:59 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0432, validation CrossEntropy: 1.0263\n","2025-06-07 11:35:08 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0417, validation CrossEntropy: 1.0613\n","2025-06-07 11:35:18 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0314, validation CrossEntropy: 1.0409\n","2025-06-07 11:35:27 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0751, validation CrossEntropy: 1.2127\n","2025-06-07 11:35:37 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0468, validation CrossEntropy: 1.0284\n","2025-06-07 11:35:37 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 11:35:37 [INFO]: Finished training. The best model is from epoch#13.\n","2025-06-07 11:35:37 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113231/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 11:35:41 [INFO]: No given device, using default device: cpu\n","2025-06-07 11:35:41 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113541\n","2025-06-07 11:35:41 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113541/tensorboard\n","2025-06-07 11:35:41 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 11:35:41 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 11:35:41 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 11:35:52 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5574, validation CrossEntropy: 1.2526\n","2025-06-07 11:36:01 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.3556, validation CrossEntropy: 1.0972\n","2025-06-07 11:36:10 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.2747, validation CrossEntropy: 1.1026\n","2025-06-07 11:36:20 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2386, validation CrossEntropy: 1.0592\n","2025-06-07 11:36:29 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.2119, validation CrossEntropy: 1.1261\n","2025-06-07 11:36:39 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1840, validation CrossEntropy: 1.0477\n","2025-06-07 11:36:48 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1679, validation CrossEntropy: 1.0606\n","2025-06-07 11:36:57 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.1670, validation CrossEntropy: 1.0601\n","2025-06-07 11:37:06 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1421, validation CrossEntropy: 1.0829\n","2025-06-07 11:37:16 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.1364, validation CrossEntropy: 1.0400\n","2025-06-07 11:37:25 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.1107, validation CrossEntropy: 1.0173\n","2025-06-07 11:37:34 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.1097, validation CrossEntropy: 1.0319\n","2025-06-07 11:37:44 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.1257, validation CrossEntropy: 1.0374\n","2025-06-07 11:37:53 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.1097, validation CrossEntropy: 1.0261\n","2025-06-07 11:38:02 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0853, validation CrossEntropy: 1.0008\n","2025-06-07 11:38:12 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0742, validation CrossEntropy: 0.9973\n","2025-06-07 11:38:21 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0584, validation CrossEntropy: 1.0445\n","2025-06-07 11:38:30 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0537, validation CrossEntropy: 1.0060\n","2025-06-07 11:38:40 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0465, validation CrossEntropy: 1.0406\n","2025-06-07 11:38:49 [INFO]: Epoch 020 - training loss (CrossEntropy): 1.0452, validation CrossEntropy: 0.9992\n","2025-06-07 11:38:59 [INFO]: Epoch 021 - training loss (CrossEntropy): 1.0161, validation CrossEntropy: 1.0997\n","2025-06-07 11:39:09 [INFO]: Epoch 022 - training loss (CrossEntropy): 1.0353, validation CrossEntropy: 1.0497\n","2025-06-07 11:39:09 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 11:39:09 [INFO]: Finished training. The best model is from epoch#16.\n","2025-06-07 11:39:09 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113541/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 11:39:14 [INFO]: No given device, using default device: cpu\n","2025-06-07 11:39:14 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113914\n","2025-06-07 11:39:14 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113914/tensorboard\n","2025-06-07 11:39:14 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 11:39:14 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 11:39:14 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 11:39:25 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.6038, validation CrossEntropy: 1.3125\n","2025-06-07 11:39:36 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.4147, validation CrossEntropy: 1.5000\n","2025-06-07 11:39:46 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.3173, validation CrossEntropy: 1.1575\n","2025-06-07 11:39:56 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.2541, validation CrossEntropy: 1.1084\n","2025-06-07 11:40:05 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.2476, validation CrossEntropy: 1.0878\n","2025-06-07 11:40:15 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1891, validation CrossEntropy: 1.0885\n","2025-06-07 11:40:25 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.1807, validation CrossEntropy: 1.1491\n","2025-06-07 11:40:35 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.1590, validation CrossEntropy: 1.0315\n","2025-06-07 11:40:44 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.1294, validation CrossEntropy: 1.0571\n","2025-06-07 11:40:54 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.1061, validation CrossEntropy: 1.0741\n","2025-06-07 11:41:03 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0866, validation CrossEntropy: 1.0522\n","2025-06-07 11:41:13 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0859, validation CrossEntropy: 1.0689\n","2025-06-07 11:41:22 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0681, validation CrossEntropy: 1.1247\n","2025-06-07 11:41:31 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0493, validation CrossEntropy: 1.0701\n","2025-06-07 11:41:31 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 11:41:31 [INFO]: Finished training. The best model is from epoch#8.\n","2025-06-07 11:41:31 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T113914/Raindrop.pypots\n"]},{"output_type":"stream","name":"stdout","text":["Raindrop(n_layers=2, d_ffn=256, n_heads=2, dropout=0.3) & 0.2085 ± 0.0003 & 0.0586 ± 0.0022 0.0357 ± 0.0019 0.1669 ± 0.0004 \\\n","[180.5758023262024, 245.0770034790039, 185.40188312530518, 208.2741460800171, 136.50115299224854]\n","191.1660 ± 35.5885\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["n_layers=2\n","d_ffn=256\n","n_heads=2\n","dropout=0.1\n","d_model = X_train_bal.shape[2] * 4\n","run_model(\n","  lambda: Raindrop(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    n_layers=n_layers,\n","    d_model=X_train_bal.shape[2] * 4,\n","    d_ffn=d_ffn,\n","    n_heads=n_heads,\n","    dropout=dropout,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/raindrop',\n","    model_saving_strategy='best'\n","  ),\n","  f\"Raindrop({n_layers=}, {d_ffn=}, {d_model=}, {n_heads=}, {dropout=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acltMKRobE7G","executionInfo":{"status":"ok","timestamp":1749298174800,"user_tz":-120,"elapsed":968061,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"290f4331-5de9-4850-89e9-14952ee188fd"},"id":"acltMKRobE7G","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 11:53:26 [INFO]: No given device, using default device: cpu\n","2025-06-07 11:53:26 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T115326\n","2025-06-07 11:53:26 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T115326/tensorboard\n","2025-06-07 11:53:26 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 11:53:26 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 11:53:26 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 11:53:36 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5466, validation CrossEntropy: 1.2829\n","2025-06-07 11:53:45 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2673, validation CrossEntropy: 1.2025\n","2025-06-07 11:53:54 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1608, validation CrossEntropy: 1.1202\n","2025-06-07 11:54:03 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.1141, validation CrossEntropy: 1.1869\n","2025-06-07 11:54:12 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0969, validation CrossEntropy: 1.0516\n","2025-06-07 11:54:21 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0546, validation CrossEntropy: 1.0236\n","2025-06-07 11:54:29 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0479, validation CrossEntropy: 1.0610\n","2025-06-07 11:54:38 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0375, validation CrossEntropy: 0.9893\n","2025-06-07 11:54:48 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0467, validation CrossEntropy: 1.0011\n","2025-06-07 11:54:59 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0213, validation CrossEntropy: 1.0276\n","2025-06-07 11:55:08 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0239, validation CrossEntropy: 1.0095\n","2025-06-07 11:55:18 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0459, validation CrossEntropy: 1.0519\n","2025-06-07 11:55:27 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0106, validation CrossEntropy: 0.9874\n","2025-06-07 11:55:36 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0130, validation CrossEntropy: 1.0705\n","2025-06-07 11:55:45 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9962, validation CrossEntropy: 0.9949\n","2025-06-07 11:55:54 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.9754, validation CrossEntropy: 0.9987\n","2025-06-07 11:56:03 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9737, validation CrossEntropy: 1.0006\n","2025-06-07 11:56:12 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9587, validation CrossEntropy: 0.9922\n","2025-06-07 11:56:21 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9585, validation CrossEntropy: 1.0243\n","2025-06-07 11:56:21 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 11:56:21 [INFO]: Finished training. The best model is from epoch#13.\n","2025-06-07 11:56:21 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T115326/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 11:56:25 [INFO]: No given device, using default device: cpu\n","2025-06-07 11:56:25 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T115625\n","2025-06-07 11:56:25 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T115625/tensorboard\n","2025-06-07 11:56:25 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 11:56:25 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 11:56:25 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 11:56:35 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5733, validation CrossEntropy: 1.2783\n","2025-06-07 11:56:43 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2842, validation CrossEntropy: 1.1611\n","2025-06-07 11:56:52 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1793, validation CrossEntropy: 1.2812\n","2025-06-07 11:57:01 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.1594, validation CrossEntropy: 1.0570\n","2025-06-07 11:57:10 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.1052, validation CrossEntropy: 1.1696\n","2025-06-07 11:57:18 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0524, validation CrossEntropy: 1.0123\n","2025-06-07 11:57:27 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0520, validation CrossEntropy: 0.9985\n","2025-06-07 11:57:36 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0353, validation CrossEntropy: 1.0586\n","2025-06-07 11:57:44 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0535, validation CrossEntropy: 1.1104\n","2025-06-07 11:57:53 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0416, validation CrossEntropy: 0.9975\n","2025-06-07 11:58:02 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0148, validation CrossEntropy: 0.9791\n","2025-06-07 11:58:11 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9878, validation CrossEntropy: 0.9842\n","2025-06-07 11:58:20 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9781, validation CrossEntropy: 0.9791\n","2025-06-07 11:58:29 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9919, validation CrossEntropy: 1.0197\n","2025-06-07 11:58:38 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9742, validation CrossEntropy: 1.0606\n","2025-06-07 11:58:47 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.9585, validation CrossEntropy: 0.9848\n","2025-06-07 11:58:55 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9406, validation CrossEntropy: 0.9741\n","2025-06-07 11:59:04 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9261, validation CrossEntropy: 1.0141\n","2025-06-07 11:59:14 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9488, validation CrossEntropy: 0.9671\n","2025-06-07 11:59:23 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9245, validation CrossEntropy: 0.9887\n","2025-06-07 11:59:32 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9302, validation CrossEntropy: 0.9932\n","2025-06-07 11:59:41 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9259, validation CrossEntropy: 1.0587\n","2025-06-07 11:59:49 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9154, validation CrossEntropy: 1.0023\n","2025-06-07 11:59:58 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9049, validation CrossEntropy: 0.9588\n","2025-06-07 12:00:08 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.9153, validation CrossEntropy: 0.9854\n","2025-06-07 12:00:17 [INFO]: Epoch 026 - training loss (CrossEntropy): 0.9123, validation CrossEntropy: 1.0253\n","2025-06-07 12:00:25 [INFO]: Epoch 027 - training loss (CrossEntropy): 0.8976, validation CrossEntropy: 1.0644\n","2025-06-07 12:00:34 [INFO]: Epoch 028 - training loss (CrossEntropy): 0.9190, validation CrossEntropy: 0.9447\n","2025-06-07 12:00:43 [INFO]: Epoch 029 - training loss (CrossEntropy): 0.9092, validation CrossEntropy: 0.9994\n","2025-06-07 12:00:52 [INFO]: Epoch 030 - training loss (CrossEntropy): 0.9000, validation CrossEntropy: 0.9919\n","2025-06-07 12:00:52 [INFO]: Finished training. The best model is from epoch#28.\n","2025-06-07 12:00:52 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T115625/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:00:56 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:00:56 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120056\n","2025-06-07 12:00:56 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120056/tensorboard\n","2025-06-07 12:00:56 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:00:56 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:00:56 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 12:01:06 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4170, validation CrossEntropy: 1.1527\n","2025-06-07 12:01:15 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.1812, validation CrossEntropy: 1.1875\n","2025-06-07 12:01:23 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1215, validation CrossEntropy: 1.0244\n","2025-06-07 12:01:32 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0745, validation CrossEntropy: 1.0053\n","2025-06-07 12:01:41 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0502, validation CrossEntropy: 1.0878\n","2025-06-07 12:01:50 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0327, validation CrossEntropy: 0.9621\n","2025-06-07 12:01:59 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0149, validation CrossEntropy: 0.9939\n","2025-06-07 12:02:09 [INFO]: Epoch 008 - training loss (CrossEntropy): 0.9780, validation CrossEntropy: 0.9723\n","2025-06-07 12:02:18 [INFO]: Epoch 009 - training loss (CrossEntropy): 0.9696, validation CrossEntropy: 0.9823\n","2025-06-07 12:02:27 [INFO]: Epoch 010 - training loss (CrossEntropy): 0.9416, validation CrossEntropy: 0.9775\n","2025-06-07 12:02:36 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9421, validation CrossEntropy: 1.0234\n","2025-06-07 12:02:45 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9300, validation CrossEntropy: 0.9748\n","2025-06-07 12:02:45 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:02:45 [INFO]: Finished training. The best model is from epoch#6.\n","2025-06-07 12:02:45 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120056/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:02:49 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:02:49 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120249\n","2025-06-07 12:02:49 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120249/tensorboard\n","2025-06-07 12:02:49 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:02:49 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:02:49 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 12:02:59 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4053, validation CrossEntropy: 1.2088\n","2025-06-07 12:03:08 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.1455, validation CrossEntropy: 1.1209\n","2025-06-07 12:03:17 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.0914, validation CrossEntropy: 1.0498\n","2025-06-07 12:03:27 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0308, validation CrossEntropy: 1.0548\n","2025-06-07 12:03:36 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0334, validation CrossEntropy: 0.9955\n","2025-06-07 12:03:45 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0489, validation CrossEntropy: 0.9933\n","2025-06-07 12:03:54 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0309, validation CrossEntropy: 1.0120\n","2025-06-07 12:04:03 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0291, validation CrossEntropy: 0.9735\n","2025-06-07 12:04:12 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0338, validation CrossEntropy: 1.0517\n","2025-06-07 12:04:21 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0187, validation CrossEntropy: 1.0082\n","2025-06-07 12:04:31 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9997, validation CrossEntropy: 0.9899\n","2025-06-07 12:04:39 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9981, validation CrossEntropy: 1.0116\n","2025-06-07 12:04:48 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9844, validation CrossEntropy: 0.9913\n","2025-06-07 12:04:57 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9660, validation CrossEntropy: 0.9747\n","2025-06-07 12:04:57 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:04:57 [INFO]: Finished training. The best model is from epoch#8.\n","2025-06-07 12:04:57 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120249/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:05:01 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:05:01 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120501\n","2025-06-07 12:05:01 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120501/tensorboard\n","2025-06-07 12:05:01 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:05:01 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:05:01 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 160,444\n","2025-06-07 12:05:11 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4753, validation CrossEntropy: 1.3731\n","2025-06-07 12:05:20 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2602, validation CrossEntropy: 1.1015\n","2025-06-07 12:05:29 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1437, validation CrossEntropy: 1.0133\n","2025-06-07 12:05:38 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0963, validation CrossEntropy: 1.1157\n","2025-06-07 12:05:46 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0501, validation CrossEntropy: 1.0552\n","2025-06-07 12:05:56 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0116, validation CrossEntropy: 0.9922\n","2025-06-07 12:06:05 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0215, validation CrossEntropy: 1.0491\n","2025-06-07 12:06:13 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0357, validation CrossEntropy: 1.1019\n","2025-06-07 12:06:22 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0124, validation CrossEntropy: 1.0002\n","2025-06-07 12:06:31 [INFO]: Epoch 010 - training loss (CrossEntropy): 0.9996, validation CrossEntropy: 0.9748\n","2025-06-07 12:06:40 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0002, validation CrossEntropy: 0.9770\n","2025-06-07 12:06:49 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9708, validation CrossEntropy: 0.9666\n","2025-06-07 12:06:58 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9708, validation CrossEntropy: 0.9976\n","2025-06-07 12:07:07 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9807, validation CrossEntropy: 0.9844\n","2025-06-07 12:07:16 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9696, validation CrossEntropy: 0.9867\n","2025-06-07 12:07:25 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.9730, validation CrossEntropy: 0.9609\n","2025-06-07 12:07:34 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9686, validation CrossEntropy: 1.0024\n","2025-06-07 12:07:43 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9686, validation CrossEntropy: 0.9648\n","2025-06-07 12:07:52 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9549, validation CrossEntropy: 0.9893\n","2025-06-07 12:08:01 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9563, validation CrossEntropy: 0.9589\n","2025-06-07 12:08:10 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9629, validation CrossEntropy: 0.9739\n","2025-06-07 12:08:19 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9683, validation CrossEntropy: 1.0145\n","2025-06-07 12:08:28 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9639, validation CrossEntropy: 0.9417\n","2025-06-07 12:08:36 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9540, validation CrossEntropy: 0.9587\n","2025-06-07 12:08:46 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.9441, validation CrossEntropy: 0.9648\n","2025-06-07 12:08:55 [INFO]: Epoch 026 - training loss (CrossEntropy): 0.9621, validation CrossEntropy: 0.9904\n","2025-06-07 12:09:04 [INFO]: Epoch 027 - training loss (CrossEntropy): 0.9497, validation CrossEntropy: 0.9670\n","2025-06-07 12:09:12 [INFO]: Epoch 028 - training loss (CrossEntropy): 0.9349, validation CrossEntropy: 0.9817\n","2025-06-07 12:09:21 [INFO]: Epoch 029 - training loss (CrossEntropy): 0.9493, validation CrossEntropy: 0.9366\n","2025-06-07 12:09:30 [INFO]: Epoch 030 - training loss (CrossEntropy): 0.9597, validation CrossEntropy: 0.9761\n","2025-06-07 12:09:30 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 12:09:30 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120501/Raindrop.pypots\n"]},{"output_type":"stream","name":"stdout","text":["Raindrop(n_layers=2, d_ffn=256, d_model=56, n_heads=2, dropout=0.1) & 0.2084 ± 0.0000 & 0.0576 ± 0.0002 0.0348 ± 0.0001 0.1667 ± 0.0000 \\\n","[174.33714294433594, 267.25950837135315, 108.49952268600464, 128.348464012146, 268.73482751846313]\n","189.4359 ± 67.6094\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["n_layers=1\n","d_ffn=128\n","n_heads=2\n","dropout=0.1\n","d_model = X_train_bal.shape[2] * 2\n","run_model(\n","  lambda: Raindrop(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    n_layers=n_layers,\n","    d_model=X_train_bal.shape[2] * 4,\n","    d_ffn=d_ffn,\n","    n_heads=n_heads,\n","    dropout=dropout,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/raindrop',\n","    model_saving_strategy='best'\n","  ),\n","  f\"Raindrop({n_layers=}, {d_ffn=}, {d_model=}, {n_heads=}, {dropout=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfxHwiW6a2ho","executionInfo":{"status":"ok","timestamp":1749299350291,"user_tz":-120,"elapsed":1175472,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"ba4cfa5b-e225-452a-fd66-b1d03744cb16"},"id":"rfxHwiW6a2ho","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 12:09:34 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:09:34 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120934\n","2025-06-07 12:09:34 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120934/tensorboard\n","2025-06-07 12:09:34 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:09:34 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:09:34 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 83,380\n","2025-06-07 12:09:44 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5218, validation CrossEntropy: 1.3151\n","2025-06-07 12:09:52 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2650, validation CrossEntropy: 1.1422\n","2025-06-07 12:10:01 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1558, validation CrossEntropy: 1.0863\n","2025-06-07 12:10:09 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.1204, validation CrossEntropy: 1.0476\n","2025-06-07 12:10:18 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0795, validation CrossEntropy: 1.0502\n","2025-06-07 12:10:26 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0540, validation CrossEntropy: 1.0100\n","2025-06-07 12:10:34 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0275, validation CrossEntropy: 0.9967\n","2025-06-07 12:10:43 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0060, validation CrossEntropy: 0.9688\n","2025-06-07 12:10:51 [INFO]: Epoch 009 - training loss (CrossEntropy): 0.9846, validation CrossEntropy: 1.0040\n","2025-06-07 12:11:00 [INFO]: Epoch 010 - training loss (CrossEntropy): 0.9668, validation CrossEntropy: 0.9852\n","2025-06-07 12:11:08 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9671, validation CrossEntropy: 0.9679\n","2025-06-07 12:11:16 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9527, validation CrossEntropy: 0.9957\n","2025-06-07 12:11:25 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9621, validation CrossEntropy: 0.9989\n","2025-06-07 12:11:33 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9376, validation CrossEntropy: 0.9793\n","2025-06-07 12:11:42 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9536, validation CrossEntropy: 0.9712\n","2025-06-07 12:11:50 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.9289, validation CrossEntropy: 0.9507\n","2025-06-07 12:11:59 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9253, validation CrossEntropy: 1.0198\n","2025-06-07 12:12:07 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9229, validation CrossEntropy: 0.9944\n","2025-06-07 12:12:16 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9122, validation CrossEntropy: 0.9901\n","2025-06-07 12:12:24 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9017, validation CrossEntropy: 0.9723\n","2025-06-07 12:12:32 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.8974, validation CrossEntropy: 1.0271\n","2025-06-07 12:12:41 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9074, validation CrossEntropy: 1.0268\n","2025-06-07 12:12:41 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:12:41 [INFO]: Finished training. The best model is from epoch#16.\n","2025-06-07 12:12:41 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T120934/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:12:45 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:12:45 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T121245\n","2025-06-07 12:12:45 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T121245/tensorboard\n","2025-06-07 12:12:45 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:12:45 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:12:45 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 83,380\n","2025-06-07 12:12:55 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4880, validation CrossEntropy: 1.2344\n","2025-06-07 12:13:04 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2740, validation CrossEntropy: 1.1406\n","2025-06-07 12:13:12 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.2178, validation CrossEntropy: 1.2978\n","2025-06-07 12:13:21 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.1904, validation CrossEntropy: 1.0294\n","2025-06-07 12:13:29 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.1340, validation CrossEntropy: 1.0461\n","2025-06-07 12:13:38 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.1070, validation CrossEntropy: 1.0740\n","2025-06-07 12:13:46 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0953, validation CrossEntropy: 1.1033\n","2025-06-07 12:13:55 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0643, validation CrossEntropy: 1.0285\n","2025-06-07 12:14:03 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0597, validation CrossEntropy: 1.0468\n","2025-06-07 12:14:11 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0551, validation CrossEntropy: 1.0362\n","2025-06-07 12:14:19 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0384, validation CrossEntropy: 1.0536\n","2025-06-07 12:14:28 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0341, validation CrossEntropy: 0.9964\n","2025-06-07 12:14:36 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0230, validation CrossEntropy: 0.9846\n","2025-06-07 12:14:45 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0252, validation CrossEntropy: 0.9824\n","2025-06-07 12:14:53 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0354, validation CrossEntropy: 1.0257\n","2025-06-07 12:15:02 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0560, validation CrossEntropy: 1.0018\n","2025-06-07 12:15:10 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0379, validation CrossEntropy: 1.0546\n","2025-06-07 12:15:19 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0246, validation CrossEntropy: 0.9788\n","2025-06-07 12:15:27 [INFO]: Epoch 019 - training loss (CrossEntropy): 1.0085, validation CrossEntropy: 0.9791\n","2025-06-07 12:15:35 [INFO]: Epoch 020 - training loss (CrossEntropy): 1.0038, validation CrossEntropy: 0.9953\n","2025-06-07 12:15:44 [INFO]: Epoch 021 - training loss (CrossEntropy): 1.0029, validation CrossEntropy: 0.9966\n","2025-06-07 12:15:52 [INFO]: Epoch 022 - training loss (CrossEntropy): 1.0089, validation CrossEntropy: 0.9794\n","2025-06-07 12:16:00 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9823, validation CrossEntropy: 0.9675\n","2025-06-07 12:16:09 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9794, validation CrossEntropy: 0.9910\n","2025-06-07 12:16:18 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.9737, validation CrossEntropy: 0.9606\n","2025-06-07 12:16:26 [INFO]: Epoch 026 - training loss (CrossEntropy): 0.9514, validation CrossEntropy: 0.9655\n","2025-06-07 12:16:34 [INFO]: Epoch 027 - training loss (CrossEntropy): 0.9508, validation CrossEntropy: 1.0222\n","2025-06-07 12:16:43 [INFO]: Epoch 028 - training loss (CrossEntropy): 0.9501, validation CrossEntropy: 0.9599\n","2025-06-07 12:16:51 [INFO]: Epoch 029 - training loss (CrossEntropy): 0.9375, validation CrossEntropy: 0.9915\n","2025-06-07 12:16:59 [INFO]: Epoch 030 - training loss (CrossEntropy): 0.9472, validation CrossEntropy: 0.9465\n","2025-06-07 12:16:59 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 12:16:59 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T121245/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:17:03 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:17:03 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T121703\n","2025-06-07 12:17:03 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T121703/tensorboard\n","2025-06-07 12:17:03 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:17:03 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:17:03 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 83,380\n","2025-06-07 12:17:13 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5900, validation CrossEntropy: 1.3469\n","2025-06-07 12:17:21 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2712, validation CrossEntropy: 1.1234\n","2025-06-07 12:17:29 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1417, validation CrossEntropy: 1.0495\n","2025-06-07 12:17:37 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0684, validation CrossEntropy: 1.0173\n","2025-06-07 12:17:46 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0567, validation CrossEntropy: 1.0612\n","2025-06-07 12:17:54 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0425, validation CrossEntropy: 0.9888\n","2025-06-07 12:18:02 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0282, validation CrossEntropy: 1.0347\n","2025-06-07 12:18:11 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0213, validation CrossEntropy: 1.0357\n","2025-06-07 12:18:19 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0141, validation CrossEntropy: 1.0181\n","2025-06-07 12:18:27 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0015, validation CrossEntropy: 1.0455\n","2025-06-07 12:18:36 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9864, validation CrossEntropy: 0.9828\n","2025-06-07 12:18:44 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9687, validation CrossEntropy: 0.9788\n","2025-06-07 12:18:53 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9841, validation CrossEntropy: 0.9871\n","2025-06-07 12:19:01 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9646, validation CrossEntropy: 1.0171\n","2025-06-07 12:19:09 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9675, validation CrossEntropy: 1.0199\n","2025-06-07 12:19:18 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.9504, validation CrossEntropy: 0.9778\n","2025-06-07 12:19:26 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9554, validation CrossEntropy: 0.9741\n","2025-06-07 12:19:34 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9389, validation CrossEntropy: 0.9838\n","2025-06-07 12:19:43 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9526, validation CrossEntropy: 1.0117\n","2025-06-07 12:19:51 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9392, validation CrossEntropy: 0.9657\n","2025-06-07 12:20:00 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9108, validation CrossEntropy: 1.0000\n","2025-06-07 12:20:08 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.8980, validation CrossEntropy: 0.9727\n","2025-06-07 12:20:16 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9225, validation CrossEntropy: 1.0072\n","2025-06-07 12:20:24 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9089, validation CrossEntropy: 0.9800\n","2025-06-07 12:20:32 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.8979, validation CrossEntropy: 0.9599\n","2025-06-07 12:20:41 [INFO]: Epoch 026 - training loss (CrossEntropy): 0.9045, validation CrossEntropy: 0.9970\n","2025-06-07 12:20:49 [INFO]: Epoch 027 - training loss (CrossEntropy): 0.8777, validation CrossEntropy: 0.9561\n","2025-06-07 12:20:58 [INFO]: Epoch 028 - training loss (CrossEntropy): 0.8924, validation CrossEntropy: 0.9495\n","2025-06-07 12:21:06 [INFO]: Epoch 029 - training loss (CrossEntropy): 0.8908, validation CrossEntropy: 0.9736\n","2025-06-07 12:21:14 [INFO]: Epoch 030 - training loss (CrossEntropy): 0.8903, validation CrossEntropy: 0.9814\n","2025-06-07 12:21:14 [INFO]: Finished training. The best model is from epoch#28.\n","2025-06-07 12:21:14 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T121703/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:21:18 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:21:18 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122118\n","2025-06-07 12:21:18 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122118/tensorboard\n","2025-06-07 12:21:18 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:21:18 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:21:18 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 83,380\n","2025-06-07 12:21:28 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5964, validation CrossEntropy: 1.2606\n","2025-06-07 12:21:36 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2155, validation CrossEntropy: 1.1344\n","2025-06-07 12:21:44 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1122, validation CrossEntropy: 1.0595\n","2025-06-07 12:21:52 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0547, validation CrossEntropy: 1.0176\n","2025-06-07 12:22:00 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0392, validation CrossEntropy: 0.9975\n","2025-06-07 12:22:09 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0391, validation CrossEntropy: 1.0618\n","2025-06-07 12:22:17 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0242, validation CrossEntropy: 1.0492\n","2025-06-07 12:22:26 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0288, validation CrossEntropy: 1.0050\n","2025-06-07 12:22:34 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0172, validation CrossEntropy: 1.0384\n","2025-06-07 12:22:43 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0151, validation CrossEntropy: 1.0630\n","2025-06-07 12:22:51 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0114, validation CrossEntropy: 0.9904\n","2025-06-07 12:23:00 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0081, validation CrossEntropy: 1.0165\n","2025-06-07 12:23:08 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0046, validation CrossEntropy: 0.9800\n","2025-06-07 12:23:17 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0009, validation CrossEntropy: 0.9811\n","2025-06-07 12:23:25 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9943, validation CrossEntropy: 0.9835\n","2025-06-07 12:23:33 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.9914, validation CrossEntropy: 1.0152\n","2025-06-07 12:23:42 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9994, validation CrossEntropy: 1.0246\n","2025-06-07 12:23:50 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9867, validation CrossEntropy: 0.9730\n","2025-06-07 12:23:59 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9767, validation CrossEntropy: 0.9628\n","2025-06-07 12:24:07 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9807, validation CrossEntropy: 1.0066\n","2025-06-07 12:24:16 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9657, validation CrossEntropy: 0.9903\n","2025-06-07 12:24:24 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9741, validation CrossEntropy: 0.9758\n","2025-06-07 12:24:32 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9825, validation CrossEntropy: 1.0082\n","2025-06-07 12:24:41 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9715, validation CrossEntropy: 0.9787\n","2025-06-07 12:24:49 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.9946, validation CrossEntropy: 1.0855\n","2025-06-07 12:24:49 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:24:49 [INFO]: Finished training. The best model is from epoch#19.\n","2025-06-07 12:24:49 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122118/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:24:53 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:24:53 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122453\n","2025-06-07 12:24:53 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122453/tensorboard\n","2025-06-07 12:24:53 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:24:53 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:24:53 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 83,380\n","2025-06-07 12:25:03 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5457, validation CrossEntropy: 1.3016\n","2025-06-07 12:25:11 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2528, validation CrossEntropy: 1.1292\n","2025-06-07 12:25:19 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1231, validation CrossEntropy: 1.0907\n","2025-06-07 12:25:28 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0595, validation CrossEntropy: 1.0273\n","2025-06-07 12:25:36 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0730, validation CrossEntropy: 1.0740\n","2025-06-07 12:25:44 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0735, validation CrossEntropy: 1.0128\n","2025-06-07 12:25:52 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0234, validation CrossEntropy: 1.0093\n","2025-06-07 12:26:01 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0436, validation CrossEntropy: 1.0121\n","2025-06-07 12:26:09 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0291, validation CrossEntropy: 1.0395\n","2025-06-07 12:26:17 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0098, validation CrossEntropy: 1.0245\n","2025-06-07 12:26:25 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9962, validation CrossEntropy: 0.9924\n","2025-06-07 12:26:34 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0050, validation CrossEntropy: 0.9824\n","2025-06-07 12:26:43 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9935, validation CrossEntropy: 0.9790\n","2025-06-07 12:26:51 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9966, validation CrossEntropy: 1.0300\n","2025-06-07 12:26:59 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9880, validation CrossEntropy: 1.0609\n","2025-06-07 12:27:08 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0023, validation CrossEntropy: 1.0502\n","2025-06-07 12:27:17 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9828, validation CrossEntropy: 0.9652\n","2025-06-07 12:27:25 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9683, validation CrossEntropy: 0.9662\n","2025-06-07 12:27:34 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9707, validation CrossEntropy: 0.9718\n","2025-06-07 12:27:42 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9674, validation CrossEntropy: 0.9637\n","2025-06-07 12:27:50 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9564, validation CrossEntropy: 1.0364\n","2025-06-07 12:27:59 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9456, validation CrossEntropy: 0.9822\n","2025-06-07 12:28:07 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9425, validation CrossEntropy: 0.9660\n","2025-06-07 12:28:16 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9334, validation CrossEntropy: 0.9755\n","2025-06-07 12:28:24 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.9381, validation CrossEntropy: 0.9630\n","2025-06-07 12:28:33 [INFO]: Epoch 026 - training loss (CrossEntropy): 0.9322, validation CrossEntropy: 0.9928\n","2025-06-07 12:28:41 [INFO]: Epoch 027 - training loss (CrossEntropy): 0.9355, validation CrossEntropy: 0.9638\n","2025-06-07 12:28:49 [INFO]: Epoch 028 - training loss (CrossEntropy): 0.9345, validation CrossEntropy: 0.9955\n","2025-06-07 12:28:58 [INFO]: Epoch 029 - training loss (CrossEntropy): 0.9318, validation CrossEntropy: 0.9942\n","2025-06-07 12:29:06 [INFO]: Epoch 030 - training loss (CrossEntropy): 0.9228, validation CrossEntropy: 0.9617\n","2025-06-07 12:29:06 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 12:29:06 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122453/Raindrop.pypots\n"]},{"output_type":"stream","name":"stdout","text":["Raindrop(n_layers=1, d_ffn=128, d_model=28, n_heads=2, dropout=0.1) & 0.2716 ± 0.1053 & 0.1508 ± 0.1388 0.1674 ± 0.1706 0.2281 ± 0.1013 \\\n","[186.45443868637085, 254.24835014343262, 250.87551259994507, 210.8983404636383, 252.76811814308167]\n","231.0490 ± 27.5599\n"]}]},{"cell_type":"code","source":["n_layers=2\n","d_ffn=32\n","n_heads=3\n","dropout=0.1\n","d_model = X_train_bal.shape[2] * 1\n","run_model(\n","  lambda: Raindrop(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    n_layers=n_layers,\n","    d_model=X_train_bal.shape[2] * 4,\n","    d_ffn=d_ffn,\n","    n_heads=n_heads,\n","    dropout=dropout,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/raindrop',\n","    model_saving_strategy='best'\n","  ),\n","  f\"Raindrop({n_layers=}, {d_ffn=}, {d_model=}, {n_heads=}, {dropout=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a9jlVvSCbTAJ","executionInfo":{"status":"ok","timestamp":1749300190277,"user_tz":-120,"elapsed":839968,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"2bb8e2a3-71c5-401a-a7f2-cd82d0fa386b"},"id":"a9jlVvSCbTAJ","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 12:29:10 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:29:10 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122910\n","2025-06-07 12:29:10 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122910/tensorboard\n","2025-06-07 12:29:10 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:29:10 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:29:10 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 95,484\n","2025-06-07 12:29:20 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4748, validation CrossEntropy: 1.2372\n","2025-06-07 12:29:28 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.1902, validation CrossEntropy: 1.0492\n","2025-06-07 12:29:37 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.0777, validation CrossEntropy: 1.0550\n","2025-06-07 12:29:46 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0592, validation CrossEntropy: 1.0548\n","2025-06-07 12:29:55 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0336, validation CrossEntropy: 1.0011\n","2025-06-07 12:30:03 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0191, validation CrossEntropy: 0.9796\n","2025-06-07 12:30:12 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0064, validation CrossEntropy: 0.9653\n","2025-06-07 12:30:21 [INFO]: Epoch 008 - training loss (CrossEntropy): 0.9807, validation CrossEntropy: 1.0693\n","2025-06-07 12:30:29 [INFO]: Epoch 009 - training loss (CrossEntropy): 0.9817, validation CrossEntropy: 0.9614\n","2025-06-07 12:30:38 [INFO]: Epoch 010 - training loss (CrossEntropy): 0.9707, validation CrossEntropy: 0.9876\n","2025-06-07 12:30:46 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9584, validation CrossEntropy: 0.9771\n","2025-06-07 12:30:55 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9373, validation CrossEntropy: 0.9532\n","2025-06-07 12:31:04 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9344, validation CrossEntropy: 0.9642\n","2025-06-07 12:31:13 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9457, validation CrossEntropy: 1.0007\n","2025-06-07 12:31:21 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9245, validation CrossEntropy: 0.9637\n","2025-06-07 12:31:30 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.9437, validation CrossEntropy: 0.9503\n","2025-06-07 12:31:39 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.9293, validation CrossEntropy: 1.0261\n","2025-06-07 12:31:48 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.9287, validation CrossEntropy: 0.9696\n","2025-06-07 12:31:56 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9189, validation CrossEntropy: 0.9345\n","2025-06-07 12:32:05 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9218, validation CrossEntropy: 0.9469\n","2025-06-07 12:32:14 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9249, validation CrossEntropy: 1.0751\n","2025-06-07 12:32:22 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9318, validation CrossEntropy: 0.9614\n","2025-06-07 12:32:31 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9258, validation CrossEntropy: 0.9783\n","2025-06-07 12:32:40 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9154, validation CrossEntropy: 0.9538\n","2025-06-07 12:32:48 [INFO]: Epoch 025 - training loss (CrossEntropy): 0.9269, validation CrossEntropy: 0.9660\n","2025-06-07 12:32:48 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:32:48 [INFO]: Finished training. The best model is from epoch#19.\n","2025-06-07 12:32:48 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T122910/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:32:53 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:32:53 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123253\n","2025-06-07 12:32:53 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123253/tensorboard\n","2025-06-07 12:32:53 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:32:53 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:32:53 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 95,484\n","2025-06-07 12:33:02 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5397, validation CrossEntropy: 1.2855\n","2025-06-07 12:33:11 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2949, validation CrossEntropy: 1.1216\n","2025-06-07 12:33:20 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1571, validation CrossEntropy: 1.3385\n","2025-06-07 12:33:29 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.1186, validation CrossEntropy: 1.0440\n","2025-06-07 12:33:37 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0928, validation CrossEntropy: 1.0281\n","2025-06-07 12:33:46 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0914, validation CrossEntropy: 1.1408\n","2025-06-07 12:33:55 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0494, validation CrossEntropy: 1.0065\n","2025-06-07 12:34:04 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0452, validation CrossEntropy: 1.0592\n","2025-06-07 12:34:12 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0513, validation CrossEntropy: 1.0146\n","2025-06-07 12:34:21 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0487, validation CrossEntropy: 1.0489\n","2025-06-07 12:34:30 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0729, validation CrossEntropy: 1.0373\n","2025-06-07 12:34:39 [INFO]: Epoch 012 - training loss (CrossEntropy): 1.0416, validation CrossEntropy: 1.0828\n","2025-06-07 12:34:47 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0362, validation CrossEntropy: 1.0241\n","2025-06-07 12:34:47 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:34:47 [INFO]: Finished training. The best model is from epoch#7.\n","2025-06-07 12:34:47 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123253/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:34:51 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:34:51 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123451\n","2025-06-07 12:34:51 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123451/tensorboard\n","2025-06-07 12:34:51 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:34:51 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:34:51 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 95,484\n","2025-06-07 12:35:01 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.4519, validation CrossEntropy: 1.1986\n","2025-06-07 12:35:10 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.1762, validation CrossEntropy: 1.0677\n","2025-06-07 12:35:19 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1022, validation CrossEntropy: 1.0215\n","2025-06-07 12:35:27 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0499, validation CrossEntropy: 1.0379\n","2025-06-07 12:35:36 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0592, validation CrossEntropy: 1.0007\n","2025-06-07 12:35:44 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0559, validation CrossEntropy: 0.9849\n","2025-06-07 12:35:53 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0292, validation CrossEntropy: 0.9742\n","2025-06-07 12:36:02 [INFO]: Epoch 008 - training loss (CrossEntropy): 0.9963, validation CrossEntropy: 0.9847\n","2025-06-07 12:36:10 [INFO]: Epoch 009 - training loss (CrossEntropy): 0.9923, validation CrossEntropy: 0.9549\n","2025-06-07 12:36:19 [INFO]: Epoch 010 - training loss (CrossEntropy): 0.9884, validation CrossEntropy: 0.9755\n","2025-06-07 12:36:27 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9822, validation CrossEntropy: 0.9625\n","2025-06-07 12:36:35 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9788, validation CrossEntropy: 0.9809\n","2025-06-07 12:36:44 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9644, validation CrossEntropy: 0.9842\n","2025-06-07 12:36:53 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9561, validation CrossEntropy: 1.0404\n","2025-06-07 12:37:01 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9488, validation CrossEntropy: 1.0628\n","2025-06-07 12:37:01 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:37:01 [INFO]: Finished training. The best model is from epoch#9.\n","2025-06-07 12:37:01 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123451/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:37:06 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:37:06 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123706\n","2025-06-07 12:37:06 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123706/tensorboard\n","2025-06-07 12:37:06 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:37:06 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:37:06 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 95,484\n","2025-06-07 12:37:16 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5354, validation CrossEntropy: 1.2753\n","2025-06-07 12:37:25 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.2458, validation CrossEntropy: 1.1672\n","2025-06-07 12:37:33 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1530, validation CrossEntropy: 1.1341\n","2025-06-07 12:37:42 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.1180, validation CrossEntropy: 1.0578\n","2025-06-07 12:37:51 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0848, validation CrossEntropy: 1.0724\n","2025-06-07 12:38:00 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0701, validation CrossEntropy: 1.0793\n","2025-06-07 12:38:09 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0638, validation CrossEntropy: 1.0786\n","2025-06-07 12:38:18 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0517, validation CrossEntropy: 1.1496\n","2025-06-07 12:38:26 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0573, validation CrossEntropy: 1.0492\n","2025-06-07 12:38:35 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0392, validation CrossEntropy: 1.0120\n","2025-06-07 12:38:44 [INFO]: Epoch 011 - training loss (CrossEntropy): 1.0187, validation CrossEntropy: 1.0604\n","2025-06-07 12:38:53 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9979, validation CrossEntropy: 1.0013\n","2025-06-07 12:39:02 [INFO]: Epoch 013 - training loss (CrossEntropy): 1.0216, validation CrossEntropy: 1.0149\n","2025-06-07 12:39:11 [INFO]: Epoch 014 - training loss (CrossEntropy): 1.0127, validation CrossEntropy: 1.1623\n","2025-06-07 12:39:20 [INFO]: Epoch 015 - training loss (CrossEntropy): 1.0536, validation CrossEntropy: 1.0141\n","2025-06-07 12:39:28 [INFO]: Epoch 016 - training loss (CrossEntropy): 1.0313, validation CrossEntropy: 1.0027\n","2025-06-07 12:39:37 [INFO]: Epoch 017 - training loss (CrossEntropy): 1.0052, validation CrossEntropy: 1.1294\n","2025-06-07 12:39:45 [INFO]: Epoch 018 - training loss (CrossEntropy): 1.0088, validation CrossEntropy: 0.9870\n","2025-06-07 12:39:54 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.9956, validation CrossEntropy: 1.0268\n","2025-06-07 12:40:02 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.9923, validation CrossEntropy: 1.0517\n","2025-06-07 12:40:11 [INFO]: Epoch 021 - training loss (CrossEntropy): 0.9970, validation CrossEntropy: 1.0067\n","2025-06-07 12:40:20 [INFO]: Epoch 022 - training loss (CrossEntropy): 0.9756, validation CrossEntropy: 1.0051\n","2025-06-07 12:40:29 [INFO]: Epoch 023 - training loss (CrossEntropy): 0.9717, validation CrossEntropy: 0.9897\n","2025-06-07 12:40:38 [INFO]: Epoch 024 - training loss (CrossEntropy): 0.9891, validation CrossEntropy: 1.0218\n","2025-06-07 12:40:38 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:40:38 [INFO]: Finished training. The best model is from epoch#18.\n","2025-06-07 12:40:38 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T123706/Raindrop.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:40:42 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:40:42 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T124042\n","2025-06-07 12:40:42 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T124042/tensorboard\n","2025-06-07 12:40:42 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:40:42 [INFO]: Using customized CrossEntropy as the validation metric function.\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/raindrop/backbone.py:114: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n","  nn.init.xavier_uniform(self.R_u)  # xavier_uniform also known as glorot\n","2025-06-07 12:40:42 [INFO]: Raindrop initialized with the given hyperparameters, the number of trainable parameters: 95,484\n","2025-06-07 12:40:52 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.5022, validation CrossEntropy: 1.2305\n","2025-06-07 12:41:01 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.1872, validation CrossEntropy: 1.2527\n","2025-06-07 12:41:10 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.1076, validation CrossEntropy: 1.1281\n","2025-06-07 12:41:19 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.0705, validation CrossEntropy: 1.1630\n","2025-06-07 12:41:28 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.0439, validation CrossEntropy: 1.0030\n","2025-06-07 12:41:36 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0339, validation CrossEntropy: 0.9774\n","2025-06-07 12:41:45 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0108, validation CrossEntropy: 0.9929\n","2025-06-07 12:41:54 [INFO]: Epoch 008 - training loss (CrossEntropy): 0.9935, validation CrossEntropy: 0.9777\n","2025-06-07 12:42:03 [INFO]: Epoch 009 - training loss (CrossEntropy): 0.9956, validation CrossEntropy: 0.9826\n","2025-06-07 12:42:12 [INFO]: Epoch 010 - training loss (CrossEntropy): 0.9833, validation CrossEntropy: 0.9571\n","2025-06-07 12:42:21 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9797, validation CrossEntropy: 0.9691\n","2025-06-07 12:42:29 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9828, validation CrossEntropy: 1.0387\n","2025-06-07 12:42:38 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9686, validation CrossEntropy: 0.9801\n","2025-06-07 12:42:48 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9570, validation CrossEntropy: 0.9661\n","2025-06-07 12:42:56 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9530, validation CrossEntropy: 0.9764\n","2025-06-07 12:43:05 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.9496, validation CrossEntropy: 1.0032\n","2025-06-07 12:43:05 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:43:05 [INFO]: Finished training. The best model is from epoch#10.\n","2025-06-07 12:43:05 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/raindrop/20250607_T124042/Raindrop.pypots\n"]},{"output_type":"stream","name":"stdout","text":["Raindrop(n_layers=2, d_ffn=32, d_model=14, n_heads=3, dropout=0.1) & 0.2199 ± 0.0218 & 0.0904 ± 0.0438 0.0910 ± 0.0948 0.1792 ± 0.0207 \\\n","[218.37839603424072, 114.39803743362427, 130.12150859832764, 211.59607887268066, 143.2910876274109]\n","163.5570 ± 43.0311\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","source":["## Brits"],"metadata":{"id":"bWt62L7pe7N7"},"id":"bWt62L7pe7N7"},{"cell_type":"code","source":["\n","rnn_hidden_size=64\n","classification_weight=1\n","reconstruction_weight=1\n","\n","run_model(\n","  lambda: BRITS(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    rnn_hidden_size=rnn_hidden_size,\n","    classification_weight=classification_weight,\n","    reconstruction_weight=reconstruction_weight,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/brits',\n","    model_saving_strategy='best'\n","  ),\n","  f\"BRITS({rnn_hidden_size=}, {classification_weight=}, {reconstruction_weight=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IB3WMpeSe8UG","executionInfo":{"status":"ok","timestamp":1749300817368,"user_tz":-120,"elapsed":627089,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"e727c3c5-b87e-4467-8d83-f077f42f353f"},"id":"IB3WMpeSe8UG","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 12:43:10 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:43:10 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T124310\n","2025-06-07 12:43:10 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T124310/tensorboard\n","2025-06-07 12:43:10 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:43:10 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:43:10 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 12:43:17 [INFO]: Epoch 001 - training loss (CrossEntropy): 1886.3897, validation CrossEntropy: 1.5690\n","2025-06-07 12:43:21 [INFO]: Epoch 002 - training loss (CrossEntropy): 1504.1904, validation CrossEntropy: 1.5113\n","2025-06-07 12:43:25 [INFO]: Epoch 003 - training loss (CrossEntropy): 1361.3795, validation CrossEntropy: 1.4511\n","2025-06-07 12:43:29 [INFO]: Epoch 004 - training loss (CrossEntropy): 1318.1157, validation CrossEntropy: 1.4720\n","2025-06-07 12:43:34 [INFO]: Epoch 005 - training loss (CrossEntropy): 1311.2729, validation CrossEntropy: 1.4208\n","2025-06-07 12:43:38 [INFO]: Epoch 006 - training loss (CrossEntropy): 1307.9066, validation CrossEntropy: 1.3636\n","2025-06-07 12:43:42 [INFO]: Epoch 007 - training loss (CrossEntropy): 1297.3146, validation CrossEntropy: 1.3557\n","2025-06-07 12:43:46 [INFO]: Epoch 008 - training loss (CrossEntropy): 1293.8217, validation CrossEntropy: 1.3436\n","2025-06-07 12:43:50 [INFO]: Epoch 009 - training loss (CrossEntropy): 1286.6137, validation CrossEntropy: 1.2885\n","2025-06-07 12:43:55 [INFO]: Epoch 010 - training loss (CrossEntropy): 1280.8327, validation CrossEntropy: 1.3049\n","2025-06-07 12:43:59 [INFO]: Epoch 011 - training loss (CrossEntropy): 1281.6796, validation CrossEntropy: 1.3130\n","2025-06-07 12:44:03 [INFO]: Epoch 012 - training loss (CrossEntropy): 1275.4926, validation CrossEntropy: 1.2901\n","2025-06-07 12:44:07 [INFO]: Epoch 013 - training loss (CrossEntropy): 1274.2305, validation CrossEntropy: 1.2982\n","2025-06-07 12:44:11 [INFO]: Epoch 014 - training loss (CrossEntropy): 1269.2175, validation CrossEntropy: 1.2580\n","2025-06-07 12:44:15 [INFO]: Epoch 015 - training loss (CrossEntropy): 1264.6865, validation CrossEntropy: 1.3149\n","2025-06-07 12:44:20 [INFO]: Epoch 016 - training loss (CrossEntropy): 1262.4150, validation CrossEntropy: 1.3037\n","2025-06-07 12:44:24 [INFO]: Epoch 017 - training loss (CrossEntropy): 1262.4630, validation CrossEntropy: 1.2927\n","2025-06-07 12:44:28 [INFO]: Epoch 018 - training loss (CrossEntropy): 1256.0391, validation CrossEntropy: 1.2823\n","2025-06-07 12:44:32 [INFO]: Epoch 019 - training loss (CrossEntropy): 1256.8014, validation CrossEntropy: 1.3175\n","2025-06-07 12:44:37 [INFO]: Epoch 020 - training loss (CrossEntropy): 1252.0795, validation CrossEntropy: 1.2724\n","2025-06-07 12:44:37 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:44:37 [INFO]: Finished training. The best model is from epoch#14.\n","2025-06-07 12:44:37 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T124310/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:44:39 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:44:39 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T124439\n","2025-06-07 12:44:39 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T124439/tensorboard\n","2025-06-07 12:44:39 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:44:39 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:44:39 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 12:44:46 [INFO]: Epoch 001 - training loss (CrossEntropy): 1904.0238, validation CrossEntropy: 1.6184\n","2025-06-07 12:44:51 [INFO]: Epoch 002 - training loss (CrossEntropy): 1537.0076, validation CrossEntropy: 1.5410\n","2025-06-07 12:44:55 [INFO]: Epoch 003 - training loss (CrossEntropy): 1367.7926, validation CrossEntropy: 1.4952\n","2025-06-07 12:44:59 [INFO]: Epoch 004 - training loss (CrossEntropy): 1319.0160, validation CrossEntropy: 1.4687\n","2025-06-07 12:45:03 [INFO]: Epoch 005 - training loss (CrossEntropy): 1316.1396, validation CrossEntropy: 1.3925\n","2025-06-07 12:45:08 [INFO]: Epoch 006 - training loss (CrossEntropy): 1308.2701, validation CrossEntropy: 1.4184\n","2025-06-07 12:45:12 [INFO]: Epoch 007 - training loss (CrossEntropy): 1296.7613, validation CrossEntropy: 1.3612\n","2025-06-07 12:45:16 [INFO]: Epoch 008 - training loss (CrossEntropy): 1293.3570, validation CrossEntropy: 1.3557\n","2025-06-07 12:45:20 [INFO]: Epoch 009 - training loss (CrossEntropy): 1288.8540, validation CrossEntropy: 1.3274\n","2025-06-07 12:45:24 [INFO]: Epoch 010 - training loss (CrossEntropy): 1283.6750, validation CrossEntropy: 1.3232\n","2025-06-07 12:45:28 [INFO]: Epoch 011 - training loss (CrossEntropy): 1276.5487, validation CrossEntropy: 1.3177\n","2025-06-07 12:45:33 [INFO]: Epoch 012 - training loss (CrossEntropy): 1275.0879, validation CrossEntropy: 1.2901\n","2025-06-07 12:45:37 [INFO]: Epoch 013 - training loss (CrossEntropy): 1274.3242, validation CrossEntropy: 1.2907\n","2025-06-07 12:45:41 [INFO]: Epoch 014 - training loss (CrossEntropy): 1268.5731, validation CrossEntropy: 1.2503\n","2025-06-07 12:45:45 [INFO]: Epoch 015 - training loss (CrossEntropy): 1270.7343, validation CrossEntropy: 1.2485\n","2025-06-07 12:45:50 [INFO]: Epoch 016 - training loss (CrossEntropy): 1265.9944, validation CrossEntropy: 1.2345\n","2025-06-07 12:45:54 [INFO]: Epoch 017 - training loss (CrossEntropy): 1260.7926, validation CrossEntropy: 1.2235\n","2025-06-07 12:45:58 [INFO]: Epoch 018 - training loss (CrossEntropy): 1257.1762, validation CrossEntropy: 1.2333\n","2025-06-07 12:46:03 [INFO]: Epoch 019 - training loss (CrossEntropy): 1256.3306, validation CrossEntropy: 1.2074\n","2025-06-07 12:46:07 [INFO]: Epoch 020 - training loss (CrossEntropy): 1251.4582, validation CrossEntropy: 1.2210\n","2025-06-07 12:46:11 [INFO]: Epoch 021 - training loss (CrossEntropy): 1245.3141, validation CrossEntropy: 1.2010\n","2025-06-07 12:46:16 [INFO]: Epoch 022 - training loss (CrossEntropy): 1244.1342, validation CrossEntropy: 1.2098\n","2025-06-07 12:46:21 [INFO]: Epoch 023 - training loss (CrossEntropy): 1241.4060, validation CrossEntropy: 1.2020\n","2025-06-07 12:46:25 [INFO]: Epoch 024 - training loss (CrossEntropy): 1242.5004, validation CrossEntropy: 1.2031\n","2025-06-07 12:46:29 [INFO]: Epoch 025 - training loss (CrossEntropy): 1237.6818, validation CrossEntropy: 1.1771\n","2025-06-07 12:46:34 [INFO]: Epoch 026 - training loss (CrossEntropy): 1233.5977, validation CrossEntropy: 1.1628\n","2025-06-07 12:46:38 [INFO]: Epoch 027 - training loss (CrossEntropy): 1229.0303, validation CrossEntropy: 1.1630\n","2025-06-07 12:46:43 [INFO]: Epoch 028 - training loss (CrossEntropy): 1229.4039, validation CrossEntropy: 1.1708\n","2025-06-07 12:46:47 [INFO]: Epoch 029 - training loss (CrossEntropy): 1226.2713, validation CrossEntropy: 1.1589\n","2025-06-07 12:46:52 [INFO]: Epoch 030 - training loss (CrossEntropy): 1223.6931, validation CrossEntropy: 1.1624\n","2025-06-07 12:46:52 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 12:46:52 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T124439/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:46:54 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:46:54 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T124654\n","2025-06-07 12:46:54 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T124654/tensorboard\n","2025-06-07 12:46:54 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:46:54 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:46:54 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 12:47:01 [INFO]: Epoch 001 - training loss (CrossEntropy): 1872.1524, validation CrossEntropy: 1.5775\n","2025-06-07 12:47:05 [INFO]: Epoch 002 - training loss (CrossEntropy): 1530.6422, validation CrossEntropy: 1.5001\n","2025-06-07 12:47:09 [INFO]: Epoch 003 - training loss (CrossEntropy): 1372.3163, validation CrossEntropy: 1.4812\n","2025-06-07 12:47:13 [INFO]: Epoch 004 - training loss (CrossEntropy): 1318.5137, validation CrossEntropy: 1.4576\n","2025-06-07 12:47:18 [INFO]: Epoch 005 - training loss (CrossEntropy): 1309.2407, validation CrossEntropy: 1.4044\n","2025-06-07 12:47:22 [INFO]: Epoch 006 - training loss (CrossEntropy): 1302.5480, validation CrossEntropy: 1.3916\n","2025-06-07 12:47:26 [INFO]: Epoch 007 - training loss (CrossEntropy): 1294.7583, validation CrossEntropy: 1.3363\n","2025-06-07 12:47:30 [INFO]: Epoch 008 - training loss (CrossEntropy): 1288.1450, validation CrossEntropy: 1.2943\n","2025-06-07 12:47:34 [INFO]: Epoch 009 - training loss (CrossEntropy): 1285.4507, validation CrossEntropy: 1.2545\n","2025-06-07 12:47:39 [INFO]: Epoch 010 - training loss (CrossEntropy): 1283.4137, validation CrossEntropy: 1.2546\n","2025-06-07 12:47:43 [INFO]: Epoch 011 - training loss (CrossEntropy): 1279.3345, validation CrossEntropy: 1.2168\n","2025-06-07 12:47:47 [INFO]: Epoch 012 - training loss (CrossEntropy): 1276.9898, validation CrossEntropy: 1.1907\n","2025-06-07 12:47:52 [INFO]: Epoch 013 - training loss (CrossEntropy): 1270.5222, validation CrossEntropy: 1.2255\n","2025-06-07 12:47:56 [INFO]: Epoch 014 - training loss (CrossEntropy): 1269.6376, validation CrossEntropy: 1.1700\n","2025-06-07 12:48:01 [INFO]: Epoch 015 - training loss (CrossEntropy): 1263.1094, validation CrossEntropy: 1.1888\n","2025-06-07 12:48:05 [INFO]: Epoch 016 - training loss (CrossEntropy): 1258.1024, validation CrossEntropy: 1.1548\n","2025-06-07 12:48:10 [INFO]: Epoch 017 - training loss (CrossEntropy): 1259.9347, validation CrossEntropy: 1.1708\n","2025-06-07 12:48:14 [INFO]: Epoch 018 - training loss (CrossEntropy): 1253.4006, validation CrossEntropy: 1.1536\n","2025-06-07 12:48:18 [INFO]: Epoch 019 - training loss (CrossEntropy): 1254.7147, validation CrossEntropy: 1.1604\n","2025-06-07 12:48:22 [INFO]: Epoch 020 - training loss (CrossEntropy): 1249.0951, validation CrossEntropy: 1.1229\n","2025-06-07 12:48:27 [INFO]: Epoch 021 - training loss (CrossEntropy): 1246.2237, validation CrossEntropy: 1.1292\n","2025-06-07 12:48:31 [INFO]: Epoch 022 - training loss (CrossEntropy): 1243.1224, validation CrossEntropy: 1.1252\n","2025-06-07 12:48:35 [INFO]: Epoch 023 - training loss (CrossEntropy): 1238.4836, validation CrossEntropy: 1.1089\n","2025-06-07 12:48:39 [INFO]: Epoch 024 - training loss (CrossEntropy): 1236.9144, validation CrossEntropy: 1.1100\n","2025-06-07 12:48:44 [INFO]: Epoch 025 - training loss (CrossEntropy): 1240.0934, validation CrossEntropy: 1.1173\n","2025-06-07 12:48:48 [INFO]: Epoch 026 - training loss (CrossEntropy): 1233.6957, validation CrossEntropy: 1.0920\n","2025-06-07 12:48:52 [INFO]: Epoch 027 - training loss (CrossEntropy): 1229.6427, validation CrossEntropy: 1.0906\n","2025-06-07 12:48:56 [INFO]: Epoch 028 - training loss (CrossEntropy): 1227.2433, validation CrossEntropy: 1.0861\n","2025-06-07 12:49:00 [INFO]: Epoch 029 - training loss (CrossEntropy): 1222.2364, validation CrossEntropy: 1.0892\n","2025-06-07 12:49:05 [INFO]: Epoch 030 - training loss (CrossEntropy): 1225.5686, validation CrossEntropy: 1.0844\n","2025-06-07 12:49:05 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 12:49:05 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T124654/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:49:07 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:49:07 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T124907\n","2025-06-07 12:49:07 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T124907/tensorboard\n","2025-06-07 12:49:07 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:49:07 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:49:07 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 12:49:14 [INFO]: Epoch 001 - training loss (CrossEntropy): 1843.0572, validation CrossEntropy: 1.5527\n","2025-06-07 12:49:19 [INFO]: Epoch 002 - training loss (CrossEntropy): 1479.6717, validation CrossEntropy: 1.5075\n","2025-06-07 12:49:23 [INFO]: Epoch 003 - training loss (CrossEntropy): 1349.4963, validation CrossEntropy: 1.4640\n","2025-06-07 12:49:27 [INFO]: Epoch 004 - training loss (CrossEntropy): 1322.8956, validation CrossEntropy: 1.4158\n","2025-06-07 12:49:31 [INFO]: Epoch 005 - training loss (CrossEntropy): 1310.6102, validation CrossEntropy: 1.3660\n","2025-06-07 12:49:35 [INFO]: Epoch 006 - training loss (CrossEntropy): 1303.4342, validation CrossEntropy: 1.3463\n","2025-06-07 12:49:39 [INFO]: Epoch 007 - training loss (CrossEntropy): 1299.7303, validation CrossEntropy: 1.3328\n","2025-06-07 12:49:44 [INFO]: Epoch 008 - training loss (CrossEntropy): 1291.0833, validation CrossEntropy: 1.2703\n","2025-06-07 12:49:48 [INFO]: Epoch 009 - training loss (CrossEntropy): 1292.6227, validation CrossEntropy: 1.2786\n","2025-06-07 12:49:52 [INFO]: Epoch 010 - training loss (CrossEntropy): 1283.1074, validation CrossEntropy: 1.2693\n","2025-06-07 12:49:57 [INFO]: Epoch 011 - training loss (CrossEntropy): 1280.7949, validation CrossEntropy: 1.2892\n","2025-06-07 12:50:01 [INFO]: Epoch 012 - training loss (CrossEntropy): 1278.9296, validation CrossEntropy: 1.2550\n","2025-06-07 12:50:05 [INFO]: Epoch 013 - training loss (CrossEntropy): 1274.4577, validation CrossEntropy: 1.2527\n","2025-06-07 12:50:10 [INFO]: Epoch 014 - training loss (CrossEntropy): 1270.1239, validation CrossEntropy: 1.2416\n","2025-06-07 12:50:14 [INFO]: Epoch 015 - training loss (CrossEntropy): 1265.2049, validation CrossEntropy: 1.2227\n","2025-06-07 12:50:19 [INFO]: Epoch 016 - training loss (CrossEntropy): 1266.1231, validation CrossEntropy: 1.2156\n","2025-06-07 12:50:23 [INFO]: Epoch 017 - training loss (CrossEntropy): 1262.3502, validation CrossEntropy: 1.2064\n","2025-06-07 12:50:27 [INFO]: Epoch 018 - training loss (CrossEntropy): 1258.0387, validation CrossEntropy: 1.2031\n","2025-06-07 12:50:31 [INFO]: Epoch 019 - training loss (CrossEntropy): 1257.3310, validation CrossEntropy: 1.1828\n","2025-06-07 12:50:36 [INFO]: Epoch 020 - training loss (CrossEntropy): 1254.9467, validation CrossEntropy: 1.1754\n","2025-06-07 12:50:40 [INFO]: Epoch 021 - training loss (CrossEntropy): 1246.0958, validation CrossEntropy: 1.1676\n","2025-06-07 12:50:45 [INFO]: Epoch 022 - training loss (CrossEntropy): 1246.6275, validation CrossEntropy: 1.1682\n","2025-06-07 12:50:49 [INFO]: Epoch 023 - training loss (CrossEntropy): 1242.1274, validation CrossEntropy: 1.1894\n","2025-06-07 12:50:54 [INFO]: Epoch 024 - training loss (CrossEntropy): 1245.7439, validation CrossEntropy: 1.1575\n","2025-06-07 12:50:58 [INFO]: Epoch 025 - training loss (CrossEntropy): 1239.5690, validation CrossEntropy: 1.1532\n","2025-06-07 12:51:02 [INFO]: Epoch 026 - training loss (CrossEntropy): 1234.0389, validation CrossEntropy: 1.1475\n","2025-06-07 12:51:07 [INFO]: Epoch 027 - training loss (CrossEntropy): 1231.1021, validation CrossEntropy: 1.1745\n","2025-06-07 12:51:11 [INFO]: Epoch 028 - training loss (CrossEntropy): 1229.0899, validation CrossEntropy: 1.1619\n","2025-06-07 12:51:15 [INFO]: Epoch 029 - training loss (CrossEntropy): 1226.6329, validation CrossEntropy: 1.1174\n","2025-06-07 12:51:20 [INFO]: Epoch 030 - training loss (CrossEntropy): 1224.4286, validation CrossEntropy: 1.1350\n","2025-06-07 12:51:20 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 12:51:20 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T124907/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:51:22 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:51:22 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125122\n","2025-06-07 12:51:22 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125122/tensorboard\n","2025-06-07 12:51:22 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:51:22 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:51:22 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 12:51:30 [INFO]: Epoch 001 - training loss (CrossEntropy): 1768.2163, validation CrossEntropy: 1.5892\n","2025-06-07 12:51:35 [INFO]: Epoch 002 - training loss (CrossEntropy): 1443.7116, validation CrossEntropy: 1.5696\n","2025-06-07 12:51:39 [INFO]: Epoch 003 - training loss (CrossEntropy): 1343.3149, validation CrossEntropy: 1.5190\n","2025-06-07 12:51:44 [INFO]: Epoch 004 - training loss (CrossEntropy): 1315.9443, validation CrossEntropy: 1.4580\n","2025-06-07 12:51:48 [INFO]: Epoch 005 - training loss (CrossEntropy): 1304.9155, validation CrossEntropy: 1.4546\n","2025-06-07 12:51:52 [INFO]: Epoch 006 - training loss (CrossEntropy): 1303.4166, validation CrossEntropy: 1.4280\n","2025-06-07 12:51:57 [INFO]: Epoch 007 - training loss (CrossEntropy): 1293.2053, validation CrossEntropy: 1.3828\n","2025-06-07 12:52:01 [INFO]: Epoch 008 - training loss (CrossEntropy): 1289.7449, validation CrossEntropy: 1.3318\n","2025-06-07 12:52:06 [INFO]: Epoch 009 - training loss (CrossEntropy): 1284.3828, validation CrossEntropy: 1.3039\n","2025-06-07 12:52:10 [INFO]: Epoch 010 - training loss (CrossEntropy): 1282.5936, validation CrossEntropy: 1.3124\n","2025-06-07 12:52:14 [INFO]: Epoch 011 - training loss (CrossEntropy): 1279.4159, validation CrossEntropy: 1.2866\n","2025-06-07 12:52:19 [INFO]: Epoch 012 - training loss (CrossEntropy): 1273.9768, validation CrossEntropy: 1.2895\n","2025-06-07 12:52:23 [INFO]: Epoch 013 - training loss (CrossEntropy): 1271.8565, validation CrossEntropy: 1.2655\n","2025-06-07 12:52:27 [INFO]: Epoch 014 - training loss (CrossEntropy): 1266.9111, validation CrossEntropy: 1.2548\n","2025-06-07 12:52:32 [INFO]: Epoch 015 - training loss (CrossEntropy): 1267.2814, validation CrossEntropy: 1.2445\n","2025-06-07 12:52:36 [INFO]: Epoch 016 - training loss (CrossEntropy): 1262.5093, validation CrossEntropy: 1.2403\n","2025-06-07 12:52:40 [INFO]: Epoch 017 - training loss (CrossEntropy): 1257.9334, validation CrossEntropy: 1.2186\n","2025-06-07 12:52:44 [INFO]: Epoch 018 - training loss (CrossEntropy): 1256.1741, validation CrossEntropy: 1.2410\n","2025-06-07 12:52:49 [INFO]: Epoch 019 - training loss (CrossEntropy): 1253.7405, validation CrossEntropy: 1.2215\n","2025-06-07 12:52:53 [INFO]: Epoch 020 - training loss (CrossEntropy): 1249.0331, validation CrossEntropy: 1.2114\n","2025-06-07 12:52:57 [INFO]: Epoch 021 - training loss (CrossEntropy): 1248.7021, validation CrossEntropy: 1.2230\n","2025-06-07 12:53:01 [INFO]: Epoch 022 - training loss (CrossEntropy): 1245.0919, validation CrossEntropy: 1.2118\n","2025-06-07 12:53:06 [INFO]: Epoch 023 - training loss (CrossEntropy): 1238.6320, validation CrossEntropy: 1.2140\n","2025-06-07 12:53:10 [INFO]: Epoch 024 - training loss (CrossEntropy): 1240.5294, validation CrossEntropy: 1.1953\n","2025-06-07 12:53:14 [INFO]: Epoch 025 - training loss (CrossEntropy): 1237.2045, validation CrossEntropy: 1.1825\n","2025-06-07 12:53:18 [INFO]: Epoch 026 - training loss (CrossEntropy): 1232.6783, validation CrossEntropy: 1.1932\n","2025-06-07 12:53:22 [INFO]: Epoch 027 - training loss (CrossEntropy): 1228.2528, validation CrossEntropy: 1.1875\n","2025-06-07 12:53:26 [INFO]: Epoch 028 - training loss (CrossEntropy): 1229.5143, validation CrossEntropy: 1.1775\n","2025-06-07 12:53:30 [INFO]: Epoch 029 - training loss (CrossEntropy): 1227.2084, validation CrossEntropy: 1.1694\n","2025-06-07 12:53:34 [INFO]: Epoch 030 - training loss (CrossEntropy): 1224.0627, validation CrossEntropy: 1.1878\n","2025-06-07 12:53:34 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 12:53:34 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T125122/BRITS.pypots\n"]},{"output_type":"stream","name":"stdout","text":["BRITS(rnn_hidden_size=64, classification_weight=1, reconstruction_weight=1) & 0.2471 ± 0.0349 & 0.1096 ± 0.0414 0.0949 ± 0.0605 0.2067 ± 0.0330 \\\n","[86.84256029129028, 132.44885897636414, 130.91451454162598, 132.68743991851807, 132.19823360443115]\n","123.0183 ± 18.0982\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["\n","rnn_hidden_size=32\n","classification_weight=1\n","reconstruction_weight=1\n","\n","run_model(\n","  lambda: BRITS(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    rnn_hidden_size=rnn_hidden_size,\n","    classification_weight=classification_weight,\n","    reconstruction_weight=reconstruction_weight,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/brits',\n","    model_saving_strategy='best'\n","  ),\n","  f\"BRITS({rnn_hidden_size=}, {classification_weight=}, {reconstruction_weight=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qby4NinXcfVV","executionInfo":{"status":"ok","timestamp":1749301362626,"user_tz":-120,"elapsed":545246,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"9a4ad3d7-55b8-4800-cbd9-1816cd30a079"},"id":"Qby4NinXcfVV","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 12:53:37 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:53:37 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125337\n","2025-06-07 12:53:37 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125337/tensorboard\n","2025-06-07 12:53:37 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:53:37 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:53:37 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 12:53:44 [INFO]: Epoch 001 - training loss (CrossEntropy): 1922.8579, validation CrossEntropy: 1.6541\n","2025-06-07 12:53:47 [INFO]: Epoch 002 - training loss (CrossEntropy): 1540.9021, validation CrossEntropy: 1.6016\n","2025-06-07 12:53:51 [INFO]: Epoch 003 - training loss (CrossEntropy): 1386.1600, validation CrossEntropy: 1.6023\n","2025-06-07 12:53:55 [INFO]: Epoch 004 - training loss (CrossEntropy): 1321.8194, validation CrossEntropy: 1.5759\n","2025-06-07 12:53:59 [INFO]: Epoch 005 - training loss (CrossEntropy): 1317.5119, validation CrossEntropy: 1.5307\n","2025-06-07 12:54:03 [INFO]: Epoch 006 - training loss (CrossEntropy): 1305.6913, validation CrossEntropy: 1.4683\n","2025-06-07 12:54:07 [INFO]: Epoch 007 - training loss (CrossEntropy): 1300.9658, validation CrossEntropy: 1.4735\n","2025-06-07 12:54:11 [INFO]: Epoch 008 - training loss (CrossEntropy): 1295.5264, validation CrossEntropy: 1.4299\n","2025-06-07 12:54:14 [INFO]: Epoch 009 - training loss (CrossEntropy): 1290.5560, validation CrossEntropy: 1.4516\n","2025-06-07 12:54:18 [INFO]: Epoch 010 - training loss (CrossEntropy): 1292.6921, validation CrossEntropy: 1.4176\n","2025-06-07 12:54:22 [INFO]: Epoch 011 - training loss (CrossEntropy): 1284.9336, validation CrossEntropy: 1.3991\n","2025-06-07 12:54:26 [INFO]: Epoch 012 - training loss (CrossEntropy): 1276.8142, validation CrossEntropy: 1.3760\n","2025-06-07 12:54:30 [INFO]: Epoch 013 - training loss (CrossEntropy): 1280.6675, validation CrossEntropy: 1.3649\n","2025-06-07 12:54:34 [INFO]: Epoch 014 - training loss (CrossEntropy): 1277.3149, validation CrossEntropy: 1.3309\n","2025-06-07 12:54:38 [INFO]: Epoch 015 - training loss (CrossEntropy): 1270.0180, validation CrossEntropy: 1.3165\n","2025-06-07 12:54:42 [INFO]: Epoch 016 - training loss (CrossEntropy): 1269.3087, validation CrossEntropy: 1.3365\n","2025-06-07 12:54:47 [INFO]: Epoch 017 - training loss (CrossEntropy): 1264.7307, validation CrossEntropy: 1.3408\n","2025-06-07 12:54:51 [INFO]: Epoch 018 - training loss (CrossEntropy): 1261.1364, validation CrossEntropy: 1.3352\n","2025-06-07 12:54:55 [INFO]: Epoch 019 - training loss (CrossEntropy): 1260.7587, validation CrossEntropy: 1.3996\n","2025-06-07 12:55:00 [INFO]: Epoch 020 - training loss (CrossEntropy): 1253.8862, validation CrossEntropy: 1.4175\n","2025-06-07 12:55:04 [INFO]: Epoch 021 - training loss (CrossEntropy): 1252.3613, validation CrossEntropy: 1.4084\n","2025-06-07 12:55:04 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 12:55:04 [INFO]: Finished training. The best model is from epoch#15.\n","2025-06-07 12:55:04 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T125337/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:55:06 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:55:06 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125506\n","2025-06-07 12:55:06 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125506/tensorboard\n","2025-06-07 12:55:06 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:55:06 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:55:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 12:55:13 [INFO]: Epoch 001 - training loss (CrossEntropy): 2025.1007, validation CrossEntropy: 1.6628\n","2025-06-07 12:55:17 [INFO]: Epoch 002 - training loss (CrossEntropy): 1569.0830, validation CrossEntropy: 1.5686\n","2025-06-07 12:55:22 [INFO]: Epoch 003 - training loss (CrossEntropy): 1368.6269, validation CrossEntropy: 1.5479\n","2025-06-07 12:55:26 [INFO]: Epoch 004 - training loss (CrossEntropy): 1319.1617, validation CrossEntropy: 1.5713\n","2025-06-07 12:55:30 [INFO]: Epoch 005 - training loss (CrossEntropy): 1311.3197, validation CrossEntropy: 1.5496\n","2025-06-07 12:55:34 [INFO]: Epoch 006 - training loss (CrossEntropy): 1305.2632, validation CrossEntropy: 1.4849\n","2025-06-07 12:55:38 [INFO]: Epoch 007 - training loss (CrossEntropy): 1301.5577, validation CrossEntropy: 1.4563\n","2025-06-07 12:55:43 [INFO]: Epoch 008 - training loss (CrossEntropy): 1295.8601, validation CrossEntropy: 1.4421\n","2025-06-07 12:55:47 [INFO]: Epoch 009 - training loss (CrossEntropy): 1288.8126, validation CrossEntropy: 1.4778\n","2025-06-07 12:55:51 [INFO]: Epoch 010 - training loss (CrossEntropy): 1288.5855, validation CrossEntropy: 1.4605\n","2025-06-07 12:55:55 [INFO]: Epoch 011 - training loss (CrossEntropy): 1286.6240, validation CrossEntropy: 1.4183\n","2025-06-07 12:55:59 [INFO]: Epoch 012 - training loss (CrossEntropy): 1279.3399, validation CrossEntropy: 1.4043\n","2025-06-07 12:56:03 [INFO]: Epoch 013 - training loss (CrossEntropy): 1274.7377, validation CrossEntropy: 1.3834\n","2025-06-07 12:56:07 [INFO]: Epoch 014 - training loss (CrossEntropy): 1273.0515, validation CrossEntropy: 1.3570\n","2025-06-07 12:56:11 [INFO]: Epoch 015 - training loss (CrossEntropy): 1272.2705, validation CrossEntropy: 1.3386\n","2025-06-07 12:56:14 [INFO]: Epoch 016 - training loss (CrossEntropy): 1268.0875, validation CrossEntropy: 1.3397\n","2025-06-07 12:56:19 [INFO]: Epoch 017 - training loss (CrossEntropy): 1264.9292, validation CrossEntropy: 1.3234\n","2025-06-07 12:56:23 [INFO]: Epoch 018 - training loss (CrossEntropy): 1262.2868, validation CrossEntropy: 1.3055\n","2025-06-07 12:56:27 [INFO]: Epoch 019 - training loss (CrossEntropy): 1259.1421, validation CrossEntropy: 1.2983\n","2025-06-07 12:56:31 [INFO]: Epoch 020 - training loss (CrossEntropy): 1255.8561, validation CrossEntropy: 1.2695\n","2025-06-07 12:56:35 [INFO]: Epoch 021 - training loss (CrossEntropy): 1249.4929, validation CrossEntropy: 1.2464\n","2025-06-07 12:56:39 [INFO]: Epoch 022 - training loss (CrossEntropy): 1252.5435, validation CrossEntropy: 1.2518\n","2025-06-07 12:56:43 [INFO]: Epoch 023 - training loss (CrossEntropy): 1246.7388, validation CrossEntropy: 1.2639\n","2025-06-07 12:56:47 [INFO]: Epoch 024 - training loss (CrossEntropy): 1246.8096, validation CrossEntropy: 1.2686\n","2025-06-07 12:56:52 [INFO]: Epoch 025 - training loss (CrossEntropy): 1238.7247, validation CrossEntropy: 1.2429\n","2025-06-07 12:56:56 [INFO]: Epoch 026 - training loss (CrossEntropy): 1240.6775, validation CrossEntropy: 1.2343\n","2025-06-07 12:57:00 [INFO]: Epoch 027 - training loss (CrossEntropy): 1236.8012, validation CrossEntropy: 1.2349\n","2025-06-07 12:57:04 [INFO]: Epoch 028 - training loss (CrossEntropy): 1235.4399, validation CrossEntropy: 1.2399\n","2025-06-07 12:57:08 [INFO]: Epoch 029 - training loss (CrossEntropy): 1227.3423, validation CrossEntropy: 1.2120\n","2025-06-07 12:57:12 [INFO]: Epoch 030 - training loss (CrossEntropy): 1227.5513, validation CrossEntropy: 1.2300\n","2025-06-07 12:57:12 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 12:57:12 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T125506/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 12:57:14 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:57:14 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125714\n","2025-06-07 12:57:14 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125714/tensorboard\n","2025-06-07 12:57:14 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:57:14 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:57:14 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 12:57:21 [INFO]: Epoch 001 - training loss (CrossEntropy): 1906.5020, validation CrossEntropy: 1.6546\n","2025-06-07 12:57:25 [INFO]: Epoch 002 - training loss (CrossEntropy): 1511.8402, validation CrossEntropy: 1.5768\n","2025-06-07 12:57:29 [INFO]: Epoch 003 - training loss (CrossEntropy): 1360.3854, validation CrossEntropy: 1.5568\n","2025-06-07 12:57:33 [INFO]: Epoch 004 - training loss (CrossEntropy): 1318.2714, validation CrossEntropy: 1.5221\n","2025-06-07 12:57:38 [INFO]: Epoch 005 - training loss (CrossEntropy): 1306.7230, validation CrossEntropy: 1.5074\n","2025-06-07 12:57:41 [INFO]: Epoch 006 - training loss (CrossEntropy): 1304.2635, validation CrossEntropy: 1.5044\n","2025-06-07 12:57:45 [INFO]: Epoch 007 - training loss (CrossEntropy): 1299.1221, validation CrossEntropy: 1.4834\n","2025-06-07 12:57:50 [INFO]: Epoch 008 - training loss (CrossEntropy): 1293.4950, validation CrossEntropy: 1.4411\n","2025-06-07 12:57:53 [INFO]: Epoch 009 - training loss (CrossEntropy): 1287.3464, validation CrossEntropy: 1.4984\n","2025-06-07 12:57:57 [INFO]: Epoch 010 - training loss (CrossEntropy): 1284.4826, validation CrossEntropy: 1.4777\n","2025-06-07 12:58:01 [INFO]: Epoch 011 - training loss (CrossEntropy): 1285.5786, validation CrossEntropy: 1.4519\n","2025-06-07 12:58:05 [INFO]: Epoch 012 - training loss (CrossEntropy): 1279.0070, validation CrossEntropy: 1.4452\n","2025-06-07 12:58:09 [INFO]: Epoch 013 - training loss (CrossEntropy): 1274.7316, validation CrossEntropy: 1.4396\n","2025-06-07 12:58:13 [INFO]: Epoch 014 - training loss (CrossEntropy): 1275.4929, validation CrossEntropy: 1.4219\n","2025-06-07 12:58:17 [INFO]: Epoch 015 - training loss (CrossEntropy): 1274.6110, validation CrossEntropy: 1.4140\n","2025-06-07 12:58:20 [INFO]: Epoch 016 - training loss (CrossEntropy): 1264.2913, validation CrossEntropy: 1.4011\n","2025-06-07 12:58:25 [INFO]: Epoch 017 - training loss (CrossEntropy): 1264.4465, validation CrossEntropy: 1.3947\n","2025-06-07 12:58:29 [INFO]: Epoch 018 - training loss (CrossEntropy): 1263.5506, validation CrossEntropy: 1.3809\n","2025-06-07 12:58:33 [INFO]: Epoch 019 - training loss (CrossEntropy): 1254.5997, validation CrossEntropy: 1.3737\n","2025-06-07 12:58:37 [INFO]: Epoch 020 - training loss (CrossEntropy): 1254.1693, validation CrossEntropy: 1.3611\n","2025-06-07 12:58:41 [INFO]: Epoch 021 - training loss (CrossEntropy): 1254.8308, validation CrossEntropy: 1.3511\n","2025-06-07 12:58:45 [INFO]: Epoch 022 - training loss (CrossEntropy): 1251.1969, validation CrossEntropy: 1.3480\n","2025-06-07 12:58:48 [INFO]: Epoch 023 - training loss (CrossEntropy): 1245.3520, validation CrossEntropy: 1.3703\n","2025-06-07 12:58:52 [INFO]: Epoch 024 - training loss (CrossEntropy): 1247.6354, validation CrossEntropy: 1.3429\n","2025-06-07 12:58:56 [INFO]: Epoch 025 - training loss (CrossEntropy): 1242.4179, validation CrossEntropy: 1.3386\n","2025-06-07 12:59:00 [INFO]: Epoch 026 - training loss (CrossEntropy): 1243.5244, validation CrossEntropy: 1.3388\n","2025-06-07 12:59:04 [INFO]: Epoch 027 - training loss (CrossEntropy): 1231.0029, validation CrossEntropy: 1.3249\n","2025-06-07 12:59:08 [INFO]: Epoch 028 - training loss (CrossEntropy): 1233.0315, validation CrossEntropy: 1.3242\n","2025-06-07 12:59:12 [INFO]: Epoch 029 - training loss (CrossEntropy): 1230.0877, validation CrossEntropy: 1.3069\n","2025-06-07 12:59:16 [INFO]: Epoch 030 - training loss (CrossEntropy): 1226.4037, validation CrossEntropy: 1.3070\n","2025-06-07 12:59:16 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 12:59:16 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T125714/BRITS.pypots\n","2025-06-07 12:59:18 [INFO]: No given device, using default device: cpu\n","2025-06-07 12:59:18 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125918\n","2025-06-07 12:59:18 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T125918/tensorboard\n","2025-06-07 12:59:18 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 12:59:18 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 12:59:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 12:59:25 [INFO]: Epoch 001 - training loss (CrossEntropy): 2160.2820, validation CrossEntropy: 1.6591\n","2025-06-07 12:59:28 [INFO]: Epoch 002 - training loss (CrossEntropy): 1622.2799, validation CrossEntropy: 1.6430\n","2025-06-07 12:59:32 [INFO]: Epoch 003 - training loss (CrossEntropy): 1398.5394, validation CrossEntropy: 1.6402\n","2025-06-07 12:59:36 [INFO]: Epoch 004 - training loss (CrossEntropy): 1326.4297, validation CrossEntropy: 1.5949\n","2025-06-07 12:59:40 [INFO]: Epoch 005 - training loss (CrossEntropy): 1318.1187, validation CrossEntropy: 1.5586\n","2025-06-07 12:59:44 [INFO]: Epoch 006 - training loss (CrossEntropy): 1309.8800, validation CrossEntropy: 1.5066\n","2025-06-07 12:59:48 [INFO]: Epoch 007 - training loss (CrossEntropy): 1300.2583, validation CrossEntropy: 1.4737\n","2025-06-07 12:59:51 [INFO]: Epoch 008 - training loss (CrossEntropy): 1297.4036, validation CrossEntropy: 1.4616\n","2025-06-07 12:59:55 [INFO]: Epoch 009 - training loss (CrossEntropy): 1295.3986, validation CrossEntropy: 1.4113\n","2025-06-07 12:59:59 [INFO]: Epoch 010 - training loss (CrossEntropy): 1287.4491, validation CrossEntropy: 1.4172\n","2025-06-07 13:00:03 [INFO]: Epoch 011 - training loss (CrossEntropy): 1287.0387, validation CrossEntropy: 1.3874\n","2025-06-07 13:00:07 [INFO]: Epoch 012 - training loss (CrossEntropy): 1279.2706, validation CrossEntropy: 1.4114\n","2025-06-07 13:00:10 [INFO]: Epoch 013 - training loss (CrossEntropy): 1278.7233, validation CrossEntropy: 1.3576\n","2025-06-07 13:00:14 [INFO]: Epoch 014 - training loss (CrossEntropy): 1276.0631, validation CrossEntropy: 1.3728\n","2025-06-07 13:00:18 [INFO]: Epoch 015 - training loss (CrossEntropy): 1271.3347, validation CrossEntropy: 1.4061\n","2025-06-07 13:00:22 [INFO]: Epoch 016 - training loss (CrossEntropy): 1268.0804, validation CrossEntropy: 1.4049\n","2025-06-07 13:00:26 [INFO]: Epoch 017 - training loss (CrossEntropy): 1263.6766, validation CrossEntropy: 1.4007\n","2025-06-07 13:00:30 [INFO]: Epoch 018 - training loss (CrossEntropy): 1260.0483, validation CrossEntropy: 1.3970\n","2025-06-07 13:00:33 [INFO]: Epoch 019 - training loss (CrossEntropy): 1255.1336, validation CrossEntropy: 1.3879\n","2025-06-07 13:00:33 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 13:00:33 [INFO]: Finished training. The best model is from epoch#13.\n","2025-06-07 13:00:33 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T125918/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:00:36 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:00:36 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130036\n","2025-06-07 13:00:36 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130036/tensorboard\n","2025-06-07 13:00:36 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:00:36 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:00:36 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:00:42 [INFO]: Epoch 001 - training loss (CrossEntropy): 2010.4665, validation CrossEntropy: 1.6610\n","2025-06-07 13:00:47 [INFO]: Epoch 002 - training loss (CrossEntropy): 1589.2766, validation CrossEntropy: 1.5977\n","2025-06-07 13:00:51 [INFO]: Epoch 003 - training loss (CrossEntropy): 1382.7977, validation CrossEntropy: 1.6388\n","2025-06-07 13:00:55 [INFO]: Epoch 004 - training loss (CrossEntropy): 1321.9765, validation CrossEntropy: 1.5984\n","2025-06-07 13:00:59 [INFO]: Epoch 005 - training loss (CrossEntropy): 1315.4251, validation CrossEntropy: 1.5489\n","2025-06-07 13:01:03 [INFO]: Epoch 006 - training loss (CrossEntropy): 1304.3421, validation CrossEntropy: 1.5250\n","2025-06-07 13:01:07 [INFO]: Epoch 007 - training loss (CrossEntropy): 1305.2719, validation CrossEntropy: 1.5171\n","2025-06-07 13:01:11 [INFO]: Epoch 008 - training loss (CrossEntropy): 1302.4909, validation CrossEntropy: 1.4910\n","2025-06-07 13:01:15 [INFO]: Epoch 009 - training loss (CrossEntropy): 1298.4904, validation CrossEntropy: 1.4480\n","2025-06-07 13:01:19 [INFO]: Epoch 010 - training loss (CrossEntropy): 1293.9190, validation CrossEntropy: 1.4346\n","2025-06-07 13:01:23 [INFO]: Epoch 011 - training loss (CrossEntropy): 1289.4180, validation CrossEntropy: 1.4001\n","2025-06-07 13:01:27 [INFO]: Epoch 012 - training loss (CrossEntropy): 1279.3007, validation CrossEntropy: 1.3860\n","2025-06-07 13:01:31 [INFO]: Epoch 013 - training loss (CrossEntropy): 1278.2152, validation CrossEntropy: 1.3723\n","2025-06-07 13:01:35 [INFO]: Epoch 014 - training loss (CrossEntropy): 1276.6120, validation CrossEntropy: 1.3836\n","2025-06-07 13:01:39 [INFO]: Epoch 015 - training loss (CrossEntropy): 1274.9960, validation CrossEntropy: 1.3804\n","2025-06-07 13:01:43 [INFO]: Epoch 016 - training loss (CrossEntropy): 1267.1505, validation CrossEntropy: 1.3580\n","2025-06-07 13:01:47 [INFO]: Epoch 017 - training loss (CrossEntropy): 1266.7145, validation CrossEntropy: 1.3796\n","2025-06-07 13:01:51 [INFO]: Epoch 018 - training loss (CrossEntropy): 1262.4488, validation CrossEntropy: 1.3394\n","2025-06-07 13:01:55 [INFO]: Epoch 019 - training loss (CrossEntropy): 1262.2079, validation CrossEntropy: 1.3209\n","2025-06-07 13:01:59 [INFO]: Epoch 020 - training loss (CrossEntropy): 1257.6308, validation CrossEntropy: 1.3087\n","2025-06-07 13:02:03 [INFO]: Epoch 021 - training loss (CrossEntropy): 1255.4861, validation CrossEntropy: 1.3320\n","2025-06-07 13:02:08 [INFO]: Epoch 022 - training loss (CrossEntropy): 1251.7151, validation CrossEntropy: 1.2972\n","2025-06-07 13:02:12 [INFO]: Epoch 023 - training loss (CrossEntropy): 1251.2140, validation CrossEntropy: 1.2780\n","2025-06-07 13:02:16 [INFO]: Epoch 024 - training loss (CrossEntropy): 1248.4424, validation CrossEntropy: 1.2851\n","2025-06-07 13:02:20 [INFO]: Epoch 025 - training loss (CrossEntropy): 1242.1861, validation CrossEntropy: 1.2805\n","2025-06-07 13:02:24 [INFO]: Epoch 026 - training loss (CrossEntropy): 1240.3243, validation CrossEntropy: 1.2666\n","2025-06-07 13:02:28 [INFO]: Epoch 027 - training loss (CrossEntropy): 1236.5347, validation CrossEntropy: 1.2408\n","2025-06-07 13:02:32 [INFO]: Epoch 028 - training loss (CrossEntropy): 1231.1986, validation CrossEntropy: 1.2447\n","2025-06-07 13:02:36 [INFO]: Epoch 029 - training loss (CrossEntropy): 1235.0059, validation CrossEntropy: 1.2609\n","2025-06-07 13:02:40 [INFO]: Epoch 030 - training loss (CrossEntropy): 1228.5669, validation CrossEntropy: 1.2579\n","2025-06-07 13:02:40 [INFO]: Finished training. The best model is from epoch#27.\n","2025-06-07 13:02:40 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T130036/BRITS.pypots\n"]},{"output_type":"stream","name":"stdout","text":["BRITS(rnn_hidden_size=32, classification_weight=1, reconstruction_weight=1) & 0.2327 ± 0.0600 & 0.0987 ± 0.0362 0.1255 ± 0.0854 0.1954 ± 0.0568 \\\n","[86.8244903087616, 125.73783826828003, 121.40227460861206, 75.36989617347717, 124.33925318717957]\n","106.7348 ± 21.2901\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["\n","rnn_hidden_size=16\n","classification_weight=1\n","reconstruction_weight=1\n","\n","run_model(\n","  lambda: BRITS(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    rnn_hidden_size=rnn_hidden_size,\n","    classification_weight=classification_weight,\n","    reconstruction_weight=reconstruction_weight,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/brits',\n","    model_saving_strategy='best'\n","  ),\n","  f\"BRITS({rnn_hidden_size=}, {classification_weight=}, {reconstruction_weight=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0H0hY8fcgly","executionInfo":{"status":"ok","timestamp":1749301708844,"user_tz":-120,"elapsed":346202,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"498e1319-021c-4140-f363-e95ff2748b29"},"id":"_0H0hY8fcgly","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 13:02:42 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:02:42 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130242\n","2025-06-07 13:02:42 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130242/tensorboard\n","2025-06-07 13:02:42 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:02:42 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:02:42 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 8,700\n","2025-06-07 13:02:49 [INFO]: Epoch 001 - training loss (CrossEntropy): 2040.3743, validation CrossEntropy: 1.7272\n","2025-06-07 13:02:53 [INFO]: Epoch 002 - training loss (CrossEntropy): 1591.2264, validation CrossEntropy: 1.6105\n","2025-06-07 13:02:57 [INFO]: Epoch 003 - training loss (CrossEntropy): 1395.6041, validation CrossEntropy: 1.5730\n","2025-06-07 13:03:00 [INFO]: Epoch 004 - training loss (CrossEntropy): 1330.6132, validation CrossEntropy: 1.6226\n","2025-06-07 13:03:04 [INFO]: Epoch 005 - training loss (CrossEntropy): 1319.6250, validation CrossEntropy: 1.6603\n","2025-06-07 13:03:08 [INFO]: Epoch 006 - training loss (CrossEntropy): 1310.8139, validation CrossEntropy: 1.6332\n","2025-06-07 13:03:12 [INFO]: Epoch 007 - training loss (CrossEntropy): 1309.9855, validation CrossEntropy: 1.6135\n","2025-06-07 13:03:15 [INFO]: Epoch 008 - training loss (CrossEntropy): 1298.7199, validation CrossEntropy: 1.5952\n","2025-06-07 13:03:19 [INFO]: Epoch 009 - training loss (CrossEntropy): 1300.1299, validation CrossEntropy: 1.5839\n","2025-06-07 13:03:19 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 13:03:19 [INFO]: Finished training. The best model is from epoch#3.\n","2025-06-07 13:03:19 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T130242/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:03:21 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:03:21 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130321\n","2025-06-07 13:03:21 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130321/tensorboard\n","2025-06-07 13:03:21 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:03:21 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:03:21 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 8,700\n","2025-06-07 13:03:28 [INFO]: Epoch 001 - training loss (CrossEntropy): 1932.5532, validation CrossEntropy: 1.7627\n","2025-06-07 13:03:32 [INFO]: Epoch 002 - training loss (CrossEntropy): 1531.3726, validation CrossEntropy: 1.7137\n","2025-06-07 13:03:36 [INFO]: Epoch 003 - training loss (CrossEntropy): 1378.3500, validation CrossEntropy: 1.7127\n","2025-06-07 13:03:39 [INFO]: Epoch 004 - training loss (CrossEntropy): 1328.5555, validation CrossEntropy: 1.6901\n","2025-06-07 13:03:43 [INFO]: Epoch 005 - training loss (CrossEntropy): 1312.5085, validation CrossEntropy: 1.6342\n","2025-06-07 13:03:47 [INFO]: Epoch 006 - training loss (CrossEntropy): 1309.7157, validation CrossEntropy: 1.7224\n","2025-06-07 13:03:50 [INFO]: Epoch 007 - training loss (CrossEntropy): 1307.3706, validation CrossEntropy: 1.6725\n","2025-06-07 13:03:54 [INFO]: Epoch 008 - training loss (CrossEntropy): 1295.3144, validation CrossEntropy: 1.6416\n","2025-06-07 13:03:58 [INFO]: Epoch 009 - training loss (CrossEntropy): 1293.9317, validation CrossEntropy: 1.6493\n","2025-06-07 13:04:01 [INFO]: Epoch 010 - training loss (CrossEntropy): 1293.2372, validation CrossEntropy: 1.6430\n","2025-06-07 13:04:05 [INFO]: Epoch 011 - training loss (CrossEntropy): 1283.8022, validation CrossEntropy: 1.6293\n","2025-06-07 13:04:09 [INFO]: Epoch 012 - training loss (CrossEntropy): 1284.3866, validation CrossEntropy: 1.6161\n","2025-06-07 13:04:12 [INFO]: Epoch 013 - training loss (CrossEntropy): 1280.8896, validation CrossEntropy: 1.5872\n","2025-06-07 13:04:16 [INFO]: Epoch 014 - training loss (CrossEntropy): 1274.2856, validation CrossEntropy: 1.5727\n","2025-06-07 13:04:20 [INFO]: Epoch 015 - training loss (CrossEntropy): 1273.4849, validation CrossEntropy: 1.5687\n","2025-06-07 13:04:23 [INFO]: Epoch 016 - training loss (CrossEntropy): 1271.7910, validation CrossEntropy: 1.5533\n","2025-06-07 13:04:27 [INFO]: Epoch 017 - training loss (CrossEntropy): 1269.2810, validation CrossEntropy: 1.5516\n","2025-06-07 13:04:30 [INFO]: Epoch 018 - training loss (CrossEntropy): 1264.4946, validation CrossEntropy: 1.5937\n","2025-06-07 13:04:34 [INFO]: Epoch 019 - training loss (CrossEntropy): 1262.2477, validation CrossEntropy: 1.5366\n","2025-06-07 13:04:37 [INFO]: Epoch 020 - training loss (CrossEntropy): 1259.1525, validation CrossEntropy: 1.5221\n","2025-06-07 13:04:41 [INFO]: Epoch 021 - training loss (CrossEntropy): 1254.0998, validation CrossEntropy: 1.5313\n","2025-06-07 13:04:45 [INFO]: Epoch 022 - training loss (CrossEntropy): 1256.1506, validation CrossEntropy: 1.5186\n","2025-06-07 13:04:49 [INFO]: Epoch 023 - training loss (CrossEntropy): 1249.5901, validation CrossEntropy: 1.5031\n","2025-06-07 13:04:52 [INFO]: Epoch 024 - training loss (CrossEntropy): 1244.1790, validation CrossEntropy: 1.4984\n","2025-06-07 13:04:56 [INFO]: Epoch 025 - training loss (CrossEntropy): 1242.2398, validation CrossEntropy: 1.4993\n","2025-06-07 13:04:59 [INFO]: Epoch 026 - training loss (CrossEntropy): 1248.2165, validation CrossEntropy: 1.4893\n","2025-06-07 13:05:03 [INFO]: Epoch 027 - training loss (CrossEntropy): 1240.2184, validation CrossEntropy: 1.4955\n","2025-06-07 13:05:07 [INFO]: Epoch 028 - training loss (CrossEntropy): 1235.3794, validation CrossEntropy: 1.4790\n","2025-06-07 13:05:10 [INFO]: Epoch 029 - training loss (CrossEntropy): 1236.6170, validation CrossEntropy: 1.4796\n","2025-06-07 13:05:14 [INFO]: Epoch 030 - training loss (CrossEntropy): 1233.0622, validation CrossEntropy: 1.4693\n","2025-06-07 13:05:14 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:05:14 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T130321/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:05:17 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:05:17 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130517\n","2025-06-07 13:05:17 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130517/tensorboard\n","2025-06-07 13:05:17 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:05:17 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:05:17 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 8,700\n","2025-06-07 13:05:23 [INFO]: Epoch 001 - training loss (CrossEntropy): 2079.0798, validation CrossEntropy: 1.7316\n","2025-06-07 13:05:27 [INFO]: Epoch 002 - training loss (CrossEntropy): 1616.6034, validation CrossEntropy: 1.6716\n","2025-06-07 13:05:31 [INFO]: Epoch 003 - training loss (CrossEntropy): 1401.0666, validation CrossEntropy: 1.6652\n","2025-06-07 13:05:34 [INFO]: Epoch 004 - training loss (CrossEntropy): 1326.6235, validation CrossEntropy: 1.6651\n","2025-06-07 13:05:38 [INFO]: Epoch 005 - training loss (CrossEntropy): 1325.0134, validation CrossEntropy: 1.6161\n","2025-06-07 13:05:42 [INFO]: Epoch 006 - training loss (CrossEntropy): 1315.8722, validation CrossEntropy: 1.6218\n","2025-06-07 13:05:46 [INFO]: Epoch 007 - training loss (CrossEntropy): 1310.7981, validation CrossEntropy: 1.5863\n","2025-06-07 13:05:49 [INFO]: Epoch 008 - training loss (CrossEntropy): 1302.4544, validation CrossEntropy: 1.6223\n","2025-06-07 13:05:53 [INFO]: Epoch 009 - training loss (CrossEntropy): 1299.8218, validation CrossEntropy: 1.6419\n","2025-06-07 13:05:57 [INFO]: Epoch 010 - training loss (CrossEntropy): 1295.3330, validation CrossEntropy: 1.6372\n","2025-06-07 13:06:01 [INFO]: Epoch 011 - training loss (CrossEntropy): 1291.5799, validation CrossEntropy: 1.6155\n","2025-06-07 13:06:05 [INFO]: Epoch 012 - training loss (CrossEntropy): 1290.2547, validation CrossEntropy: 1.6158\n","2025-06-07 13:06:09 [INFO]: Epoch 013 - training loss (CrossEntropy): 1285.2669, validation CrossEntropy: 1.6036\n","2025-06-07 13:06:09 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 13:06:09 [INFO]: Finished training. The best model is from epoch#7.\n","2025-06-07 13:06:09 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T130517/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:06:11 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:06:11 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130611\n","2025-06-07 13:06:11 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130611/tensorboard\n","2025-06-07 13:06:11 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:06:11 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:06:11 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 8,700\n","2025-06-07 13:06:17 [INFO]: Epoch 001 - training loss (CrossEntropy): 1946.9070, validation CrossEntropy: 1.7178\n","2025-06-07 13:06:21 [INFO]: Epoch 002 - training loss (CrossEntropy): 1550.9439, validation CrossEntropy: 1.6289\n","2025-06-07 13:06:25 [INFO]: Epoch 003 - training loss (CrossEntropy): 1381.4437, validation CrossEntropy: 1.6169\n","2025-06-07 13:06:29 [INFO]: Epoch 004 - training loss (CrossEntropy): 1324.6824, validation CrossEntropy: 1.6612\n","2025-06-07 13:06:33 [INFO]: Epoch 005 - training loss (CrossEntropy): 1311.4428, validation CrossEntropy: 1.6013\n","2025-06-07 13:06:36 [INFO]: Epoch 006 - training loss (CrossEntropy): 1307.4526, validation CrossEntropy: 1.5650\n","2025-06-07 13:06:40 [INFO]: Epoch 007 - training loss (CrossEntropy): 1307.8893, validation CrossEntropy: 1.6271\n","2025-06-07 13:06:44 [INFO]: Epoch 008 - training loss (CrossEntropy): 1300.5472, validation CrossEntropy: 1.6178\n","2025-06-07 13:06:48 [INFO]: Epoch 009 - training loss (CrossEntropy): 1293.0915, validation CrossEntropy: 1.6081\n","2025-06-07 13:06:52 [INFO]: Epoch 010 - training loss (CrossEntropy): 1293.6571, validation CrossEntropy: 1.5822\n","2025-06-07 13:06:56 [INFO]: Epoch 011 - training loss (CrossEntropy): 1285.9689, validation CrossEntropy: 1.5755\n","2025-06-07 13:07:00 [INFO]: Epoch 012 - training loss (CrossEntropy): 1283.7020, validation CrossEntropy: 1.5679\n","2025-06-07 13:07:00 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 13:07:00 [INFO]: Finished training. The best model is from epoch#6.\n","2025-06-07 13:07:00 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T130611/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:07:03 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:07:03 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130703\n","2025-06-07 13:07:03 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130703/tensorboard\n","2025-06-07 13:07:03 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:07:03 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:07:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 8,700\n","2025-06-07 13:07:10 [INFO]: Epoch 001 - training loss (CrossEntropy): 2043.0019, validation CrossEntropy: 1.7370\n","2025-06-07 13:07:14 [INFO]: Epoch 002 - training loss (CrossEntropy): 1569.6105, validation CrossEntropy: 1.6569\n","2025-06-07 13:07:18 [INFO]: Epoch 003 - training loss (CrossEntropy): 1370.8160, validation CrossEntropy: 1.6357\n","2025-06-07 13:07:23 [INFO]: Epoch 004 - training loss (CrossEntropy): 1328.6914, validation CrossEntropy: 1.6209\n","2025-06-07 13:07:26 [INFO]: Epoch 005 - training loss (CrossEntropy): 1322.2861, validation CrossEntropy: 1.6252\n","2025-06-07 13:07:31 [INFO]: Epoch 006 - training loss (CrossEntropy): 1313.1840, validation CrossEntropy: 1.6035\n","2025-06-07 13:07:35 [INFO]: Epoch 007 - training loss (CrossEntropy): 1304.5353, validation CrossEntropy: 1.6516\n","2025-06-07 13:07:39 [INFO]: Epoch 008 - training loss (CrossEntropy): 1304.5440, validation CrossEntropy: 1.5945\n","2025-06-07 13:07:43 [INFO]: Epoch 009 - training loss (CrossEntropy): 1299.8820, validation CrossEntropy: 1.6072\n","2025-06-07 13:07:47 [INFO]: Epoch 010 - training loss (CrossEntropy): 1294.0243, validation CrossEntropy: 1.6179\n","2025-06-07 13:07:50 [INFO]: Epoch 011 - training loss (CrossEntropy): 1295.3669, validation CrossEntropy: 1.5640\n","2025-06-07 13:07:55 [INFO]: Epoch 012 - training loss (CrossEntropy): 1290.0275, validation CrossEntropy: 1.5501\n","2025-06-07 13:07:59 [INFO]: Epoch 013 - training loss (CrossEntropy): 1284.2898, validation CrossEntropy: 1.5271\n","2025-06-07 13:08:03 [INFO]: Epoch 014 - training loss (CrossEntropy): 1281.2499, validation CrossEntropy: 1.5108\n","2025-06-07 13:08:07 [INFO]: Epoch 015 - training loss (CrossEntropy): 1276.0500, validation CrossEntropy: 1.5698\n","2025-06-07 13:08:11 [INFO]: Epoch 016 - training loss (CrossEntropy): 1268.3017, validation CrossEntropy: 1.5675\n","2025-06-07 13:08:15 [INFO]: Epoch 017 - training loss (CrossEntropy): 1269.3823, validation CrossEntropy: 1.5492\n","2025-06-07 13:08:19 [INFO]: Epoch 018 - training loss (CrossEntropy): 1270.1287, validation CrossEntropy: 1.5385\n","2025-06-07 13:08:22 [INFO]: Epoch 019 - training loss (CrossEntropy): 1262.7862, validation CrossEntropy: 1.5337\n","2025-06-07 13:08:26 [INFO]: Epoch 020 - training loss (CrossEntropy): 1257.7781, validation CrossEntropy: 1.5175\n","2025-06-07 13:08:26 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 13:08:26 [INFO]: Finished training. The best model is from epoch#14.\n","2025-06-07 13:08:26 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T130703/BRITS.pypots\n"]},{"output_type":"stream","name":"stdout","text":["BRITS(rnn_hidden_size=16, classification_weight=1, reconstruction_weight=1) & 0.2490 ± 0.0536 & 0.1316 ± 0.0357 0.1503 ± 0.0432 0.1995 ± 0.0426 \\\n","[36.68051218986511, 112.917409658432, 51.95389008522034, 49.39838147163391, 83.33440113067627]\n","66.8569 ± 27.6788\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["\n","rnn_hidden_size=64\n","classification_weight=2\n","reconstruction_weight=1\n","\n","run_model(\n","  lambda: BRITS(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    rnn_hidden_size=rnn_hidden_size,\n","    classification_weight=classification_weight,\n","    reconstruction_weight=reconstruction_weight,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/brits',\n","    model_saving_strategy='best'\n","  ),\n","  f\"BRITS({rnn_hidden_size=}, {classification_weight=}, {reconstruction_weight=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I36Q_Jctch5w","executionInfo":{"status":"ok","timestamp":1749302363728,"user_tz":-120,"elapsed":654879,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"62171040-a0d4-48e9-d186-d333a1628fdb"},"id":"I36Q_Jctch5w","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 13:08:28 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:08:28 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130828\n","2025-06-07 13:08:28 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T130828/tensorboard\n","2025-06-07 13:08:28 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:08:28 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:08:28 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:08:36 [INFO]: Epoch 001 - training loss (CrossEntropy): 1909.1517, validation CrossEntropy: 1.5402\n","2025-06-07 13:08:40 [INFO]: Epoch 002 - training loss (CrossEntropy): 1512.0806, validation CrossEntropy: 1.4451\n","2025-06-07 13:08:44 [INFO]: Epoch 003 - training loss (CrossEntropy): 1361.3091, validation CrossEntropy: 1.3827\n","2025-06-07 13:08:49 [INFO]: Epoch 004 - training loss (CrossEntropy): 1322.0424, validation CrossEntropy: 1.3606\n","2025-06-07 13:08:54 [INFO]: Epoch 005 - training loss (CrossEntropy): 1316.0060, validation CrossEntropy: 1.3436\n","2025-06-07 13:08:58 [INFO]: Epoch 006 - training loss (CrossEntropy): 1309.3497, validation CrossEntropy: 1.3194\n","2025-06-07 13:09:03 [INFO]: Epoch 007 - training loss (CrossEntropy): 1303.9995, validation CrossEntropy: 1.2916\n","2025-06-07 13:09:07 [INFO]: Epoch 008 - training loss (CrossEntropy): 1301.3045, validation CrossEntropy: 1.2344\n","2025-06-07 13:09:11 [INFO]: Epoch 009 - training loss (CrossEntropy): 1294.2578, validation CrossEntropy: 1.2021\n","2025-06-07 13:09:16 [INFO]: Epoch 010 - training loss (CrossEntropy): 1293.4703, validation CrossEntropy: 1.1747\n","2025-06-07 13:09:20 [INFO]: Epoch 011 - training loss (CrossEntropy): 1285.5624, validation CrossEntropy: 1.1644\n","2025-06-07 13:09:24 [INFO]: Epoch 012 - training loss (CrossEntropy): 1279.7288, validation CrossEntropy: 1.1504\n","2025-06-07 13:09:29 [INFO]: Epoch 013 - training loss (CrossEntropy): 1277.1556, validation CrossEntropy: 1.1269\n","2025-06-07 13:09:33 [INFO]: Epoch 014 - training loss (CrossEntropy): 1270.6750, validation CrossEntropy: 1.1192\n","2025-06-07 13:09:37 [INFO]: Epoch 015 - training loss (CrossEntropy): 1268.7486, validation CrossEntropy: 1.0954\n","2025-06-07 13:09:41 [INFO]: Epoch 016 - training loss (CrossEntropy): 1267.9568, validation CrossEntropy: 1.0847\n","2025-06-07 13:09:46 [INFO]: Epoch 017 - training loss (CrossEntropy): 1263.3479, validation CrossEntropy: 1.1011\n","2025-06-07 13:09:50 [INFO]: Epoch 018 - training loss (CrossEntropy): 1260.8801, validation CrossEntropy: 1.0744\n","2025-06-07 13:09:54 [INFO]: Epoch 019 - training loss (CrossEntropy): 1258.7191, validation CrossEntropy: 1.0840\n","2025-06-07 13:09:59 [INFO]: Epoch 020 - training loss (CrossEntropy): 1253.6820, validation CrossEntropy: 1.0718\n","2025-06-07 13:10:03 [INFO]: Epoch 021 - training loss (CrossEntropy): 1249.6070, validation CrossEntropy: 1.0464\n","2025-06-07 13:10:07 [INFO]: Epoch 022 - training loss (CrossEntropy): 1251.2932, validation CrossEntropy: 1.0604\n","2025-06-07 13:10:11 [INFO]: Epoch 023 - training loss (CrossEntropy): 1244.1874, validation CrossEntropy: 1.0310\n","2025-06-07 13:10:16 [INFO]: Epoch 024 - training loss (CrossEntropy): 1238.0236, validation CrossEntropy: 1.0596\n","2025-06-07 13:10:20 [INFO]: Epoch 025 - training loss (CrossEntropy): 1244.1568, validation CrossEntropy: 1.0310\n","2025-06-07 13:10:24 [INFO]: Epoch 026 - training loss (CrossEntropy): 1237.8711, validation CrossEntropy: 1.0377\n","2025-06-07 13:10:28 [INFO]: Epoch 027 - training loss (CrossEntropy): 1231.6805, validation CrossEntropy: 1.0447\n","2025-06-07 13:10:33 [INFO]: Epoch 028 - training loss (CrossEntropy): 1228.0331, validation CrossEntropy: 1.0208\n","2025-06-07 13:10:37 [INFO]: Epoch 029 - training loss (CrossEntropy): 1230.2212, validation CrossEntropy: 1.0195\n","2025-06-07 13:10:41 [INFO]: Epoch 030 - training loss (CrossEntropy): 1224.9797, validation CrossEntropy: 1.0151\n","2025-06-07 13:10:41 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:10:41 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T130828/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:10:43 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:10:43 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131043\n","2025-06-07 13:10:43 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131043/tensorboard\n","2025-06-07 13:10:43 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:10:43 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:10:43 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:10:50 [INFO]: Epoch 001 - training loss (CrossEntropy): 2016.0292, validation CrossEntropy: 1.5290\n","2025-06-07 13:10:55 [INFO]: Epoch 002 - training loss (CrossEntropy): 1564.8932, validation CrossEntropy: 1.4099\n","2025-06-07 13:10:59 [INFO]: Epoch 003 - training loss (CrossEntropy): 1367.7480, validation CrossEntropy: 1.3968\n","2025-06-07 13:11:03 [INFO]: Epoch 004 - training loss (CrossEntropy): 1318.7379, validation CrossEntropy: 1.3653\n","2025-06-07 13:11:08 [INFO]: Epoch 005 - training loss (CrossEntropy): 1314.6375, validation CrossEntropy: 1.3527\n","2025-06-07 13:11:12 [INFO]: Epoch 006 - training loss (CrossEntropy): 1306.7146, validation CrossEntropy: 1.3333\n","2025-06-07 13:11:16 [INFO]: Epoch 007 - training loss (CrossEntropy): 1300.1020, validation CrossEntropy: 1.2929\n","2025-06-07 13:11:20 [INFO]: Epoch 008 - training loss (CrossEntropy): 1295.9591, validation CrossEntropy: 1.2562\n","2025-06-07 13:11:24 [INFO]: Epoch 009 - training loss (CrossEntropy): 1289.4901, validation CrossEntropy: 1.2519\n","2025-06-07 13:11:29 [INFO]: Epoch 010 - training loss (CrossEntropy): 1284.4380, validation CrossEntropy: 1.2234\n","2025-06-07 13:11:33 [INFO]: Epoch 011 - training loss (CrossEntropy): 1285.3161, validation CrossEntropy: 1.1960\n","2025-06-07 13:11:37 [INFO]: Epoch 012 - training loss (CrossEntropy): 1280.8261, validation CrossEntropy: 1.1875\n","2025-06-07 13:11:42 [INFO]: Epoch 013 - training loss (CrossEntropy): 1273.9828, validation CrossEntropy: 1.1791\n","2025-06-07 13:11:46 [INFO]: Epoch 014 - training loss (CrossEntropy): 1270.3328, validation CrossEntropy: 1.1882\n","2025-06-07 13:11:50 [INFO]: Epoch 015 - training loss (CrossEntropy): 1270.0154, validation CrossEntropy: 1.1593\n","2025-06-07 13:11:55 [INFO]: Epoch 016 - training loss (CrossEntropy): 1265.0170, validation CrossEntropy: 1.1430\n","2025-06-07 13:11:59 [INFO]: Epoch 017 - training loss (CrossEntropy): 1263.2945, validation CrossEntropy: 1.1228\n","2025-06-07 13:12:04 [INFO]: Epoch 018 - training loss (CrossEntropy): 1261.7691, validation CrossEntropy: 1.1182\n","2025-06-07 13:12:08 [INFO]: Epoch 019 - training loss (CrossEntropy): 1257.1273, validation CrossEntropy: 1.1019\n","2025-06-07 13:12:12 [INFO]: Epoch 020 - training loss (CrossEntropy): 1255.5168, validation CrossEntropy: 1.0958\n","2025-06-07 13:12:17 [INFO]: Epoch 021 - training loss (CrossEntropy): 1250.9085, validation CrossEntropy: 1.0921\n","2025-06-07 13:12:21 [INFO]: Epoch 022 - training loss (CrossEntropy): 1250.0373, validation CrossEntropy: 1.0871\n","2025-06-07 13:12:26 [INFO]: Epoch 023 - training loss (CrossEntropy): 1246.9552, validation CrossEntropy: 1.0858\n","2025-06-07 13:12:30 [INFO]: Epoch 024 - training loss (CrossEntropy): 1240.7815, validation CrossEntropy: 1.0708\n","2025-06-07 13:12:34 [INFO]: Epoch 025 - training loss (CrossEntropy): 1239.7566, validation CrossEntropy: 1.0770\n","2025-06-07 13:12:39 [INFO]: Epoch 026 - training loss (CrossEntropy): 1237.2753, validation CrossEntropy: 1.0649\n","2025-06-07 13:12:43 [INFO]: Epoch 027 - training loss (CrossEntropy): 1233.9442, validation CrossEntropy: 1.0383\n","2025-06-07 13:12:48 [INFO]: Epoch 028 - training loss (CrossEntropy): 1230.8128, validation CrossEntropy: 1.0372\n","2025-06-07 13:12:52 [INFO]: Epoch 029 - training loss (CrossEntropy): 1227.4407, validation CrossEntropy: 1.0448\n","2025-06-07 13:12:56 [INFO]: Epoch 030 - training loss (CrossEntropy): 1223.7290, validation CrossEntropy: 1.0358\n","2025-06-07 13:12:56 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:12:56 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T131043/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:12:59 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:12:59 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131259\n","2025-06-07 13:12:59 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131259/tensorboard\n","2025-06-07 13:12:59 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:12:59 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:12:59 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:13:06 [INFO]: Epoch 001 - training loss (CrossEntropy): 2086.4892, validation CrossEntropy: 1.5173\n","2025-06-07 13:13:11 [INFO]: Epoch 002 - training loss (CrossEntropy): 1597.4755, validation CrossEntropy: 1.3889\n","2025-06-07 13:13:15 [INFO]: Epoch 003 - training loss (CrossEntropy): 1388.8538, validation CrossEntropy: 1.3741\n","2025-06-07 13:13:19 [INFO]: Epoch 004 - training loss (CrossEntropy): 1322.6023, validation CrossEntropy: 1.3467\n","2025-06-07 13:13:24 [INFO]: Epoch 005 - training loss (CrossEntropy): 1309.5656, validation CrossEntropy: 1.2872\n","2025-06-07 13:13:28 [INFO]: Epoch 006 - training loss (CrossEntropy): 1311.9895, validation CrossEntropy: 1.2766\n","2025-06-07 13:13:32 [INFO]: Epoch 007 - training loss (CrossEntropy): 1297.3437, validation CrossEntropy: 1.2511\n","2025-06-07 13:13:37 [INFO]: Epoch 008 - training loss (CrossEntropy): 1294.7500, validation CrossEntropy: 1.2721\n","2025-06-07 13:13:41 [INFO]: Epoch 009 - training loss (CrossEntropy): 1290.6641, validation CrossEntropy: 1.2578\n","2025-06-07 13:13:45 [INFO]: Epoch 010 - training loss (CrossEntropy): 1288.3351, validation CrossEntropy: 1.2345\n","2025-06-07 13:13:50 [INFO]: Epoch 011 - training loss (CrossEntropy): 1280.8884, validation CrossEntropy: 1.2005\n","2025-06-07 13:13:54 [INFO]: Epoch 012 - training loss (CrossEntropy): 1277.6327, validation CrossEntropy: 1.2368\n","2025-06-07 13:13:58 [INFO]: Epoch 013 - training loss (CrossEntropy): 1276.6516, validation CrossEntropy: 1.1735\n","2025-06-07 13:14:02 [INFO]: Epoch 014 - training loss (CrossEntropy): 1276.4049, validation CrossEntropy: 1.1971\n","2025-06-07 13:14:06 [INFO]: Epoch 015 - training loss (CrossEntropy): 1269.8134, validation CrossEntropy: 1.1597\n","2025-06-07 13:14:11 [INFO]: Epoch 016 - training loss (CrossEntropy): 1263.7305, validation CrossEntropy: 1.1525\n","2025-06-07 13:14:15 [INFO]: Epoch 017 - training loss (CrossEntropy): 1261.3253, validation CrossEntropy: 1.1485\n","2025-06-07 13:14:19 [INFO]: Epoch 018 - training loss (CrossEntropy): 1259.5359, validation CrossEntropy: 1.1670\n","2025-06-07 13:14:23 [INFO]: Epoch 019 - training loss (CrossEntropy): 1253.4394, validation CrossEntropy: 1.1379\n","2025-06-07 13:14:27 [INFO]: Epoch 020 - training loss (CrossEntropy): 1251.1512, validation CrossEntropy: 1.1316\n","2025-06-07 13:14:31 [INFO]: Epoch 021 - training loss (CrossEntropy): 1251.3947, validation CrossEntropy: 1.1847\n","2025-06-07 13:14:35 [INFO]: Epoch 022 - training loss (CrossEntropy): 1245.1935, validation CrossEntropy: 1.1928\n","2025-06-07 13:14:39 [INFO]: Epoch 023 - training loss (CrossEntropy): 1240.7012, validation CrossEntropy: 1.1734\n","2025-06-07 13:14:44 [INFO]: Epoch 024 - training loss (CrossEntropy): 1241.8971, validation CrossEntropy: 1.1586\n","2025-06-07 13:14:48 [INFO]: Epoch 025 - training loss (CrossEntropy): 1240.5398, validation CrossEntropy: 1.1564\n","2025-06-07 13:14:52 [INFO]: Epoch 026 - training loss (CrossEntropy): 1238.2351, validation CrossEntropy: 1.1407\n","2025-06-07 13:14:52 [INFO]: Exceeded the training patience. Terminating the training procedure...\n","2025-06-07 13:14:52 [INFO]: Finished training. The best model is from epoch#20.\n","2025-06-07 13:14:52 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T131259/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:14:54 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:14:54 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131454\n","2025-06-07 13:14:54 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131454/tensorboard\n","2025-06-07 13:14:54 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:14:54 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:14:54 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:15:01 [INFO]: Epoch 001 - training loss (CrossEntropy): 1976.4282, validation CrossEntropy: 1.5376\n","2025-06-07 13:15:05 [INFO]: Epoch 002 - training loss (CrossEntropy): 1553.3152, validation CrossEntropy: 1.4530\n","2025-06-07 13:15:09 [INFO]: Epoch 003 - training loss (CrossEntropy): 1384.5365, validation CrossEntropy: 1.3733\n","2025-06-07 13:15:13 [INFO]: Epoch 004 - training loss (CrossEntropy): 1323.1997, validation CrossEntropy: 1.3182\n","2025-06-07 13:15:18 [INFO]: Epoch 005 - training loss (CrossEntropy): 1311.5758, validation CrossEntropy: 1.2795\n","2025-06-07 13:15:21 [INFO]: Epoch 006 - training loss (CrossEntropy): 1308.7130, validation CrossEntropy: 1.2691\n","2025-06-07 13:15:25 [INFO]: Epoch 007 - training loss (CrossEntropy): 1297.6483, validation CrossEntropy: 1.2194\n","2025-06-07 13:15:30 [INFO]: Epoch 008 - training loss (CrossEntropy): 1293.6530, validation CrossEntropy: 1.1832\n","2025-06-07 13:15:33 [INFO]: Epoch 009 - training loss (CrossEntropy): 1289.6822, validation CrossEntropy: 1.1764\n","2025-06-07 13:15:37 [INFO]: Epoch 010 - training loss (CrossEntropy): 1286.6109, validation CrossEntropy: 1.1512\n","2025-06-07 13:15:42 [INFO]: Epoch 011 - training loss (CrossEntropy): 1281.9228, validation CrossEntropy: 1.1520\n","2025-06-07 13:15:46 [INFO]: Epoch 012 - training loss (CrossEntropy): 1273.4035, validation CrossEntropy: 1.1392\n","2025-06-07 13:15:51 [INFO]: Epoch 013 - training loss (CrossEntropy): 1277.4747, validation CrossEntropy: 1.1499\n","2025-06-07 13:15:55 [INFO]: Epoch 014 - training loss (CrossEntropy): 1267.3715, validation CrossEntropy: 1.1394\n","2025-06-07 13:15:59 [INFO]: Epoch 015 - training loss (CrossEntropy): 1264.7843, validation CrossEntropy: 1.1114\n","2025-06-07 13:16:04 [INFO]: Epoch 016 - training loss (CrossEntropy): 1263.9296, validation CrossEntropy: 1.1214\n","2025-06-07 13:16:08 [INFO]: Epoch 017 - training loss (CrossEntropy): 1261.9176, validation CrossEntropy: 1.1139\n","2025-06-07 13:16:12 [INFO]: Epoch 018 - training loss (CrossEntropy): 1258.7679, validation CrossEntropy: 1.1200\n","2025-06-07 13:16:16 [INFO]: Epoch 019 - training loss (CrossEntropy): 1255.6093, validation CrossEntropy: 1.1048\n","2025-06-07 13:16:21 [INFO]: Epoch 020 - training loss (CrossEntropy): 1254.3187, validation CrossEntropy: 1.1122\n","2025-06-07 13:16:25 [INFO]: Epoch 021 - training loss (CrossEntropy): 1252.3456, validation CrossEntropy: 1.1092\n","2025-06-07 13:16:29 [INFO]: Epoch 022 - training loss (CrossEntropy): 1246.3120, validation CrossEntropy: 1.0835\n","2025-06-07 13:16:33 [INFO]: Epoch 023 - training loss (CrossEntropy): 1243.7458, validation CrossEntropy: 1.0841\n","2025-06-07 13:16:38 [INFO]: Epoch 024 - training loss (CrossEntropy): 1239.7597, validation CrossEntropy: 1.0830\n","2025-06-07 13:16:42 [INFO]: Epoch 025 - training loss (CrossEntropy): 1233.6038, validation CrossEntropy: 1.0704\n","2025-06-07 13:16:46 [INFO]: Epoch 026 - training loss (CrossEntropy): 1236.9772, validation CrossEntropy: 1.0498\n","2025-06-07 13:16:51 [INFO]: Epoch 027 - training loss (CrossEntropy): 1236.4711, validation CrossEntropy: 1.0498\n","2025-06-07 13:16:55 [INFO]: Epoch 028 - training loss (CrossEntropy): 1226.9665, validation CrossEntropy: 1.0827\n","2025-06-07 13:16:59 [INFO]: Epoch 029 - training loss (CrossEntropy): 1223.7269, validation CrossEntropy: 1.0295\n","2025-06-07 13:17:03 [INFO]: Epoch 030 - training loss (CrossEntropy): 1220.7267, validation CrossEntropy: 1.0238\n","2025-06-07 13:17:03 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:17:03 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T131454/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:17:06 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:17:06 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131706\n","2025-06-07 13:17:06 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131706/tensorboard\n","2025-06-07 13:17:06 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:17:06 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:17:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:17:13 [INFO]: Epoch 001 - training loss (CrossEntropy): 2177.1542, validation CrossEntropy: 1.5332\n","2025-06-07 13:17:18 [INFO]: Epoch 002 - training loss (CrossEntropy): 1667.9365, validation CrossEntropy: 1.3857\n","2025-06-07 13:17:22 [INFO]: Epoch 003 - training loss (CrossEntropy): 1418.3193, validation CrossEntropy: 1.3910\n","2025-06-07 13:17:26 [INFO]: Epoch 004 - training loss (CrossEntropy): 1328.7412, validation CrossEntropy: 1.3324\n","2025-06-07 13:17:31 [INFO]: Epoch 005 - training loss (CrossEntropy): 1311.6115, validation CrossEntropy: 1.3007\n","2025-06-07 13:17:35 [INFO]: Epoch 006 - training loss (CrossEntropy): 1303.6193, validation CrossEntropy: 1.2560\n","2025-06-07 13:17:39 [INFO]: Epoch 007 - training loss (CrossEntropy): 1302.8564, validation CrossEntropy: 1.2855\n","2025-06-07 13:17:44 [INFO]: Epoch 008 - training loss (CrossEntropy): 1296.2202, validation CrossEntropy: 1.2562\n","2025-06-07 13:17:48 [INFO]: Epoch 009 - training loss (CrossEntropy): 1290.5413, validation CrossEntropy: 1.2235\n","2025-06-07 13:17:53 [INFO]: Epoch 010 - training loss (CrossEntropy): 1287.1026, validation CrossEntropy: 1.2184\n","2025-06-07 13:17:58 [INFO]: Epoch 011 - training loss (CrossEntropy): 1284.0762, validation CrossEntropy: 1.1800\n","2025-06-07 13:18:02 [INFO]: Epoch 012 - training loss (CrossEntropy): 1277.9230, validation CrossEntropy: 1.1926\n","2025-06-07 13:18:06 [INFO]: Epoch 013 - training loss (CrossEntropy): 1278.0748, validation CrossEntropy: 1.1597\n","2025-06-07 13:18:11 [INFO]: Epoch 014 - training loss (CrossEntropy): 1272.8592, validation CrossEntropy: 1.1674\n","2025-06-07 13:18:15 [INFO]: Epoch 015 - training loss (CrossEntropy): 1269.5970, validation CrossEntropy: 1.1895\n","2025-06-07 13:18:20 [INFO]: Epoch 016 - training loss (CrossEntropy): 1266.0179, validation CrossEntropy: 1.1646\n","2025-06-07 13:18:24 [INFO]: Epoch 017 - training loss (CrossEntropy): 1262.5396, validation CrossEntropy: 1.1630\n","2025-06-07 13:18:28 [INFO]: Epoch 018 - training loss (CrossEntropy): 1257.7199, validation CrossEntropy: 1.1310\n","2025-06-07 13:18:33 [INFO]: Epoch 019 - training loss (CrossEntropy): 1256.4714, validation CrossEntropy: 1.1319\n","2025-06-07 13:18:38 [INFO]: Epoch 020 - training loss (CrossEntropy): 1252.4044, validation CrossEntropy: 1.1201\n","2025-06-07 13:18:42 [INFO]: Epoch 021 - training loss (CrossEntropy): 1250.0997, validation CrossEntropy: 1.1189\n","2025-06-07 13:18:47 [INFO]: Epoch 022 - training loss (CrossEntropy): 1244.9083, validation CrossEntropy: 1.1049\n","2025-06-07 13:18:51 [INFO]: Epoch 023 - training loss (CrossEntropy): 1245.3861, validation CrossEntropy: 1.0934\n","2025-06-07 13:18:55 [INFO]: Epoch 024 - training loss (CrossEntropy): 1245.9151, validation CrossEntropy: 1.1008\n","2025-06-07 13:19:00 [INFO]: Epoch 025 - training loss (CrossEntropy): 1242.9323, validation CrossEntropy: 1.0988\n","2025-06-07 13:19:04 [INFO]: Epoch 026 - training loss (CrossEntropy): 1235.2182, validation CrossEntropy: 1.0678\n","2025-06-07 13:19:08 [INFO]: Epoch 027 - training loss (CrossEntropy): 1236.3240, validation CrossEntropy: 1.0688\n","2025-06-07 13:19:12 [INFO]: Epoch 028 - training loss (CrossEntropy): 1232.6275, validation CrossEntropy: 1.0968\n","2025-06-07 13:19:17 [INFO]: Epoch 029 - training loss (CrossEntropy): 1227.0141, validation CrossEntropy: 1.0549\n","2025-06-07 13:19:21 [INFO]: Epoch 030 - training loss (CrossEntropy): 1225.5727, validation CrossEntropy: 1.0602\n","2025-06-07 13:19:21 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 13:19:21 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T131706/BRITS.pypots\n"]},{"output_type":"stream","name":"stdout","text":["BRITS(rnn_hidden_size=64, classification_weight=2, reconstruction_weight=1) & 0.2316 ± 0.0085 & 0.0997 ± 0.0147 0.1157 ± 0.0811 0.1995 ± 0.0120 \\\n","[132.5286250114441, 132.90294933319092, 112.51139116287231, 129.33488368988037, 135.12255811691284]\n","128.4801 ± 8.1952\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["\n","rnn_hidden_size=32\n","classification_weight=2\n","reconstruction_weight=1\n","\n","run_model(\n","  lambda: BRITS(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    rnn_hidden_size=rnn_hidden_size,\n","    classification_weight=classification_weight,\n","    reconstruction_weight=reconstruction_weight,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/brits',\n","    model_saving_strategy='best'\n","  ),\n","  f\"BRITS({rnn_hidden_size=}, {classification_weight=}, {reconstruction_weight=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FKnet-Oxcj4G","executionInfo":{"status":"ok","timestamp":1749302988300,"user_tz":-120,"elapsed":624566,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"0f47674c-1c65-410a-d93a-9393407002cc"},"id":"FKnet-Oxcj4G","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 13:19:23 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:19:23 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131923\n","2025-06-07 13:19:23 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T131923/tensorboard\n","2025-06-07 13:19:23 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:19:23 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:19:23 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:19:31 [INFO]: Epoch 001 - training loss (CrossEntropy): 1936.0760, validation CrossEntropy: 1.6423\n","2025-06-07 13:19:35 [INFO]: Epoch 002 - training loss (CrossEntropy): 1557.2403, validation CrossEntropy: 1.5339\n","2025-06-07 13:19:39 [INFO]: Epoch 003 - training loss (CrossEntropy): 1372.5416, validation CrossEntropy: 1.4375\n","2025-06-07 13:19:43 [INFO]: Epoch 004 - training loss (CrossEntropy): 1321.8852, validation CrossEntropy: 1.4007\n","2025-06-07 13:19:47 [INFO]: Epoch 005 - training loss (CrossEntropy): 1317.0963, validation CrossEntropy: 1.4126\n","2025-06-07 13:19:51 [INFO]: Epoch 006 - training loss (CrossEntropy): 1309.0986, validation CrossEntropy: 1.3944\n","2025-06-07 13:19:55 [INFO]: Epoch 007 - training loss (CrossEntropy): 1303.4588, validation CrossEntropy: 1.3748\n","2025-06-07 13:19:59 [INFO]: Epoch 008 - training loss (CrossEntropy): 1301.2447, validation CrossEntropy: 1.3515\n","2025-06-07 13:20:03 [INFO]: Epoch 009 - training loss (CrossEntropy): 1294.3233, validation CrossEntropy: 1.3246\n","2025-06-07 13:20:07 [INFO]: Epoch 010 - training loss (CrossEntropy): 1291.2755, validation CrossEntropy: 1.3054\n","2025-06-07 13:20:11 [INFO]: Epoch 011 - training loss (CrossEntropy): 1288.7030, validation CrossEntropy: 1.3012\n","2025-06-07 13:20:15 [INFO]: Epoch 012 - training loss (CrossEntropy): 1282.1161, validation CrossEntropy: 1.2726\n","2025-06-07 13:20:19 [INFO]: Epoch 013 - training loss (CrossEntropy): 1278.1904, validation CrossEntropy: 1.2541\n","2025-06-07 13:20:23 [INFO]: Epoch 014 - training loss (CrossEntropy): 1274.6827, validation CrossEntropy: 1.2614\n","2025-06-07 13:20:27 [INFO]: Epoch 015 - training loss (CrossEntropy): 1277.9616, validation CrossEntropy: 1.2293\n","2025-06-07 13:20:31 [INFO]: Epoch 016 - training loss (CrossEntropy): 1270.5837, validation CrossEntropy: 1.2342\n","2025-06-07 13:20:34 [INFO]: Epoch 017 - training loss (CrossEntropy): 1267.4448, validation CrossEntropy: 1.2054\n","2025-06-07 13:20:39 [INFO]: Epoch 018 - training loss (CrossEntropy): 1264.2673, validation CrossEntropy: 1.1984\n","2025-06-07 13:20:42 [INFO]: Epoch 019 - training loss (CrossEntropy): 1262.5309, validation CrossEntropy: 1.1956\n","2025-06-07 13:20:46 [INFO]: Epoch 020 - training loss (CrossEntropy): 1261.0144, validation CrossEntropy: 1.2097\n","2025-06-07 13:20:50 [INFO]: Epoch 021 - training loss (CrossEntropy): 1251.3454, validation CrossEntropy: 1.2013\n","2025-06-07 13:20:54 [INFO]: Epoch 022 - training loss (CrossEntropy): 1249.8375, validation CrossEntropy: 1.2411\n","2025-06-07 13:20:58 [INFO]: Epoch 023 - training loss (CrossEntropy): 1249.8498, validation CrossEntropy: 1.2030\n","2025-06-07 13:21:02 [INFO]: Epoch 024 - training loss (CrossEntropy): 1245.8761, validation CrossEntropy: 1.1767\n","2025-06-07 13:21:06 [INFO]: Epoch 025 - training loss (CrossEntropy): 1240.2304, validation CrossEntropy: 1.1771\n","2025-06-07 13:21:10 [INFO]: Epoch 026 - training loss (CrossEntropy): 1238.7571, validation CrossEntropy: 1.1672\n","2025-06-07 13:21:15 [INFO]: Epoch 027 - training loss (CrossEntropy): 1235.5360, validation CrossEntropy: 1.2023\n","2025-06-07 13:21:19 [INFO]: Epoch 028 - training loss (CrossEntropy): 1236.3704, validation CrossEntropy: 1.1675\n","2025-06-07 13:21:23 [INFO]: Epoch 029 - training loss (CrossEntropy): 1236.3853, validation CrossEntropy: 1.1679\n","2025-06-07 13:21:27 [INFO]: Epoch 030 - training loss (CrossEntropy): 1228.0554, validation CrossEntropy: 1.1479\n","2025-06-07 13:21:27 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:21:27 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T131923/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:21:29 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:21:29 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132129\n","2025-06-07 13:21:29 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132129/tensorboard\n","2025-06-07 13:21:29 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:21:29 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:21:29 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:21:36 [INFO]: Epoch 001 - training loss (CrossEntropy): 1803.7829, validation CrossEntropy: 1.6261\n","2025-06-07 13:21:40 [INFO]: Epoch 002 - training loss (CrossEntropy): 1463.0781, validation CrossEntropy: 1.5400\n","2025-06-07 13:21:43 [INFO]: Epoch 003 - training loss (CrossEntropy): 1345.6359, validation CrossEntropy: 1.4830\n","2025-06-07 13:21:47 [INFO]: Epoch 004 - training loss (CrossEntropy): 1317.8644, validation CrossEntropy: 1.4652\n","2025-06-07 13:21:51 [INFO]: Epoch 005 - training loss (CrossEntropy): 1313.5073, validation CrossEntropy: 1.4360\n","2025-06-07 13:21:55 [INFO]: Epoch 006 - training loss (CrossEntropy): 1305.2261, validation CrossEntropy: 1.3904\n","2025-06-07 13:21:59 [INFO]: Epoch 007 - training loss (CrossEntropy): 1298.2564, validation CrossEntropy: 1.3976\n","2025-06-07 13:22:03 [INFO]: Epoch 008 - training loss (CrossEntropy): 1291.6032, validation CrossEntropy: 1.3810\n","2025-06-07 13:22:07 [INFO]: Epoch 009 - training loss (CrossEntropy): 1289.7204, validation CrossEntropy: 1.3676\n","2025-06-07 13:22:11 [INFO]: Epoch 010 - training loss (CrossEntropy): 1286.4164, validation CrossEntropy: 1.3923\n","2025-06-07 13:22:15 [INFO]: Epoch 011 - training loss (CrossEntropy): 1282.7179, validation CrossEntropy: 1.3966\n","2025-06-07 13:22:19 [INFO]: Epoch 012 - training loss (CrossEntropy): 1284.8712, validation CrossEntropy: 1.3559\n","2025-06-07 13:22:23 [INFO]: Epoch 013 - training loss (CrossEntropy): 1276.1375, validation CrossEntropy: 1.3404\n","2025-06-07 13:22:27 [INFO]: Epoch 014 - training loss (CrossEntropy): 1273.5862, validation CrossEntropy: 1.3113\n","2025-06-07 13:22:31 [INFO]: Epoch 015 - training loss (CrossEntropy): 1270.2607, validation CrossEntropy: 1.3105\n","2025-06-07 13:22:35 [INFO]: Epoch 016 - training loss (CrossEntropy): 1268.0785, validation CrossEntropy: 1.3047\n","2025-06-07 13:22:39 [INFO]: Epoch 017 - training loss (CrossEntropy): 1261.5807, validation CrossEntropy: 1.2860\n","2025-06-07 13:22:44 [INFO]: Epoch 018 - training loss (CrossEntropy): 1256.6784, validation CrossEntropy: 1.2830\n","2025-06-07 13:22:47 [INFO]: Epoch 019 - training loss (CrossEntropy): 1256.8481, validation CrossEntropy: 1.2876\n","2025-06-07 13:22:51 [INFO]: Epoch 020 - training loss (CrossEntropy): 1251.4167, validation CrossEntropy: 1.2619\n","2025-06-07 13:22:55 [INFO]: Epoch 021 - training loss (CrossEntropy): 1249.5315, validation CrossEntropy: 1.2492\n","2025-06-07 13:22:59 [INFO]: Epoch 022 - training loss (CrossEntropy): 1248.9507, validation CrossEntropy: 1.2583\n","2025-06-07 13:23:03 [INFO]: Epoch 023 - training loss (CrossEntropy): 1244.6618, validation CrossEntropy: 1.2701\n","2025-06-07 13:23:07 [INFO]: Epoch 024 - training loss (CrossEntropy): 1249.0698, validation CrossEntropy: 1.2445\n","2025-06-07 13:23:11 [INFO]: Epoch 025 - training loss (CrossEntropy): 1240.1035, validation CrossEntropy: 1.2367\n","2025-06-07 13:23:15 [INFO]: Epoch 026 - training loss (CrossEntropy): 1237.6856, validation CrossEntropy: 1.2443\n","2025-06-07 13:23:19 [INFO]: Epoch 027 - training loss (CrossEntropy): 1238.4957, validation CrossEntropy: 1.2483\n","2025-06-07 13:23:23 [INFO]: Epoch 028 - training loss (CrossEntropy): 1232.8571, validation CrossEntropy: 1.2177\n","2025-06-07 13:23:26 [INFO]: Epoch 029 - training loss (CrossEntropy): 1227.8131, validation CrossEntropy: 1.2208\n","2025-06-07 13:23:30 [INFO]: Epoch 030 - training loss (CrossEntropy): 1225.6857, validation CrossEntropy: 1.2169\n","2025-06-07 13:23:30 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:23:30 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T132129/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:23:33 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:23:33 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132333\n","2025-06-07 13:23:33 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132333/tensorboard\n","2025-06-07 13:23:33 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:23:33 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:23:33 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:23:40 [INFO]: Epoch 001 - training loss (CrossEntropy): 2073.7582, validation CrossEntropy: 1.6233\n","2025-06-07 13:23:44 [INFO]: Epoch 002 - training loss (CrossEntropy): 1572.4563, validation CrossEntropy: 1.5356\n","2025-06-07 13:23:47 [INFO]: Epoch 003 - training loss (CrossEntropy): 1370.0957, validation CrossEntropy: 1.4840\n","2025-06-07 13:23:52 [INFO]: Epoch 004 - training loss (CrossEntropy): 1323.9000, validation CrossEntropy: 1.5251\n","2025-06-07 13:23:55 [INFO]: Epoch 005 - training loss (CrossEntropy): 1320.3374, validation CrossEntropy: 1.3932\n","2025-06-07 13:23:59 [INFO]: Epoch 006 - training loss (CrossEntropy): 1308.9180, validation CrossEntropy: 1.3568\n","2025-06-07 13:24:03 [INFO]: Epoch 007 - training loss (CrossEntropy): 1303.9793, validation CrossEntropy: 1.4005\n","2025-06-07 13:24:07 [INFO]: Epoch 008 - training loss (CrossEntropy): 1301.3922, validation CrossEntropy: 1.3646\n","2025-06-07 13:24:11 [INFO]: Epoch 009 - training loss (CrossEntropy): 1294.0531, validation CrossEntropy: 1.3379\n","2025-06-07 13:24:15 [INFO]: Epoch 010 - training loss (CrossEntropy): 1288.7499, validation CrossEntropy: 1.3019\n","2025-06-07 13:24:18 [INFO]: Epoch 011 - training loss (CrossEntropy): 1284.4983, validation CrossEntropy: 1.2807\n","2025-06-07 13:24:22 [INFO]: Epoch 012 - training loss (CrossEntropy): 1283.3421, validation CrossEntropy: 1.2672\n","2025-06-07 13:24:26 [INFO]: Epoch 013 - training loss (CrossEntropy): 1276.1364, validation CrossEntropy: 1.2431\n","2025-06-07 13:24:30 [INFO]: Epoch 014 - training loss (CrossEntropy): 1277.3833, validation CrossEntropy: 1.2310\n","2025-06-07 13:24:34 [INFO]: Epoch 015 - training loss (CrossEntropy): 1270.2426, validation CrossEntropy: 1.2268\n","2025-06-07 13:24:38 [INFO]: Epoch 016 - training loss (CrossEntropy): 1268.9489, validation CrossEntropy: 1.2202\n","2025-06-07 13:24:42 [INFO]: Epoch 017 - training loss (CrossEntropy): 1269.0141, validation CrossEntropy: 1.2479\n","2025-06-07 13:24:46 [INFO]: Epoch 018 - training loss (CrossEntropy): 1262.4051, validation CrossEntropy: 1.2360\n","2025-06-07 13:24:50 [INFO]: Epoch 019 - training loss (CrossEntropy): 1256.7330, validation CrossEntropy: 1.2036\n","2025-06-07 13:24:54 [INFO]: Epoch 020 - training loss (CrossEntropy): 1257.0434, validation CrossEntropy: 1.2099\n","2025-06-07 13:24:58 [INFO]: Epoch 021 - training loss (CrossEntropy): 1259.5243, validation CrossEntropy: 1.1956\n","2025-06-07 13:25:02 [INFO]: Epoch 022 - training loss (CrossEntropy): 1248.8476, validation CrossEntropy: 1.1795\n","2025-06-07 13:25:06 [INFO]: Epoch 023 - training loss (CrossEntropy): 1246.5059, validation CrossEntropy: 1.2060\n","2025-06-07 13:25:09 [INFO]: Epoch 024 - training loss (CrossEntropy): 1244.0129, validation CrossEntropy: 1.1986\n","2025-06-07 13:25:13 [INFO]: Epoch 025 - training loss (CrossEntropy): 1238.8798, validation CrossEntropy: 1.1896\n","2025-06-07 13:25:17 [INFO]: Epoch 026 - training loss (CrossEntropy): 1243.3886, validation CrossEntropy: 1.1767\n","2025-06-07 13:25:21 [INFO]: Epoch 027 - training loss (CrossEntropy): 1232.5335, validation CrossEntropy: 1.1842\n","2025-06-07 13:25:25 [INFO]: Epoch 028 - training loss (CrossEntropy): 1234.6277, validation CrossEntropy: 1.1558\n","2025-06-07 13:25:29 [INFO]: Epoch 029 - training loss (CrossEntropy): 1232.6199, validation CrossEntropy: 1.1506\n","2025-06-07 13:25:33 [INFO]: Epoch 030 - training loss (CrossEntropy): 1228.3008, validation CrossEntropy: 1.1394\n","2025-06-07 13:25:33 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:25:33 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T132333/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:25:36 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:25:36 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132536\n","2025-06-07 13:25:36 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132536/tensorboard\n","2025-06-07 13:25:36 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:25:36 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:25:36 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:25:43 [INFO]: Epoch 001 - training loss (CrossEntropy): 2054.0520, validation CrossEntropy: 1.6888\n","2025-06-07 13:25:47 [INFO]: Epoch 002 - training loss (CrossEntropy): 1609.5352, validation CrossEntropy: 1.5796\n","2025-06-07 13:25:51 [INFO]: Epoch 003 - training loss (CrossEntropy): 1395.6478, validation CrossEntropy: 1.5016\n","2025-06-07 13:25:56 [INFO]: Epoch 004 - training loss (CrossEntropy): 1328.7574, validation CrossEntropy: 1.4542\n","2025-06-07 13:26:00 [INFO]: Epoch 005 - training loss (CrossEntropy): 1318.8373, validation CrossEntropy: 1.4397\n","2025-06-07 13:26:04 [INFO]: Epoch 006 - training loss (CrossEntropy): 1312.8400, validation CrossEntropy: 1.4079\n","2025-06-07 13:26:08 [INFO]: Epoch 007 - training loss (CrossEntropy): 1304.8529, validation CrossEntropy: 1.3782\n","2025-06-07 13:26:12 [INFO]: Epoch 008 - training loss (CrossEntropy): 1303.8291, validation CrossEntropy: 1.3690\n","2025-06-07 13:26:16 [INFO]: Epoch 009 - training loss (CrossEntropy): 1298.6710, validation CrossEntropy: 1.3522\n","2025-06-07 13:26:21 [INFO]: Epoch 010 - training loss (CrossEntropy): 1289.7317, validation CrossEntropy: 1.3172\n","2025-06-07 13:26:25 [INFO]: Epoch 011 - training loss (CrossEntropy): 1287.6379, validation CrossEntropy: 1.3304\n","2025-06-07 13:26:29 [INFO]: Epoch 012 - training loss (CrossEntropy): 1285.1280, validation CrossEntropy: 1.3198\n","2025-06-07 13:26:33 [INFO]: Epoch 013 - training loss (CrossEntropy): 1280.8444, validation CrossEntropy: 1.3392\n","2025-06-07 13:26:37 [INFO]: Epoch 014 - training loss (CrossEntropy): 1278.6818, validation CrossEntropy: 1.3089\n","2025-06-07 13:26:41 [INFO]: Epoch 015 - training loss (CrossEntropy): 1274.9795, validation CrossEntropy: 1.2996\n","2025-06-07 13:26:45 [INFO]: Epoch 016 - training loss (CrossEntropy): 1272.1265, validation CrossEntropy: 1.2827\n","2025-06-07 13:26:50 [INFO]: Epoch 017 - training loss (CrossEntropy): 1275.5764, validation CrossEntropy: 1.3323\n","2025-06-07 13:26:54 [INFO]: Epoch 018 - training loss (CrossEntropy): 1264.5831, validation CrossEntropy: 1.3076\n","2025-06-07 13:26:58 [INFO]: Epoch 019 - training loss (CrossEntropy): 1264.4213, validation CrossEntropy: 1.3208\n","2025-06-07 13:27:01 [INFO]: Epoch 020 - training loss (CrossEntropy): 1258.6889, validation CrossEntropy: 1.2877\n","2025-06-07 13:27:06 [INFO]: Epoch 021 - training loss (CrossEntropy): 1254.2073, validation CrossEntropy: 1.2726\n","2025-06-07 13:27:09 [INFO]: Epoch 022 - training loss (CrossEntropy): 1258.1854, validation CrossEntropy: 1.2941\n","2025-06-07 13:27:13 [INFO]: Epoch 023 - training loss (CrossEntropy): 1250.0158, validation CrossEntropy: 1.2777\n","2025-06-07 13:27:17 [INFO]: Epoch 024 - training loss (CrossEntropy): 1247.2017, validation CrossEntropy: 1.2755\n","2025-06-07 13:27:21 [INFO]: Epoch 025 - training loss (CrossEntropy): 1250.9468, validation CrossEntropy: 1.2653\n","2025-06-07 13:27:25 [INFO]: Epoch 026 - training loss (CrossEntropy): 1240.1623, validation CrossEntropy: 1.2479\n","2025-06-07 13:27:29 [INFO]: Epoch 027 - training loss (CrossEntropy): 1240.5962, validation CrossEntropy: 1.2534\n","2025-06-07 13:27:33 [INFO]: Epoch 028 - training loss (CrossEntropy): 1233.6826, validation CrossEntropy: 1.2361\n","2025-06-07 13:27:38 [INFO]: Epoch 029 - training loss (CrossEntropy): 1232.8496, validation CrossEntropy: 1.2169\n","2025-06-07 13:27:42 [INFO]: Epoch 030 - training loss (CrossEntropy): 1232.0456, validation CrossEntropy: 1.2148\n","2025-06-07 13:27:42 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:27:42 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T132536/BRITS.pypots\n","2025-06-07 13:27:44 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:27:44 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132744\n","2025-06-07 13:27:44 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132744/tensorboard\n","2025-06-07 13:27:44 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:27:44 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:27:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:27:52 [INFO]: Epoch 001 - training loss (CrossEntropy): 2069.6534, validation CrossEntropy: 1.6583\n","2025-06-07 13:27:56 [INFO]: Epoch 002 - training loss (CrossEntropy): 1606.1740, validation CrossEntropy: 1.5582\n","2025-06-07 13:27:59 [INFO]: Epoch 003 - training loss (CrossEntropy): 1411.9561, validation CrossEntropy: 1.4962\n","2025-06-07 13:28:04 [INFO]: Epoch 004 - training loss (CrossEntropy): 1329.5630, validation CrossEntropy: 1.4621\n","2025-06-07 13:28:07 [INFO]: Epoch 005 - training loss (CrossEntropy): 1321.3182, validation CrossEntropy: 1.4766\n","2025-06-07 13:28:11 [INFO]: Epoch 006 - training loss (CrossEntropy): 1313.5644, validation CrossEntropy: 1.4458\n","2025-06-07 13:28:15 [INFO]: Epoch 007 - training loss (CrossEntropy): 1304.8565, validation CrossEntropy: 1.3962\n","2025-06-07 13:28:19 [INFO]: Epoch 008 - training loss (CrossEntropy): 1303.7768, validation CrossEntropy: 1.3959\n","2025-06-07 13:28:22 [INFO]: Epoch 009 - training loss (CrossEntropy): 1298.4425, validation CrossEntropy: 1.4196\n","2025-06-07 13:28:26 [INFO]: Epoch 010 - training loss (CrossEntropy): 1287.9541, validation CrossEntropy: 1.4336\n","2025-06-07 13:28:30 [INFO]: Epoch 011 - training loss (CrossEntropy): 1286.5907, validation CrossEntropy: 1.3839\n","2025-06-07 13:28:34 [INFO]: Epoch 012 - training loss (CrossEntropy): 1282.8362, validation CrossEntropy: 1.3645\n","2025-06-07 13:28:38 [INFO]: Epoch 013 - training loss (CrossEntropy): 1276.4222, validation CrossEntropy: 1.3402\n","2025-06-07 13:28:42 [INFO]: Epoch 014 - training loss (CrossEntropy): 1274.2918, validation CrossEntropy: 1.3437\n","2025-06-07 13:28:46 [INFO]: Epoch 015 - training loss (CrossEntropy): 1273.3448, validation CrossEntropy: 1.3154\n","2025-06-07 13:28:50 [INFO]: Epoch 016 - training loss (CrossEntropy): 1269.6730, validation CrossEntropy: 1.2987\n","2025-06-07 13:28:54 [INFO]: Epoch 017 - training loss (CrossEntropy): 1264.6242, validation CrossEntropy: 1.3092\n","2025-06-07 13:28:58 [INFO]: Epoch 018 - training loss (CrossEntropy): 1260.9621, validation CrossEntropy: 1.2832\n","2025-06-07 13:29:02 [INFO]: Epoch 019 - training loss (CrossEntropy): 1259.7982, validation CrossEntropy: 1.2743\n","2025-06-07 13:29:06 [INFO]: Epoch 020 - training loss (CrossEntropy): 1255.0678, validation CrossEntropy: 1.2574\n","2025-06-07 13:29:10 [INFO]: Epoch 021 - training loss (CrossEntropy): 1254.5778, validation CrossEntropy: 1.2502\n","2025-06-07 13:29:14 [INFO]: Epoch 022 - training loss (CrossEntropy): 1251.6008, validation CrossEntropy: 1.2305\n","2025-06-07 13:29:18 [INFO]: Epoch 023 - training loss (CrossEntropy): 1247.9086, validation CrossEntropy: 1.2157\n","2025-06-07 13:29:22 [INFO]: Epoch 024 - training loss (CrossEntropy): 1248.9683, validation CrossEntropy: 1.2196\n","2025-06-07 13:29:26 [INFO]: Epoch 025 - training loss (CrossEntropy): 1243.2884, validation CrossEntropy: 1.1925\n","2025-06-07 13:29:30 [INFO]: Epoch 026 - training loss (CrossEntropy): 1240.3053, validation CrossEntropy: 1.1952\n","2025-06-07 13:29:34 [INFO]: Epoch 027 - training loss (CrossEntropy): 1236.4852, validation CrossEntropy: 1.1696\n","2025-06-07 13:29:38 [INFO]: Epoch 028 - training loss (CrossEntropy): 1234.5121, validation CrossEntropy: 1.1671\n","2025-06-07 13:29:42 [INFO]: Epoch 029 - training loss (CrossEntropy): 1230.2737, validation CrossEntropy: 1.1597\n","2025-06-07 13:29:46 [INFO]: Epoch 030 - training loss (CrossEntropy): 1230.2390, validation CrossEntropy: 1.1625\n","2025-06-07 13:29:46 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 13:29:46 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T132744/BRITS.pypots\n"]},{"output_type":"stream","name":"stdout","text":["BRITS(rnn_hidden_size=32, classification_weight=2, reconstruction_weight=1) & 0.2676 ± 0.0521 & 0.1286 ± 0.0587 0.1546 ± 0.1109 0.2146 ± 0.0422 \\\n","[123.17783641815186, 121.70624947547913, 120.68728399276733, 126.19342803955078, 121.48037266731262]\n","122.6490 ± 1.9466\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["\n","rnn_hidden_size=64\n","classification_weight=1\n","reconstruction_weight=2\n","\n","run_model(\n","  lambda: BRITS(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    rnn_hidden_size=rnn_hidden_size,\n","    classification_weight=classification_weight,\n","    reconstruction_weight=reconstruction_weight,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/brits',\n","    model_saving_strategy='best'\n","  ),\n","  f\"BRITS({rnn_hidden_size=}, {classification_weight=}, {reconstruction_weight=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5Qm2j8jcm0V","executionInfo":{"status":"ok","timestamp":1749303625345,"user_tz":-120,"elapsed":637035,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"6eb56db6-be1f-4eef-c5d9-910af4fccd03"},"id":"L5Qm2j8jcm0V","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 13:29:48 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:29:48 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132948\n","2025-06-07 13:29:48 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T132948/tensorboard\n","2025-06-07 13:29:48 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:29:48 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:29:48 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:29:55 [INFO]: Epoch 001 - training loss (CrossEntropy): 4235.1532, validation CrossEntropy: 1.5926\n","2025-06-07 13:29:59 [INFO]: Epoch 002 - training loss (CrossEntropy): 3322.2213, validation CrossEntropy: 1.5906\n","2025-06-07 13:30:04 [INFO]: Epoch 003 - training loss (CrossEntropy): 2805.8081, validation CrossEntropy: 1.5855\n","2025-06-07 13:30:08 [INFO]: Epoch 004 - training loss (CrossEntropy): 2659.7702, validation CrossEntropy: 1.5692\n","2025-06-07 13:30:12 [INFO]: Epoch 005 - training loss (CrossEntropy): 2622.0972, validation CrossEntropy: 1.5337\n","2025-06-07 13:30:16 [INFO]: Epoch 006 - training loss (CrossEntropy): 2614.6792, validation CrossEntropy: 1.5047\n","2025-06-07 13:30:20 [INFO]: Epoch 007 - training loss (CrossEntropy): 2610.5336, validation CrossEntropy: 1.4639\n","2025-06-07 13:30:24 [INFO]: Epoch 008 - training loss (CrossEntropy): 2588.8837, validation CrossEntropy: 1.4533\n","2025-06-07 13:30:28 [INFO]: Epoch 009 - training loss (CrossEntropy): 2575.1690, validation CrossEntropy: 1.4490\n","2025-06-07 13:30:33 [INFO]: Epoch 010 - training loss (CrossEntropy): 2577.7355, validation CrossEntropy: 1.4258\n","2025-06-07 13:30:37 [INFO]: Epoch 011 - training loss (CrossEntropy): 2559.8660, validation CrossEntropy: 1.4113\n","2025-06-07 13:30:41 [INFO]: Epoch 012 - training loss (CrossEntropy): 2551.0374, validation CrossEntropy: 1.4008\n","2025-06-07 13:30:45 [INFO]: Epoch 013 - training loss (CrossEntropy): 2544.1344, validation CrossEntropy: 1.3663\n","2025-06-07 13:30:49 [INFO]: Epoch 014 - training loss (CrossEntropy): 2545.7452, validation CrossEntropy: 1.3278\n","2025-06-07 13:30:54 [INFO]: Epoch 015 - training loss (CrossEntropy): 2535.5702, validation CrossEntropy: 1.3415\n","2025-06-07 13:30:58 [INFO]: Epoch 016 - training loss (CrossEntropy): 2533.8136, validation CrossEntropy: 1.3562\n","2025-06-07 13:31:02 [INFO]: Epoch 017 - training loss (CrossEntropy): 2518.4173, validation CrossEntropy: 1.3367\n","2025-06-07 13:31:07 [INFO]: Epoch 018 - training loss (CrossEntropy): 2518.9731, validation CrossEntropy: 1.3116\n","2025-06-07 13:31:11 [INFO]: Epoch 019 - training loss (CrossEntropy): 2505.2771, validation CrossEntropy: 1.2978\n","2025-06-07 13:31:15 [INFO]: Epoch 020 - training loss (CrossEntropy): 2503.4671, validation CrossEntropy: 1.3178\n","2025-06-07 13:31:20 [INFO]: Epoch 021 - training loss (CrossEntropy): 2510.9376, validation CrossEntropy: 1.2884\n","2025-06-07 13:31:24 [INFO]: Epoch 022 - training loss (CrossEntropy): 2495.6006, validation CrossEntropy: 1.2828\n","2025-06-07 13:31:28 [INFO]: Epoch 023 - training loss (CrossEntropy): 2484.9606, validation CrossEntropy: 1.2939\n","2025-06-07 13:31:32 [INFO]: Epoch 024 - training loss (CrossEntropy): 2476.1877, validation CrossEntropy: 1.2740\n","2025-06-07 13:31:37 [INFO]: Epoch 025 - training loss (CrossEntropy): 2482.5380, validation CrossEntropy: 1.2637\n","2025-06-07 13:31:41 [INFO]: Epoch 026 - training loss (CrossEntropy): 2474.9819, validation CrossEntropy: 1.2680\n","2025-06-07 13:31:45 [INFO]: Epoch 027 - training loss (CrossEntropy): 2468.7293, validation CrossEntropy: 1.2658\n","2025-06-07 13:31:49 [INFO]: Epoch 028 - training loss (CrossEntropy): 2465.9466, validation CrossEntropy: 1.2490\n","2025-06-07 13:31:54 [INFO]: Epoch 029 - training loss (CrossEntropy): 2460.3852, validation CrossEntropy: 1.2417\n","2025-06-07 13:31:58 [INFO]: Epoch 030 - training loss (CrossEntropy): 2444.1057, validation CrossEntropy: 1.2435\n","2025-06-07 13:31:58 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 13:31:58 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T132948/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:32:00 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:32:00 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T133200\n","2025-06-07 13:32:00 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T133200/tensorboard\n","2025-06-07 13:32:00 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:32:00 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:32:00 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:32:07 [INFO]: Epoch 001 - training loss (CrossEntropy): 4327.0031, validation CrossEntropy: 1.6215\n","2025-06-07 13:32:12 [INFO]: Epoch 002 - training loss (CrossEntropy): 3316.7117, validation CrossEntropy: 1.6315\n","2025-06-07 13:32:16 [INFO]: Epoch 003 - training loss (CrossEntropy): 2811.7562, validation CrossEntropy: 1.5921\n","2025-06-07 13:32:20 [INFO]: Epoch 004 - training loss (CrossEntropy): 2641.4129, validation CrossEntropy: 1.5645\n","2025-06-07 13:32:24 [INFO]: Epoch 005 - training loss (CrossEntropy): 2628.4651, validation CrossEntropy: 1.5311\n","2025-06-07 13:32:28 [INFO]: Epoch 006 - training loss (CrossEntropy): 2613.4713, validation CrossEntropy: 1.4887\n","2025-06-07 13:32:33 [INFO]: Epoch 007 - training loss (CrossEntropy): 2600.5029, validation CrossEntropy: 1.4750\n","2025-06-07 13:32:37 [INFO]: Epoch 008 - training loss (CrossEntropy): 2591.2964, validation CrossEntropy: 1.4501\n","2025-06-07 13:32:41 [INFO]: Epoch 009 - training loss (CrossEntropy): 2574.6197, validation CrossEntropy: 1.4323\n","2025-06-07 13:32:46 [INFO]: Epoch 010 - training loss (CrossEntropy): 2571.2161, validation CrossEntropy: 1.4186\n","2025-06-07 13:32:50 [INFO]: Epoch 011 - training loss (CrossEntropy): 2561.8506, validation CrossEntropy: 1.4060\n","2025-06-07 13:32:54 [INFO]: Epoch 012 - training loss (CrossEntropy): 2562.8366, validation CrossEntropy: 1.4105\n","2025-06-07 13:32:59 [INFO]: Epoch 013 - training loss (CrossEntropy): 2547.4029, validation CrossEntropy: 1.3970\n","2025-06-07 13:33:03 [INFO]: Epoch 014 - training loss (CrossEntropy): 2537.9521, validation CrossEntropy: 1.3752\n","2025-06-07 13:33:07 [INFO]: Epoch 015 - training loss (CrossEntropy): 2540.7826, validation CrossEntropy: 1.3836\n","2025-06-07 13:33:11 [INFO]: Epoch 016 - training loss (CrossEntropy): 2525.1456, validation CrossEntropy: 1.3725\n","2025-06-07 13:33:15 [INFO]: Epoch 017 - training loss (CrossEntropy): 2521.1814, validation CrossEntropy: 1.3639\n","2025-06-07 13:33:19 [INFO]: Epoch 018 - training loss (CrossEntropy): 2511.5354, validation CrossEntropy: 1.3658\n","2025-06-07 13:33:24 [INFO]: Epoch 019 - training loss (CrossEntropy): 2514.2315, validation CrossEntropy: 1.3276\n","2025-06-07 13:33:28 [INFO]: Epoch 020 - training loss (CrossEntropy): 2502.8425, validation CrossEntropy: 1.3565\n","2025-06-07 13:33:32 [INFO]: Epoch 021 - training loss (CrossEntropy): 2498.0777, validation CrossEntropy: 1.3193\n","2025-06-07 13:33:36 [INFO]: Epoch 022 - training loss (CrossEntropy): 2488.7074, validation CrossEntropy: 1.3071\n","2025-06-07 13:33:40 [INFO]: Epoch 023 - training loss (CrossEntropy): 2485.9899, validation CrossEntropy: 1.2950\n","2025-06-07 13:33:44 [INFO]: Epoch 024 - training loss (CrossEntropy): 2490.7426, validation CrossEntropy: 1.3087\n","2025-06-07 13:33:48 [INFO]: Epoch 025 - training loss (CrossEntropy): 2477.1952, validation CrossEntropy: 1.2814\n","2025-06-07 13:33:52 [INFO]: Epoch 026 - training loss (CrossEntropy): 2466.6013, validation CrossEntropy: 1.2699\n","2025-06-07 13:33:57 [INFO]: Epoch 027 - training loss (CrossEntropy): 2467.3486, validation CrossEntropy: 1.2770\n","2025-06-07 13:34:01 [INFO]: Epoch 028 - training loss (CrossEntropy): 2456.7246, validation CrossEntropy: 1.2735\n","2025-06-07 13:34:05 [INFO]: Epoch 029 - training loss (CrossEntropy): 2454.2093, validation CrossEntropy: 1.2758\n","2025-06-07 13:34:09 [INFO]: Epoch 030 - training loss (CrossEntropy): 2450.6222, validation CrossEntropy: 1.2718\n","2025-06-07 13:34:09 [INFO]: Finished training. The best model is from epoch#26.\n","2025-06-07 13:34:09 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T133200/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:34:11 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:34:11 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T133411\n","2025-06-07 13:34:11 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T133411/tensorboard\n","2025-06-07 13:34:11 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:34:11 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:34:11 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:34:18 [INFO]: Epoch 001 - training loss (CrossEntropy): 3740.6435, validation CrossEntropy: 1.6085\n","2025-06-07 13:34:22 [INFO]: Epoch 002 - training loss (CrossEntropy): 3014.6391, validation CrossEntropy: 1.5967\n","2025-06-07 13:34:26 [INFO]: Epoch 003 - training loss (CrossEntropy): 2728.5772, validation CrossEntropy: 1.5759\n","2025-06-07 13:34:31 [INFO]: Epoch 004 - training loss (CrossEntropy): 2631.8545, validation CrossEntropy: 1.5291\n","2025-06-07 13:34:35 [INFO]: Epoch 005 - training loss (CrossEntropy): 2618.8958, validation CrossEntropy: 1.4789\n","2025-06-07 13:34:39 [INFO]: Epoch 006 - training loss (CrossEntropy): 2596.8376, validation CrossEntropy: 1.4555\n","2025-06-07 13:34:43 [INFO]: Epoch 007 - training loss (CrossEntropy): 2587.4621, validation CrossEntropy: 1.4111\n","2025-06-07 13:34:47 [INFO]: Epoch 008 - training loss (CrossEntropy): 2578.9669, validation CrossEntropy: 1.4204\n","2025-06-07 13:34:52 [INFO]: Epoch 009 - training loss (CrossEntropy): 2568.9646, validation CrossEntropy: 1.4141\n","2025-06-07 13:34:56 [INFO]: Epoch 010 - training loss (CrossEntropy): 2562.2423, validation CrossEntropy: 1.3631\n","2025-06-07 13:35:00 [INFO]: Epoch 011 - training loss (CrossEntropy): 2558.6543, validation CrossEntropy: 1.3503\n","2025-06-07 13:35:04 [INFO]: Epoch 012 - training loss (CrossEntropy): 2552.9598, validation CrossEntropy: 1.3443\n","2025-06-07 13:35:08 [INFO]: Epoch 013 - training loss (CrossEntropy): 2551.5454, validation CrossEntropy: 1.3299\n","2025-06-07 13:35:12 [INFO]: Epoch 014 - training loss (CrossEntropy): 2539.9316, validation CrossEntropy: 1.3274\n","2025-06-07 13:35:16 [INFO]: Epoch 015 - training loss (CrossEntropy): 2531.4816, validation CrossEntropy: 1.3067\n","2025-06-07 13:35:20 [INFO]: Epoch 016 - training loss (CrossEntropy): 2519.1224, validation CrossEntropy: 1.2889\n","2025-06-07 13:35:24 [INFO]: Epoch 017 - training loss (CrossEntropy): 2515.7667, validation CrossEntropy: 1.2912\n","2025-06-07 13:35:28 [INFO]: Epoch 018 - training loss (CrossEntropy): 2515.5412, validation CrossEntropy: 1.2815\n","2025-06-07 13:35:32 [INFO]: Epoch 019 - training loss (CrossEntropy): 2502.4068, validation CrossEntropy: 1.2894\n","2025-06-07 13:35:36 [INFO]: Epoch 020 - training loss (CrossEntropy): 2500.7624, validation CrossEntropy: 1.2743\n","2025-06-07 13:35:41 [INFO]: Epoch 021 - training loss (CrossEntropy): 2500.0905, validation CrossEntropy: 1.2633\n","2025-06-07 13:35:45 [INFO]: Epoch 022 - training loss (CrossEntropy): 2484.6514, validation CrossEntropy: 1.2622\n","2025-06-07 13:35:49 [INFO]: Epoch 023 - training loss (CrossEntropy): 2481.9283, validation CrossEntropy: 1.2614\n","2025-06-07 13:35:53 [INFO]: Epoch 024 - training loss (CrossEntropy): 2475.8705, validation CrossEntropy: 1.2632\n","2025-06-07 13:35:56 [INFO]: Epoch 025 - training loss (CrossEntropy): 2476.4415, validation CrossEntropy: 1.2413\n","2025-06-07 13:36:01 [INFO]: Epoch 026 - training loss (CrossEntropy): 2457.8388, validation CrossEntropy: 1.2483\n","2025-06-07 13:36:04 [INFO]: Epoch 027 - training loss (CrossEntropy): 2461.8285, validation CrossEntropy: 1.2362\n","2025-06-07 13:36:08 [INFO]: Epoch 028 - training loss (CrossEntropy): 2460.1011, validation CrossEntropy: 1.2143\n","2025-06-07 13:36:12 [INFO]: Epoch 029 - training loss (CrossEntropy): 2447.3683, validation CrossEntropy: 1.2037\n","2025-06-07 13:36:16 [INFO]: Epoch 030 - training loss (CrossEntropy): 2448.3426, validation CrossEntropy: 1.2032\n","2025-06-07 13:36:16 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:36:16 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T133411/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:36:19 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:36:19 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T133619\n","2025-06-07 13:36:19 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T133619/tensorboard\n","2025-06-07 13:36:19 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:36:19 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:36:19 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:36:26 [INFO]: Epoch 001 - training loss (CrossEntropy): 3905.5323, validation CrossEntropy: 1.6078\n","2025-06-07 13:36:30 [INFO]: Epoch 002 - training loss (CrossEntropy): 3073.6535, validation CrossEntropy: 1.6414\n","2025-06-07 13:36:34 [INFO]: Epoch 003 - training loss (CrossEntropy): 2721.9533, validation CrossEntropy: 1.6410\n","2025-06-07 13:36:38 [INFO]: Epoch 004 - training loss (CrossEntropy): 2639.3284, validation CrossEntropy: 1.6170\n","2025-06-07 13:36:42 [INFO]: Epoch 005 - training loss (CrossEntropy): 2627.0018, validation CrossEntropy: 1.5410\n","2025-06-07 13:36:46 [INFO]: Epoch 006 - training loss (CrossEntropy): 2606.5905, validation CrossEntropy: 1.5157\n","2025-06-07 13:36:50 [INFO]: Epoch 007 - training loss (CrossEntropy): 2592.9941, validation CrossEntropy: 1.4757\n","2025-06-07 13:36:54 [INFO]: Epoch 008 - training loss (CrossEntropy): 2583.9977, validation CrossEntropy: 1.4548\n","2025-06-07 13:36:58 [INFO]: Epoch 009 - training loss (CrossEntropy): 2580.6222, validation CrossEntropy: 1.4488\n","2025-06-07 13:37:01 [INFO]: Epoch 010 - training loss (CrossEntropy): 2565.0742, validation CrossEntropy: 1.4277\n","2025-06-07 13:37:05 [INFO]: Epoch 011 - training loss (CrossEntropy): 2568.4536, validation CrossEntropy: 1.4058\n","2025-06-07 13:37:10 [INFO]: Epoch 012 - training loss (CrossEntropy): 2556.9690, validation CrossEntropy: 1.4085\n","2025-06-07 13:37:13 [INFO]: Epoch 013 - training loss (CrossEntropy): 2544.3885, validation CrossEntropy: 1.3815\n","2025-06-07 13:37:17 [INFO]: Epoch 014 - training loss (CrossEntropy): 2543.4316, validation CrossEntropy: 1.3631\n","2025-06-07 13:37:21 [INFO]: Epoch 015 - training loss (CrossEntropy): 2534.5026, validation CrossEntropy: 1.3697\n","2025-06-07 13:37:25 [INFO]: Epoch 016 - training loss (CrossEntropy): 2536.0898, validation CrossEntropy: 1.3723\n","2025-06-07 13:37:29 [INFO]: Epoch 017 - training loss (CrossEntropy): 2517.3518, validation CrossEntropy: 1.3513\n","2025-06-07 13:37:33 [INFO]: Epoch 018 - training loss (CrossEntropy): 2527.1756, validation CrossEntropy: 1.3505\n","2025-06-07 13:37:37 [INFO]: Epoch 019 - training loss (CrossEntropy): 2504.0391, validation CrossEntropy: 1.3361\n","2025-06-07 13:37:41 [INFO]: Epoch 020 - training loss (CrossEntropy): 2504.4248, validation CrossEntropy: 1.3283\n","2025-06-07 13:37:45 [INFO]: Epoch 021 - training loss (CrossEntropy): 2492.8279, validation CrossEntropy: 1.3230\n","2025-06-07 13:37:49 [INFO]: Epoch 022 - training loss (CrossEntropy): 2488.7402, validation CrossEntropy: 1.3162\n","2025-06-07 13:37:53 [INFO]: Epoch 023 - training loss (CrossEntropy): 2484.0425, validation CrossEntropy: 1.3302\n","2025-06-07 13:37:57 [INFO]: Epoch 024 - training loss (CrossEntropy): 2478.5401, validation CrossEntropy: 1.3337\n","2025-06-07 13:38:00 [INFO]: Epoch 025 - training loss (CrossEntropy): 2480.7786, validation CrossEntropy: 1.3021\n","2025-06-07 13:38:04 [INFO]: Epoch 026 - training loss (CrossEntropy): 2467.8065, validation CrossEntropy: 1.3082\n","2025-06-07 13:38:08 [INFO]: Epoch 027 - training loss (CrossEntropy): 2462.3530, validation CrossEntropy: 1.2993\n","2025-06-07 13:38:12 [INFO]: Epoch 028 - training loss (CrossEntropy): 2468.9406, validation CrossEntropy: 1.2983\n","2025-06-07 13:38:16 [INFO]: Epoch 029 - training loss (CrossEntropy): 2449.8000, validation CrossEntropy: 1.2946\n","2025-06-07 13:38:20 [INFO]: Epoch 030 - training loss (CrossEntropy): 2446.2756, validation CrossEntropy: 1.2853\n","2025-06-07 13:38:20 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:38:20 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T133619/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:38:22 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:38:22 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T133822\n","2025-06-07 13:38:22 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T133822/tensorboard\n","2025-06-07 13:38:22 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:38:22 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:38:22 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 54,300\n","2025-06-07 13:38:29 [INFO]: Epoch 001 - training loss (CrossEntropy): 3587.4015, validation CrossEntropy: 1.6179\n","2025-06-07 13:38:33 [INFO]: Epoch 002 - training loss (CrossEntropy): 2911.0539, validation CrossEntropy: 1.6149\n","2025-06-07 13:38:37 [INFO]: Epoch 003 - training loss (CrossEntropy): 2672.8378, validation CrossEntropy: 1.5812\n","2025-06-07 13:38:41 [INFO]: Epoch 004 - training loss (CrossEntropy): 2627.3380, validation CrossEntropy: 1.5347\n","2025-06-07 13:38:45 [INFO]: Epoch 005 - training loss (CrossEntropy): 2611.1109, validation CrossEntropy: 1.5067\n","2025-06-07 13:38:49 [INFO]: Epoch 006 - training loss (CrossEntropy): 2596.8490, validation CrossEntropy: 1.4808\n","2025-06-07 13:38:53 [INFO]: Epoch 007 - training loss (CrossEntropy): 2579.2529, validation CrossEntropy: 1.4510\n","2025-06-07 13:38:57 [INFO]: Epoch 008 - training loss (CrossEntropy): 2576.3427, validation CrossEntropy: 1.4118\n","2025-06-07 13:39:00 [INFO]: Epoch 009 - training loss (CrossEntropy): 2568.4804, validation CrossEntropy: 1.4009\n","2025-06-07 13:39:05 [INFO]: Epoch 010 - training loss (CrossEntropy): 2559.0075, validation CrossEntropy: 1.4176\n","2025-06-07 13:39:08 [INFO]: Epoch 011 - training loss (CrossEntropy): 2556.0850, validation CrossEntropy: 1.4026\n","2025-06-07 13:39:12 [INFO]: Epoch 012 - training loss (CrossEntropy): 2555.8375, validation CrossEntropy: 1.3899\n","2025-06-07 13:39:16 [INFO]: Epoch 013 - training loss (CrossEntropy): 2545.8145, validation CrossEntropy: 1.3616\n","2025-06-07 13:39:20 [INFO]: Epoch 014 - training loss (CrossEntropy): 2532.0764, validation CrossEntropy: 1.3415\n","2025-06-07 13:39:24 [INFO]: Epoch 015 - training loss (CrossEntropy): 2527.5537, validation CrossEntropy: 1.3300\n","2025-06-07 13:39:28 [INFO]: Epoch 016 - training loss (CrossEntropy): 2521.3926, validation CrossEntropy: 1.3107\n","2025-06-07 13:39:32 [INFO]: Epoch 017 - training loss (CrossEntropy): 2515.7664, validation CrossEntropy: 1.3118\n","2025-06-07 13:39:36 [INFO]: Epoch 018 - training loss (CrossEntropy): 2506.6909, validation CrossEntropy: 1.3036\n","2025-06-07 13:39:40 [INFO]: Epoch 019 - training loss (CrossEntropy): 2505.5130, validation CrossEntropy: 1.2859\n","2025-06-07 13:39:44 [INFO]: Epoch 020 - training loss (CrossEntropy): 2501.9516, validation CrossEntropy: 1.2944\n","2025-06-07 13:39:48 [INFO]: Epoch 021 - training loss (CrossEntropy): 2490.1769, validation CrossEntropy: 1.2919\n","2025-06-07 13:39:52 [INFO]: Epoch 022 - training loss (CrossEntropy): 2489.5375, validation CrossEntropy: 1.2611\n","2025-06-07 13:39:55 [INFO]: Epoch 023 - training loss (CrossEntropy): 2479.9828, validation CrossEntropy: 1.2637\n","2025-06-07 13:39:59 [INFO]: Epoch 024 - training loss (CrossEntropy): 2474.8783, validation CrossEntropy: 1.2581\n","2025-06-07 13:40:03 [INFO]: Epoch 025 - training loss (CrossEntropy): 2472.1907, validation CrossEntropy: 1.2481\n","2025-06-07 13:40:07 [INFO]: Epoch 026 - training loss (CrossEntropy): 2468.1690, validation CrossEntropy: 1.2618\n","2025-06-07 13:40:11 [INFO]: Epoch 027 - training loss (CrossEntropy): 2456.9411, validation CrossEntropy: 1.2534\n","2025-06-07 13:40:15 [INFO]: Epoch 028 - training loss (CrossEntropy): 2454.6677, validation CrossEntropy: 1.2377\n","2025-06-07 13:40:19 [INFO]: Epoch 029 - training loss (CrossEntropy): 2446.4779, validation CrossEntropy: 1.2466\n","2025-06-07 13:40:23 [INFO]: Epoch 030 - training loss (CrossEntropy): 2445.5276, validation CrossEntropy: 1.2506\n","2025-06-07 13:40:23 [INFO]: Finished training. The best model is from epoch#28.\n","2025-06-07 13:40:23 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T133822/BRITS.pypots\n"]},{"output_type":"stream","name":"stdout","text":["BRITS(rnn_hidden_size=64, classification_weight=1, reconstruction_weight=2) & 0.2541 ± 0.0590 & 0.1134 ± 0.0657 0.0912 ± 0.0628 0.2186 ± 0.0693 \\\n","[129.6449191570282, 128.6292552947998, 125.22912979125977, 121.13633108139038, 120.70379328727722]\n","125.0687 ± 3.6922\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["\n","rnn_hidden_size=32\n","classification_weight=1\n","reconstruction_weight=2\n","\n","run_model(\n","  lambda: BRITS(\n","    n_steps=X_train_bal.shape[1],\n","    n_features=X_train_bal.shape[2],\n","    n_classes=len(np.unique(y_train_bal)),\n","    rnn_hidden_size=rnn_hidden_size,\n","    classification_weight=classification_weight,\n","    reconstruction_weight=reconstruction_weight,\n","    batch_size=64,\n","    epochs=30,\n","    patience=6,\n","    optimizer=Adam(lr=1e-3),\n","    num_workers=0,\n","    device=None,\n","    saving_path='./runs/classify/WEATHER-KNMI/brits',\n","    model_saving_strategy='best'\n","  ),\n","  f\"BRITS({rnn_hidden_size=}, {classification_weight=}, {reconstruction_weight=})\",\n","  X_train_bal, y_train_bal, X_val_bal, y_val_bal, X_test_bal, y_test_bal\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vv9CSd9cogn","executionInfo":{"status":"ok","timestamp":1749304192519,"user_tz":-120,"elapsed":567170,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"ec12bd42-3a47-4794-8808-3b1b5680245c"},"id":"0vv9CSd9cogn","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-07 13:40:25 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:40:25 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134025\n","2025-06-07 13:40:25 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134025/tensorboard\n","2025-06-07 13:40:25 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:40:25 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:40:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:40:31 [INFO]: Epoch 001 - training loss (CrossEntropy): 4038.5104, validation CrossEntropy: 1.6835\n","2025-06-07 13:40:35 [INFO]: Epoch 002 - training loss (CrossEntropy): 3147.6901, validation CrossEntropy: 1.7417\n","2025-06-07 13:40:38 [INFO]: Epoch 003 - training loss (CrossEntropy): 2751.3388, validation CrossEntropy: 1.7093\n","2025-06-07 13:40:42 [INFO]: Epoch 004 - training loss (CrossEntropy): 2638.9309, validation CrossEntropy: 1.6915\n","2025-06-07 13:40:46 [INFO]: Epoch 005 - training loss (CrossEntropy): 2623.8378, validation CrossEntropy: 1.6784\n","2025-06-07 13:40:49 [INFO]: Epoch 006 - training loss (CrossEntropy): 2616.0298, validation CrossEntropy: 1.6462\n","2025-06-07 13:40:53 [INFO]: Epoch 007 - training loss (CrossEntropy): 2591.6739, validation CrossEntropy: 1.5911\n","2025-06-07 13:40:57 [INFO]: Epoch 008 - training loss (CrossEntropy): 2591.7167, validation CrossEntropy: 1.6210\n","2025-06-07 13:41:00 [INFO]: Epoch 009 - training loss (CrossEntropy): 2586.3911, validation CrossEntropy: 1.5974\n","2025-06-07 13:41:04 [INFO]: Epoch 010 - training loss (CrossEntropy): 2581.5353, validation CrossEntropy: 1.5719\n","2025-06-07 13:41:08 [INFO]: Epoch 011 - training loss (CrossEntropy): 2567.4861, validation CrossEntropy: 1.5611\n","2025-06-07 13:41:11 [INFO]: Epoch 012 - training loss (CrossEntropy): 2562.2874, validation CrossEntropy: 1.5186\n","2025-06-07 13:41:15 [INFO]: Epoch 013 - training loss (CrossEntropy): 2551.7398, validation CrossEntropy: 1.4949\n","2025-06-07 13:41:18 [INFO]: Epoch 014 - training loss (CrossEntropy): 2548.1362, validation CrossEntropy: 1.4894\n","2025-06-07 13:41:22 [INFO]: Epoch 015 - training loss (CrossEntropy): 2528.4421, validation CrossEntropy: 1.4797\n","2025-06-07 13:41:25 [INFO]: Epoch 016 - training loss (CrossEntropy): 2529.1254, validation CrossEntropy: 1.5067\n","2025-06-07 13:41:29 [INFO]: Epoch 017 - training loss (CrossEntropy): 2522.3458, validation CrossEntropy: 1.4987\n","2025-06-07 13:41:33 [INFO]: Epoch 018 - training loss (CrossEntropy): 2525.1475, validation CrossEntropy: 1.4861\n","2025-06-07 13:41:36 [INFO]: Epoch 019 - training loss (CrossEntropy): 2513.2093, validation CrossEntropy: 1.4840\n","2025-06-07 13:41:39 [INFO]: Epoch 020 - training loss (CrossEntropy): 2508.8849, validation CrossEntropy: 1.4769\n","2025-06-07 13:41:43 [INFO]: Epoch 021 - training loss (CrossEntropy): 2508.2707, validation CrossEntropy: 1.4565\n","2025-06-07 13:41:47 [INFO]: Epoch 022 - training loss (CrossEntropy): 2496.9599, validation CrossEntropy: 1.4488\n","2025-06-07 13:41:50 [INFO]: Epoch 023 - training loss (CrossEntropy): 2485.2243, validation CrossEntropy: 1.4406\n","2025-06-07 13:41:54 [INFO]: Epoch 024 - training loss (CrossEntropy): 2487.0669, validation CrossEntropy: 1.4535\n","2025-06-07 13:41:57 [INFO]: Epoch 025 - training loss (CrossEntropy): 2474.9013, validation CrossEntropy: 1.4398\n","2025-06-07 13:42:01 [INFO]: Epoch 026 - training loss (CrossEntropy): 2474.7947, validation CrossEntropy: 1.4306\n","2025-06-07 13:42:05 [INFO]: Epoch 027 - training loss (CrossEntropy): 2476.9204, validation CrossEntropy: 1.4201\n","2025-06-07 13:42:08 [INFO]: Epoch 028 - training loss (CrossEntropy): 2465.0170, validation CrossEntropy: 1.4237\n","2025-06-07 13:42:12 [INFO]: Epoch 029 - training loss (CrossEntropy): 2457.7631, validation CrossEntropy: 1.4234\n","2025-06-07 13:42:16 [INFO]: Epoch 030 - training loss (CrossEntropy): 2443.6226, validation CrossEntropy: 1.4199\n","2025-06-07 13:42:16 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:42:16 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T134025/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:42:18 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:42:18 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134218\n","2025-06-07 13:42:18 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134218/tensorboard\n","2025-06-07 13:42:18 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:42:18 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:42:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:42:25 [INFO]: Epoch 001 - training loss (CrossEntropy): 4179.9584, validation CrossEntropy: 1.6336\n","2025-06-07 13:42:28 [INFO]: Epoch 002 - training loss (CrossEntropy): 3248.2644, validation CrossEntropy: 1.6152\n","2025-06-07 13:42:32 [INFO]: Epoch 003 - training loss (CrossEntropy): 2794.0414, validation CrossEntropy: 1.6106\n","2025-06-07 13:42:35 [INFO]: Epoch 004 - training loss (CrossEntropy): 2647.1178, validation CrossEntropy: 1.6067\n","2025-06-07 13:42:39 [INFO]: Epoch 005 - training loss (CrossEntropy): 2633.3627, validation CrossEntropy: 1.5620\n","2025-06-07 13:42:43 [INFO]: Epoch 006 - training loss (CrossEntropy): 2621.4499, validation CrossEntropy: 1.5653\n","2025-06-07 13:42:46 [INFO]: Epoch 007 - training loss (CrossEntropy): 2602.8897, validation CrossEntropy: 1.5458\n","2025-06-07 13:42:50 [INFO]: Epoch 008 - training loss (CrossEntropy): 2601.5697, validation CrossEntropy: 1.5408\n","2025-06-07 13:42:54 [INFO]: Epoch 009 - training loss (CrossEntropy): 2586.2817, validation CrossEntropy: 1.5162\n","2025-06-07 13:42:57 [INFO]: Epoch 010 - training loss (CrossEntropy): 2573.6361, validation CrossEntropy: 1.5031\n","2025-06-07 13:43:01 [INFO]: Epoch 011 - training loss (CrossEntropy): 2562.5024, validation CrossEntropy: 1.4869\n","2025-06-07 13:43:04 [INFO]: Epoch 012 - training loss (CrossEntropy): 2558.8396, validation CrossEntropy: 1.4941\n","2025-06-07 13:43:08 [INFO]: Epoch 013 - training loss (CrossEntropy): 2551.6441, validation CrossEntropy: 1.4749\n","2025-06-07 13:43:12 [INFO]: Epoch 014 - training loss (CrossEntropy): 2549.6140, validation CrossEntropy: 1.4799\n","2025-06-07 13:43:15 [INFO]: Epoch 015 - training loss (CrossEntropy): 2550.4025, validation CrossEntropy: 1.4486\n","2025-06-07 13:43:19 [INFO]: Epoch 016 - training loss (CrossEntropy): 2530.5410, validation CrossEntropy: 1.4315\n","2025-06-07 13:43:22 [INFO]: Epoch 017 - training loss (CrossEntropy): 2522.5552, validation CrossEntropy: 1.4311\n","2025-06-07 13:43:26 [INFO]: Epoch 018 - training loss (CrossEntropy): 2524.3862, validation CrossEntropy: 1.4320\n","2025-06-07 13:43:29 [INFO]: Epoch 019 - training loss (CrossEntropy): 2517.4306, validation CrossEntropy: 1.4023\n","2025-06-07 13:43:33 [INFO]: Epoch 020 - training loss (CrossEntropy): 2509.9830, validation CrossEntropy: 1.4018\n","2025-06-07 13:43:36 [INFO]: Epoch 021 - training loss (CrossEntropy): 2508.0739, validation CrossEntropy: 1.3981\n","2025-06-07 13:43:40 [INFO]: Epoch 022 - training loss (CrossEntropy): 2506.5740, validation CrossEntropy: 1.3883\n","2025-06-07 13:43:43 [INFO]: Epoch 023 - training loss (CrossEntropy): 2486.0530, validation CrossEntropy: 1.3860\n","2025-06-07 13:43:47 [INFO]: Epoch 024 - training loss (CrossEntropy): 2480.1797, validation CrossEntropy: 1.3859\n","2025-06-07 13:43:51 [INFO]: Epoch 025 - training loss (CrossEntropy): 2481.4812, validation CrossEntropy: 1.3788\n","2025-06-07 13:43:54 [INFO]: Epoch 026 - training loss (CrossEntropy): 2478.5998, validation CrossEntropy: 1.3911\n","2025-06-07 13:43:58 [INFO]: Epoch 027 - training loss (CrossEntropy): 2463.8148, validation CrossEntropy: 1.3698\n","2025-06-07 13:44:01 [INFO]: Epoch 028 - training loss (CrossEntropy): 2464.0064, validation CrossEntropy: 1.3706\n","2025-06-07 13:44:05 [INFO]: Epoch 029 - training loss (CrossEntropy): 2469.8208, validation CrossEntropy: 1.3687\n","2025-06-07 13:44:09 [INFO]: Epoch 030 - training loss (CrossEntropy): 2457.3195, validation CrossEntropy: 1.3612\n","2025-06-07 13:44:09 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:44:09 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T134218/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:44:11 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:44:11 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134411\n","2025-06-07 13:44:11 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134411/tensorboard\n","2025-06-07 13:44:11 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:44:11 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:44:11 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:44:17 [INFO]: Epoch 001 - training loss (CrossEntropy): 4308.1573, validation CrossEntropy: 1.6753\n","2025-06-07 13:44:21 [INFO]: Epoch 002 - training loss (CrossEntropy): 3304.1902, validation CrossEntropy: 1.6737\n","2025-06-07 13:44:25 [INFO]: Epoch 003 - training loss (CrossEntropy): 2812.8418, validation CrossEntropy: 1.6694\n","2025-06-07 13:44:28 [INFO]: Epoch 004 - training loss (CrossEntropy): 2652.0250, validation CrossEntropy: 1.6627\n","2025-06-07 13:44:32 [INFO]: Epoch 005 - training loss (CrossEntropy): 2633.1838, validation CrossEntropy: 1.6462\n","2025-06-07 13:44:36 [INFO]: Epoch 006 - training loss (CrossEntropy): 2616.8751, validation CrossEntropy: 1.6276\n","2025-06-07 13:44:39 [INFO]: Epoch 007 - training loss (CrossEntropy): 2605.6993, validation CrossEntropy: 1.6173\n","2025-06-07 13:44:43 [INFO]: Epoch 008 - training loss (CrossEntropy): 2585.7747, validation CrossEntropy: 1.5838\n","2025-06-07 13:44:47 [INFO]: Epoch 009 - training loss (CrossEntropy): 2578.5018, validation CrossEntropy: 1.5374\n","2025-06-07 13:44:50 [INFO]: Epoch 010 - training loss (CrossEntropy): 2575.6300, validation CrossEntropy: 1.5043\n","2025-06-07 13:44:54 [INFO]: Epoch 011 - training loss (CrossEntropy): 2565.9961, validation CrossEntropy: 1.4908\n","2025-06-07 13:44:58 [INFO]: Epoch 012 - training loss (CrossEntropy): 2554.3592, validation CrossEntropy: 1.4826\n","2025-06-07 13:45:01 [INFO]: Epoch 013 - training loss (CrossEntropy): 2558.0032, validation CrossEntropy: 1.4629\n","2025-06-07 13:45:05 [INFO]: Epoch 014 - training loss (CrossEntropy): 2542.0047, validation CrossEntropy: 1.4879\n","2025-06-07 13:45:08 [INFO]: Epoch 015 - training loss (CrossEntropy): 2539.6898, validation CrossEntropy: 1.4706\n","2025-06-07 13:45:12 [INFO]: Epoch 016 - training loss (CrossEntropy): 2541.7174, validation CrossEntropy: 1.4376\n","2025-06-07 13:45:16 [INFO]: Epoch 017 - training loss (CrossEntropy): 2531.3143, validation CrossEntropy: 1.4360\n","2025-06-07 13:45:19 [INFO]: Epoch 018 - training loss (CrossEntropy): 2532.2343, validation CrossEntropy: 1.4247\n","2025-06-07 13:45:23 [INFO]: Epoch 019 - training loss (CrossEntropy): 2512.9218, validation CrossEntropy: 1.4257\n","2025-06-07 13:45:27 [INFO]: Epoch 020 - training loss (CrossEntropy): 2504.3152, validation CrossEntropy: 1.4387\n","2025-06-07 13:45:30 [INFO]: Epoch 021 - training loss (CrossEntropy): 2510.1347, validation CrossEntropy: 1.4207\n","2025-06-07 13:45:34 [INFO]: Epoch 022 - training loss (CrossEntropy): 2504.2424, validation CrossEntropy: 1.4143\n","2025-06-07 13:45:37 [INFO]: Epoch 023 - training loss (CrossEntropy): 2496.3749, validation CrossEntropy: 1.4090\n","2025-06-07 13:45:41 [INFO]: Epoch 024 - training loss (CrossEntropy): 2488.2975, validation CrossEntropy: 1.4046\n","2025-06-07 13:45:45 [INFO]: Epoch 025 - training loss (CrossEntropy): 2487.0490, validation CrossEntropy: 1.4034\n","2025-06-07 13:45:48 [INFO]: Epoch 026 - training loss (CrossEntropy): 2479.0170, validation CrossEntropy: 1.3930\n","2025-06-07 13:45:52 [INFO]: Epoch 027 - training loss (CrossEntropy): 2471.3421, validation CrossEntropy: 1.4107\n","2025-06-07 13:45:56 [INFO]: Epoch 028 - training loss (CrossEntropy): 2461.0718, validation CrossEntropy: 1.4012\n","2025-06-07 13:45:59 [INFO]: Epoch 029 - training loss (CrossEntropy): 2459.9944, validation CrossEntropy: 1.3903\n","2025-06-07 13:46:03 [INFO]: Epoch 030 - training loss (CrossEntropy): 2459.0120, validation CrossEntropy: 1.3844\n","2025-06-07 13:46:03 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:46:03 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T134411/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:46:05 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:46:05 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134605\n","2025-06-07 13:46:05 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134605/tensorboard\n","2025-06-07 13:46:05 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:46:05 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:46:05 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:46:11 [INFO]: Epoch 001 - training loss (CrossEntropy): 4156.1017, validation CrossEntropy: 1.6686\n","2025-06-07 13:46:15 [INFO]: Epoch 002 - training loss (CrossEntropy): 3176.9261, validation CrossEntropy: 1.6889\n","2025-06-07 13:46:19 [INFO]: Epoch 003 - training loss (CrossEntropy): 2778.3674, validation CrossEntropy: 1.6763\n","2025-06-07 13:46:23 [INFO]: Epoch 004 - training loss (CrossEntropy): 2647.7128, validation CrossEntropy: 1.6746\n","2025-06-07 13:46:26 [INFO]: Epoch 005 - training loss (CrossEntropy): 2635.1639, validation CrossEntropy: 1.6477\n","2025-06-07 13:46:30 [INFO]: Epoch 006 - training loss (CrossEntropy): 2627.6779, validation CrossEntropy: 1.6273\n","2025-06-07 13:46:33 [INFO]: Epoch 007 - training loss (CrossEntropy): 2600.9898, validation CrossEntropy: 1.5984\n","2025-06-07 13:46:37 [INFO]: Epoch 008 - training loss (CrossEntropy): 2592.6896, validation CrossEntropy: 1.6056\n","2025-06-07 13:46:41 [INFO]: Epoch 009 - training loss (CrossEntropy): 2583.9206, validation CrossEntropy: 1.5862\n","2025-06-07 13:46:44 [INFO]: Epoch 010 - training loss (CrossEntropy): 2573.7073, validation CrossEntropy: 1.5799\n","2025-06-07 13:46:48 [INFO]: Epoch 011 - training loss (CrossEntropy): 2567.8518, validation CrossEntropy: 1.5576\n","2025-06-07 13:46:52 [INFO]: Epoch 012 - training loss (CrossEntropy): 2553.5586, validation CrossEntropy: 1.5376\n","2025-06-07 13:46:55 [INFO]: Epoch 013 - training loss (CrossEntropy): 2547.9580, validation CrossEntropy: 1.5196\n","2025-06-07 13:46:59 [INFO]: Epoch 014 - training loss (CrossEntropy): 2538.3110, validation CrossEntropy: 1.5000\n","2025-06-07 13:47:02 [INFO]: Epoch 015 - training loss (CrossEntropy): 2543.9092, validation CrossEntropy: 1.4911\n","2025-06-07 13:47:06 [INFO]: Epoch 016 - training loss (CrossEntropy): 2538.4414, validation CrossEntropy: 1.4712\n","2025-06-07 13:47:10 [INFO]: Epoch 017 - training loss (CrossEntropy): 2528.9209, validation CrossEntropy: 1.4597\n","2025-06-07 13:47:13 [INFO]: Epoch 018 - training loss (CrossEntropy): 2520.3059, validation CrossEntropy: 1.4480\n","2025-06-07 13:47:17 [INFO]: Epoch 019 - training loss (CrossEntropy): 2509.8082, validation CrossEntropy: 1.4472\n","2025-06-07 13:47:20 [INFO]: Epoch 020 - training loss (CrossEntropy): 2506.7404, validation CrossEntropy: 1.4323\n","2025-06-07 13:47:24 [INFO]: Epoch 021 - training loss (CrossEntropy): 2509.2759, validation CrossEntropy: 1.4229\n","2025-06-07 13:47:27 [INFO]: Epoch 022 - training loss (CrossEntropy): 2502.4028, validation CrossEntropy: 1.4094\n","2025-06-07 13:47:31 [INFO]: Epoch 023 - training loss (CrossEntropy): 2486.6639, validation CrossEntropy: 1.4024\n","2025-06-07 13:47:35 [INFO]: Epoch 024 - training loss (CrossEntropy): 2490.2669, validation CrossEntropy: 1.4035\n","2025-06-07 13:47:38 [INFO]: Epoch 025 - training loss (CrossEntropy): 2471.2233, validation CrossEntropy: 1.3886\n","2025-06-07 13:47:42 [INFO]: Epoch 026 - training loss (CrossEntropy): 2474.8133, validation CrossEntropy: 1.4051\n","2025-06-07 13:47:45 [INFO]: Epoch 027 - training loss (CrossEntropy): 2475.2140, validation CrossEntropy: 1.3934\n","2025-06-07 13:47:49 [INFO]: Epoch 028 - training loss (CrossEntropy): 2470.7946, validation CrossEntropy: 1.3915\n","2025-06-07 13:47:52 [INFO]: Epoch 029 - training loss (CrossEntropy): 2457.4126, validation CrossEntropy: 1.3794\n","2025-06-07 13:47:56 [INFO]: Epoch 030 - training loss (CrossEntropy): 2452.3486, validation CrossEntropy: 1.3856\n","2025-06-07 13:47:56 [INFO]: Finished training. The best model is from epoch#29.\n","2025-06-07 13:47:56 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T134605/BRITS.pypots\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","2025-06-07 13:47:58 [INFO]: No given device, using default device: cpu\n","2025-06-07 13:47:58 [INFO]: Model files will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134758\n","2025-06-07 13:47:58 [INFO]: Tensorboard file will be saved to ./runs/classify/WEATHER-KNMI/brits/20250607_T134758/tensorboard\n","2025-06-07 13:47:58 [INFO]: Using customized CrossEntropy as the training loss function.\n","2025-06-07 13:47:58 [INFO]: Using customized CrossEntropy as the validation metric function.\n","2025-06-07 13:47:58 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 19,804\n","2025-06-07 13:48:05 [INFO]: Epoch 001 - training loss (CrossEntropy): 4122.2018, validation CrossEntropy: 1.7010\n","2025-06-07 13:48:09 [INFO]: Epoch 002 - training loss (CrossEntropy): 3239.4450, validation CrossEntropy: 1.6676\n","2025-06-07 13:48:12 [INFO]: Epoch 003 - training loss (CrossEntropy): 2817.3145, validation CrossEntropy: 1.6584\n","2025-06-07 13:48:16 [INFO]: Epoch 004 - training loss (CrossEntropy): 2656.2564, validation CrossEntropy: 1.6829\n","2025-06-07 13:48:20 [INFO]: Epoch 005 - training loss (CrossEntropy): 2631.6651, validation CrossEntropy: 1.6604\n","2025-06-07 13:48:23 [INFO]: Epoch 006 - training loss (CrossEntropy): 2621.5774, validation CrossEntropy: 1.6211\n","2025-06-07 13:48:27 [INFO]: Epoch 007 - training loss (CrossEntropy): 2596.9546, validation CrossEntropy: 1.6068\n","2025-06-07 13:48:31 [INFO]: Epoch 008 - training loss (CrossEntropy): 2590.4689, validation CrossEntropy: 1.6171\n","2025-06-07 13:48:34 [INFO]: Epoch 009 - training loss (CrossEntropy): 2583.9253, validation CrossEntropy: 1.5926\n","2025-06-07 13:48:38 [INFO]: Epoch 010 - training loss (CrossEntropy): 2570.0628, validation CrossEntropy: 1.5735\n","2025-06-07 13:48:41 [INFO]: Epoch 011 - training loss (CrossEntropy): 2570.7254, validation CrossEntropy: 1.5612\n","2025-06-07 13:48:45 [INFO]: Epoch 012 - training loss (CrossEntropy): 2562.8217, validation CrossEntropy: 1.5390\n","2025-06-07 13:48:48 [INFO]: Epoch 013 - training loss (CrossEntropy): 2558.6060, validation CrossEntropy: 1.5363\n","2025-06-07 13:48:52 [INFO]: Epoch 014 - training loss (CrossEntropy): 2547.0287, validation CrossEntropy: 1.5063\n","2025-06-07 13:48:56 [INFO]: Epoch 015 - training loss (CrossEntropy): 2545.8544, validation CrossEntropy: 1.5077\n","2025-06-07 13:48:59 [INFO]: Epoch 016 - training loss (CrossEntropy): 2529.6820, validation CrossEntropy: 1.5048\n","2025-06-07 13:49:03 [INFO]: Epoch 017 - training loss (CrossEntropy): 2536.0804, validation CrossEntropy: 1.5092\n","2025-06-07 13:49:06 [INFO]: Epoch 018 - training loss (CrossEntropy): 2527.1180, validation CrossEntropy: 1.4976\n","2025-06-07 13:49:10 [INFO]: Epoch 019 - training loss (CrossEntropy): 2519.8351, validation CrossEntropy: 1.4935\n","2025-06-07 13:49:14 [INFO]: Epoch 020 - training loss (CrossEntropy): 2505.2577, validation CrossEntropy: 1.4791\n","2025-06-07 13:49:17 [INFO]: Epoch 021 - training loss (CrossEntropy): 2507.9474, validation CrossEntropy: 1.4719\n","2025-06-07 13:49:21 [INFO]: Epoch 022 - training loss (CrossEntropy): 2499.5190, validation CrossEntropy: 1.4678\n","2025-06-07 13:49:25 [INFO]: Epoch 023 - training loss (CrossEntropy): 2495.9628, validation CrossEntropy: 1.4698\n","2025-06-07 13:49:28 [INFO]: Epoch 024 - training loss (CrossEntropy): 2487.7315, validation CrossEntropy: 1.4465\n","2025-06-07 13:49:32 [INFO]: Epoch 025 - training loss (CrossEntropy): 2487.1812, validation CrossEntropy: 1.4619\n","2025-06-07 13:49:35 [INFO]: Epoch 026 - training loss (CrossEntropy): 2485.4475, validation CrossEntropy: 1.4399\n","2025-06-07 13:49:39 [INFO]: Epoch 027 - training loss (CrossEntropy): 2462.5645, validation CrossEntropy: 1.4386\n","2025-06-07 13:49:43 [INFO]: Epoch 028 - training loss (CrossEntropy): 2468.0773, validation CrossEntropy: 1.4417\n","2025-06-07 13:49:46 [INFO]: Epoch 029 - training loss (CrossEntropy): 2457.5910, validation CrossEntropy: 1.4266\n","2025-06-07 13:49:50 [INFO]: Epoch 030 - training loss (CrossEntropy): 2459.8415, validation CrossEntropy: 1.4204\n","2025-06-07 13:49:50 [INFO]: Finished training. The best model is from epoch#30.\n","2025-06-07 13:49:50 [INFO]: Saved the model to ./runs/classify/WEATHER-KNMI/brits/20250607_T134758/BRITS.pypots\n"]},{"output_type":"stream","name":"stdout","text":["BRITS(rnn_hidden_size=32, classification_weight=1, reconstruction_weight=2) & 0.3051 ± 0.0763 & 0.1651 ± 0.0769 0.1580 ± 0.0662 0.2518 ± 0.0665 \\\n","[110.64922642707825, 110.9409646987915, 111.95354557037354, 111.15989232063293, 111.66374492645264]\n","111.2735 ± 0.4750\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"_L5JSg5SPoEd"},"source":["# Not deep models"],"id":"_L5JSg5SPoEd"},{"cell_type":"code","execution_count":31,"metadata":{"id":"133ce0d7","executionInfo":{"status":"ok","timestamp":1749495313046,"user_tz":-120,"elapsed":396,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"outputs":[],"source":["from sklearn.svm import SVC, LinearSVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from xgboost import XGBClassifier\n","from sklearn.base import ClassifierMixin\n","from typing import Any, TypeVar\n","from collections import namedtuple\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n","from time import time\n","\n","import ray\n","from ray import tune\n"],"id":"133ce0d7"},{"cell_type":"code","execution_count":32,"metadata":{"id":"5ba30246","executionInfo":{"status":"ok","timestamp":1749495313057,"user_tz":-120,"elapsed":2,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"outputs":[],"source":["_T = TypeVar('_T', bound=ClassifierMixin)\n","\n","def evaluate_classic_model(model: _T, X: Any, y: Any):\n","    y_pred = model.predict(X)\n","    accuracy = accuracy_score(y, y_pred)\n","    f1 = f1_score(y, y_pred, average='macro')\n","    precision = precision_score(y, y_pred, average='macro')\n","    recall = recall_score(y, y_pred, average='macro')\n","    confusion = confusion_matrix(y, y_pred)\n","    return namedtuple('Evaluation', ['accuracy', 'f1', 'precision', 'recall', 'confusion'])(accuracy, f1, precision, recall, confusion)\n","\n","def _get_formatted_metric(values: list[float]):\n","  avg = sum(values) / len(values)\n","  std = (sum([(v - avg) ** 2 for v in values]) / len(values)) ** 0.5\n","  return f\"{avg:.4f} ± {std:.4f}\"\n","\n","\n","def run_classic_model(\n","        model_cls: _T,\n","        model_kwargs: dict[str, Any],\n","        X_train, y_train, X_val, y_val, X_test, y_test,\n","        repeat: int = 5\n","):\n","  if X_train.ndim == 3:\n","      X_train = X_train.reshape((X_train.shape[0], X_train.shape[1] * X_train.shape[2]))\n","  if X_val.ndim == 3:\n","      X_val = X_val.reshape((X_val.shape[0], X_val.shape[1] * X_val.shape[2]))\n","  if X_test.ndim == 3:\n","      X_test = X_test.reshape((X_test.shape[0], X_test.shape[1] * X_test.shape[2]))\n","\n","  final_res = {\n","      'accuracy': [],\n","      'f1': [],\n","      'precision': [],\n","      'recall': []\n","  }\n","  training_times = []\n","  for _ in range(repeat):\n","    model = model_cls(**model_kwargs)\n","    _start = time()\n","    model.fit(X_train, y_train)\n","    _end = time()\n","    training_times.append(_end - _start)\n","    results = evaluate_classic_model(model, X_test, y_test)\n","    final_res['accuracy'].append(results.accuracy)\n","    final_res['f1'].append(results.f1)\n","    final_res['precision'].append(results.precision)\n","    final_res['recall'].append(results.recall)\n","\n","  print(\n","    f\"{model_cls} & {_get_formatted_metric(final_res['accuracy'])} & {_get_formatted_metric(final_res['f1'])} & {_get_formatted_metric(final_res['precision'])} & {_get_formatted_metric(final_res['recall'])} \\\\\\\\\"\n","  )\n","  print(training_times)\n","  print(_get_formatted_metric(training_times))\n"],"id":"5ba30246"},{"cell_type":"code","source":["def train_model_tune(\n","    config,\n","    model_cls: _T,\n","    X_train, y_train,\n","    X_val, y_val\n","):\n","  if X_train.ndim == 3:\n","      X_train = X_train.reshape((X_train.shape[0], X_train.shape[1] * X_train.shape[2]))\n","  if X_val.ndim == 3:\n","      X_val = X_val.reshape((X_val.shape[0], X_val.shape[1] * X_val.shape[2]))\n","\n","  model = model_cls(**config)\n","\n","  model.fit(X_train, y_train)\n","  val_metrics = evaluate_classic_model(model, X_val, y_val)\n","\n","  tune.report(\n","      {\n","        \"accuracy\": val_metrics.accuracy,\n","        \"f1\": val_metrics.f1,\n","        \"precision\": val_metrics.precision,\n","        \"recall\": val_metrics.recall\n","      }\n","  )"],"metadata":{"id":"EcjEaQ-eHU9k","executionInfo":{"status":"ok","timestamp":1749495313067,"user_tz":-120,"elapsed":3,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"execution_count":33,"outputs":[],"id":"EcjEaQ-eHU9k"},{"cell_type":"code","source":["def train_classic_model(\n","    model_cls: _T,\n","    model_kwargs: dict[str, Any],\n","    X_train, y_train\n",") -> _T:\n","  if X_train.ndim == 3:\n","      X_train = X_train.reshape((X_train.shape[0], X_train.shape[1] * X_train.shape[2]))\n","\n","  model = model_cls(**model_kwargs)\n","  model.fit(X_train, y_train)\n","  return model\n","\n","def predict_classic_model(\n","    model: _T,\n","    X_test,\n",") -> _T:\n","  if X_test.ndim == 3:\n","      X_test = X_test.reshape((X_test.shape[0], X_test.shape[1] * X_test.shape[2]))\n","  return model.predict(X_test)"],"metadata":{"id":"Lp2LgqzVDWvC","executionInfo":{"status":"ok","timestamp":1749495580567,"user_tz":-120,"elapsed":10,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"id":"Lp2LgqzVDWvC","execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["## SVC"],"metadata":{"id":"mBTWIcKDLBS_"},"id":"mBTWIcKDLBS_"},{"cell_type":"code","source":["tuner = tune.Tuner(\n","    tune.with_parameters(\n","        train_model_tune,\n","        model_cls=SVC,\n","        X_train=X_train_bal,\n","        y_train=y_train_bal,\n","        X_val=X_val_bal,\n","        y_val=y_val_bal,\n","    ),\n","    param_space={\n","        \"C\": tune.grid_search([0.1, 0.8, 1, 1.2, 2.0, 10]),\n","        'class_weight': tune.grid_search(['balanced', None])\n","    },\n","    tune_config=tune.TuneConfig(\n","        num_samples=1,\n","        metric=\"f1\",\n","        mode=\"max\"\n","    )\n",")\n","\n","results = tuner.fit()\n","best_metrics = results.get_best_result().metrics\n","print(f\"Best params: {results.get_best_result().config}\")\n","for k, v in best_metrics.items():\n","  if isinstance(v, float):\n","    print(f\"{k}: {v:.4f}\")\n","  else:\n","    print(f\"{k}: {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fl9N-o90KkQX","executionInfo":{"status":"ok","timestamp":1749394547377,"user_tz":-120,"elapsed":33772,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"6c7cb9da-4e02-4bd5-bab7-dc51b46410ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------------------------------------------+\n","| Configuration for experiment     train_model_tune_2025-06-08_14-55-14   |\n","+-------------------------------------------------------------------------+\n","| Search algorithm                 BasicVariantGenerator                  |\n","| Scheduler                        FIFOScheduler                          |\n","| Number of trials                 12                                     |\n","+-------------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/train_model_tune_2025-06-08_14-55-14\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-08_14-07-29_471419_2985/artifacts/2025-06-08_14-55-14/train_model_tune_2025-06-08_14-55-14/driver_artifacts`\n","\n","Trial status: 12 PENDING\n","Current time: 2025-06-08 14:55:14. Total running time: 0s\n","Logical resource usage: 0/8 CPUs, 0/0 GPUs\n","+-----------------------------------------------------------------+\n","| Trial name                     status        C   class_weight   |\n","+-----------------------------------------------------------------+\n","| train_model_tune_9581a_00000   PENDING     0.1   balanced       |\n","| train_model_tune_9581a_00001   PENDING     0.8   balanced       |\n","| train_model_tune_9581a_00002   PENDING     1     balanced       |\n","| train_model_tune_9581a_00003   PENDING     1.2   balanced       |\n","| train_model_tune_9581a_00004   PENDING     2     balanced       |\n","| train_model_tune_9581a_00005   PENDING    10     balanced       |\n","| train_model_tune_9581a_00006   PENDING     0.1                  |\n","| train_model_tune_9581a_00007   PENDING     0.8                  |\n","| train_model_tune_9581a_00008   PENDING     1                    |\n","| train_model_tune_9581a_00009   PENDING     1.2                  |\n","| train_model_tune_9581a_00010   PENDING     2                    |\n","| train_model_tune_9581a_00011   PENDING    10                    |\n","+-----------------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00004 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_9581a_00004 config              |\n","+--------------------------------------------------------+\n","| C                                                   2. |\n","| class_weight                                  balanced |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00002 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_9581a_00002 config              |\n","+--------------------------------------------------------+\n","| C                                                    1 |\n","| class_weight                                  balanced |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00005 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_9581a_00005 config              |\n","+--------------------------------------------------------+\n","| C                                                   10 |\n","| class_weight                                  balanced |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00003 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_9581a_00003 config              |\n","+--------------------------------------------------------+\n","| C                                                  1.2 |\n","| class_weight                                  balanced |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00006 started with configuration:\n","+---------------------------------------------------+\n","| Trial train_model_tune_9581a_00006 config         |\n","+---------------------------------------------------+\n","| C                                             0.1 |\n","| class_weight                                      |\n","+---------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00000 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_9581a_00000 config              |\n","+--------------------------------------------------------+\n","| C                                                  0.1 |\n","| class_weight                                  balanced |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00001 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_9581a_00001 config              |\n","+--------------------------------------------------------+\n","| C                                                  0.8 |\n","| class_weight                                  balanced |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00007 started with configuration:\n","+---------------------------------------------------+\n","| Trial train_model_tune_9581a_00007 config         |\n","+---------------------------------------------------+\n","| C                                             0.8 |\n","| class_weight                                      |\n","+---------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00004 completed after 1 iterations at 2025-06-08 14:55:31. Total running time: 17s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00004 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              8.69194 |\n","| time_total_s                                  8.69194 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.61727 |\n","| f1                                            0.50477 |\n","| precision                                     0.50637 |\n","| recall                                        0.51997 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00002 completed after 1 iterations at 2025-06-08 14:55:31. Total running time: 17s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00002 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              8.66499 |\n","| time_total_s                                  8.66499 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.60947 |\n","| f1                                             0.4963 |\n","| precision                                     0.49881 |\n","| recall                                        0.51349 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00005 completed after 1 iterations at 2025-06-08 14:55:31. Total running time: 17s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00005 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              8.45988 |\n","| time_total_s                                  8.45988 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62006 |\n","| f1                                            0.51814 |\n","| precision                                     0.51991 |\n","| recall                                        0.52941 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00006 completed after 1 iterations at 2025-06-08 14:55:32. Total running time: 18s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00006 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.92643 |\n","| time_total_s                                  7.92643 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.57159 |\n","| f1                                            0.45871 |\n","| precision                                      0.4478 |\n","| recall                                        0.48648 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=30609)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_model_tune pid=30609)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_9581a_00003 completed after 1 iterations at 2025-06-08 14:55:32. Total running time: 18s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00003 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              8.83336 |\n","| time_total_s                                  8.83336 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.61281 |\n","| f1                                            0.49897 |\n","| precision                                     0.50063 |\n","| recall                                        0.51544 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00007 completed after 1 iterations at 2025-06-08 14:55:33. Total running time: 18s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00007 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              5.81491 |\n","| time_total_s                                  5.81491 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6195 |\n","| f1                                            0.49729 |\n","| precision                                     0.48416 |\n","| recall                                         0.5235 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00000 completed after 1 iterations at 2025-06-08 14:55:33. Total running time: 19s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00000 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.73097 |\n","| time_total_s                                  7.73097 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.56936 |\n","| f1                                             0.4458 |\n","| precision                                     0.43786 |\n","| recall                                        0.47452 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00001 completed after 1 iterations at 2025-06-08 14:55:33. Total running time: 19s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00001 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.11819 |\n","| time_total_s                                  7.11819 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.61058 |\n","| f1                                            0.49935 |\n","| precision                                     0.50295 |\n","| recall                                        0.51529 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00008 started with configuration:\n","+--------------------------------------------------+\n","| Trial train_model_tune_9581a_00008 config        |\n","+--------------------------------------------------+\n","| C                                              1 |\n","| class_weight                                     |\n","+--------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00009 started with configuration:\n","+---------------------------------------------------+\n","| Trial train_model_tune_9581a_00009 config         |\n","+---------------------------------------------------+\n","| C                                             1.2 |\n","| class_weight                                      |\n","+---------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00010 started with configuration:\n","+--------------------------------------------------+\n","| Trial train_model_tune_9581a_00010 config        |\n","+--------------------------------------------------+\n","| C                                              2 |\n","| class_weight                                     |\n","+--------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00011 started with configuration:\n","+--------------------------------------------------+\n","| Trial train_model_tune_9581a_00011 config        |\n","+--------------------------------------------------+\n","| C                                             10 |\n","| class_weight                                     |\n","+--------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=31166)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=31166)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_9581a_00010 completed after 1 iterations at 2025-06-08 14:55:39. Total running time: 24s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00010 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.85669 |\n","| time_total_s                                  2.85669 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62786 |\n","| f1                                            0.50461 |\n","| precision                                     0.49076 |\n","| recall                                         0.5303 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00008 completed after 1 iterations at 2025-06-08 14:55:39. Total running time: 25s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00008 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.19433 |\n","| time_total_s                                  3.19433 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62117 |\n","| f1                                            0.49864 |\n","| precision                                     0.48532 |\n","| recall                                         0.5254 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_9581a_00009 completed after 1 iterations at 2025-06-08 14:55:39. Total running time: 25s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00009 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.24843 |\n","| time_total_s                                  3.24843 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62563 |\n","| f1                                            0.50338 |\n","| precision                                     0.48996 |\n","| recall                                        0.52992 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-08 14:55:40,125\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_model_tune_2025-06-08_14-55-14' in 0.0096s.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_9581a_00011 completed after 1 iterations at 2025-06-08 14:55:40. Total running time: 25s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_9581a_00011 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.88755 |\n","| time_total_s                                  2.88755 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63064 |\n","| f1                                             0.5085 |\n","| precision                                     0.49379 |\n","| recall                                        0.53392 |\n","+-------------------------------------------------------+\n","\n","Trial status: 12 TERMINATED\n","Current time: 2025-06-08 14:55:40. Total running time: 25s\n","Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n","Current best trial: 9581a_00005 with f1=0.5181449476154324 and params={'C': 10, 'class_weight': 'balanced'}\n","+------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status          C   class_weight       iter     total time (s)     accuracy         f1     precision     recall |\n","+------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_9581a_00000   TERMINATED    0.1   balanced              1            7.73097     0.569359   0.445798      0.437865   0.474522 |\n","| train_model_tune_9581a_00001   TERMINATED    0.8   balanced              1            7.11819     0.610585   0.499351      0.50295    0.515292 |\n","| train_model_tune_9581a_00002   TERMINATED    1     balanced              1            8.66499     0.609471   0.496303      0.498811   0.51349  |\n","| train_model_tune_9581a_00003   TERMINATED    1.2   balanced              1            8.83336     0.612813   0.498965      0.500631   0.515443 |\n","| train_model_tune_9581a_00004   TERMINATED    2     balanced              1            8.69194     0.61727    0.504772      0.506368   0.519969 |\n","| train_model_tune_9581a_00005   TERMINATED   10     balanced              1            8.45988     0.620056   0.518145      0.519906   0.529405 |\n","| train_model_tune_9581a_00006   TERMINATED    0.1                         1            7.92643     0.571588   0.458712      0.447796   0.486479 |\n","| train_model_tune_9581a_00007   TERMINATED    0.8                         1            5.81491     0.619499   0.497293      0.484156   0.523502 |\n","| train_model_tune_9581a_00008   TERMINATED    1                           1            3.19433     0.62117    0.498645      0.485322   0.525398 |\n","| train_model_tune_9581a_00009   TERMINATED    1.2                         1            3.24843     0.625627   0.503379      0.489965   0.529925 |\n","| train_model_tune_9581a_00010   TERMINATED    2                           1            2.85669     0.627855   0.504609      0.490762   0.530299 |\n","| train_model_tune_9581a_00011   TERMINATED   10                           1            2.88755     0.630641   0.508499      0.493793   0.533923 |\n","+------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n","Best params: {'C': 10, 'class_weight': 'balanced'}\n","accuracy: 0.6201\n","f1: 0.5181\n","precision: 0.5199\n","recall: 0.5294\n","timestamp: 1749394531\n","checkpoint_dir_name: None\n","done: True\n","training_iteration: 1\n","trial_id: 9581a_00005\n","date: 2025-06-08_14-55-31\n","time_this_iter_s: 8.4599\n","time_total_s: 8.4599\n","pid: 30565\n","hostname: 23346c329519\n","node_ip: 172.28.0.12\n","config: {'C': 10, 'class_weight': 'balanced'}\n","time_since_restore: 8.4599\n","iterations_since_restore: 1\n","experiment_tag: 5_C=10,class_weight=balanced\n"]}],"id":"Fl9N-o90KkQX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"891be840","outputId":"bd7ec990-56bf-4cd2-c005-c771788e428c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749394560933,"user_tz":-120,"elapsed":13538,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'sklearn.svm._classes.SVC'> & 0.5293 ± 0.0000 & 0.3989 ± 0.0000 & 0.4216 ± 0.0000 & 0.4354 ± 0.0000 \\\\\n","[1.8836233615875244, 1.8686199188232422, 1.826486349105835, 1.787987470626831, 1.8015129566192627]\n","1.8336 ± 0.0371\n"]}],"source":["run_classic_model(\n","    SVC,\n","    results.get_best_result().config,\n","    X_train=X_train_bal,\n","    y_train=y_train_bal,\n","    X_val=X_val_bal,\n","    y_val=y_val_bal,\n","    X_test=X_test_bal,\n","    y_test=y_test_bal,\n",")"],"id":"891be840"},{"cell_type":"code","source":["model = train_classic_model(\n","    SVC,\n","    {\n","        \"C\": 10,\n","    },\n","    X_train=X_train_bal,\n","    y_train=y_train_bal,\n",")\n","\n","y_test_pred = predict_classic_model(model, X_test_bal)\n","cm = confusion_matrix(y_test_bal, y_test_pred)\n","print(cm)\n","disp = ConfusionMatrixDisplay(\n","    confusion_matrix=cm,\n","    display_labels=[\n","        \"<500\", \"500-1000\", \"1000-2000\", \"2000-5000\", \"5000-10000\", \">10000\"\n","    ]\n",")\n","disp.plot(\n","    values_format=\"d\",\n","    xticks_rotation=45,\n","    cmap=\"Blues\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":629},"id":"53UVwcKtSuvS","executionInfo":{"status":"ok","timestamp":1749499484494,"user_tz":-120,"elapsed":2742,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"dfb35d64-b873-4c6f-c278-861015b61dd9"},"id":"53UVwcKtSuvS","execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["[[887   2  55  25  13  18]\n"," [182   0  39  10  15  17]\n"," [287   1 168  29  17  34]\n"," [158   0 512 171  74  85]\n"," [ 50   2 111 239 407 191]\n"," [  7   0  11   7  70 905]]\n"]},{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7e692899fd50>"]},"metadata":{},"execution_count":52},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["model = train_classic_model(\n","    SVC,\n","    {\n","        \"C\": 10,\n","    },\n","    X_train=X_train_bal,\n","    y_train=y_train_bal,\n",")\n","\n","y_test_pred = predict_classic_model(model, X_test_bal)\n"],"metadata":{"id":"gofNttUPcH4Q"},"id":"gofNttUPcH4Q","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## RFC"],"metadata":{"id":"8l-O-JFWLDiK"},"id":"8l-O-JFWLDiK"},{"cell_type":"code","source":["tuner = tune.Tuner(\n","    tune.with_parameters(\n","        train_model_tune,\n","        model_cls=RandomForestClassifier,\n","        X_train=X_train_bal,\n","        y_train=y_train_bal,\n","        X_val=X_val_bal,\n","        y_val=y_val_bal,\n","    ),\n","    param_space={\n","        \"n_estimators\": tune.grid_search([10, 50, 75, 100, 150, 200]),\n","        \"max_depth\": tune.grid_search([1, 3, 5, 10, None]),\n","        \"criterion\": tune.grid_search(['gini', 'log_loss', 'entropy'])\n","    },\n","    tune_config=tune.TuneConfig(\n","        num_samples=1,\n","        metric=\"f1\",\n","        mode=\"max\"\n","    )\n",")\n","\n","results = tuner.fit()\n","best_metrics = results.get_best_result().metrics\n","print(f\"Best params: {results.get_best_result().config}\")\n","for k, v in best_metrics.items():\n","  if isinstance(v, float):\n","    print(f\"{k}: {v:.4f}\")\n","  else:\n","    print(f\"{k}: {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbLJ8i2OLErF","executionInfo":{"status":"ok","timestamp":1749391754660,"user_tz":-120,"elapsed":106079,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"23ab1cad-188c-4a0a-9880-80200cadee34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-08 14:07:32,200\tINFO worker.py:1888 -- Started a local Ray instance.\n","2025-06-08 14:07:33,727\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n"]},{"output_type":"stream","name":"stdout","text":["+-------------------------------------------------------------------------+\n","| Configuration for experiment     train_model_tune_2025-06-08_14-07-29   |\n","+-------------------------------------------------------------------------+\n","| Search algorithm                 BasicVariantGenerator                  |\n","| Scheduler                        FIFOScheduler                          |\n","| Number of trials                 90                                     |\n","+-------------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/train_model_tune_2025-06-08_14-07-29\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-08_14-07-29_471419_2985/artifacts/2025-06-08_14-07-33/train_model_tune_2025-06-08_14-07-29/driver_artifacts`\n","\n","Trial status: 90 PENDING\n","Current time: 2025-06-08 14:07:35. Total running time: 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","+--------------------------------------------------------------------------------------+\n","| Trial name                     status       n_estimators     max_depth   criterion   |\n","+--------------------------------------------------------------------------------------+\n","| train_model_tune_ec733_00000   PENDING                10             1   gini        |\n","| train_model_tune_ec733_00001   PENDING                10             1   log_loss    |\n","| train_model_tune_ec733_00002   PENDING                10             1   entropy     |\n","| train_model_tune_ec733_00003   PENDING                10             3   gini        |\n","| train_model_tune_ec733_00004   PENDING                10             3   log_loss    |\n","+--------------------------------------------------------------------------------------+\n","85 more PENDING\n","\n","Trial train_model_tune_ec733_00006 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00006 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        5 |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00004 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00004 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            3 |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00001 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00001 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            1 |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00007 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00007 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            5 |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00005 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00005 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           3 |\n","| n_estimators                                       10 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00003 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00003 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        3 |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00002 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00002 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           1 |\n","| n_estimators                                       10 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00000 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00000 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        1 |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00001 completed after 1 iterations at 2025-06-08 14:07:39. Total running time: 5s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00001 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.40441 |\n","| time_total_s                                  0.40441 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.30864 |\n","| f1                                            0.16571 |\n","| precision                                     0.23545 |\n","| recall                                        0.30409 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00004 completed after 1 iterations at 2025-06-08 14:07:39. Total running time: 5s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00004 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.52753 |\n","| time_total_s                                  0.52753 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.59387 |\n","| f1                                            0.47711 |\n","| precision                                     0.46461 |\n","| recall                                         0.5024 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=5746)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_model_tune pid=5746)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00006 completed after 1 iterations at 2025-06-08 14:07:39. Total running time: 5s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00006 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               0.6168 |\n","| time_total_s                                   0.6168 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.59833 |\n","| f1                                            0.48327 |\n","| precision                                     0.47905 |\n","| recall                                        0.52352 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00005 completed after 1 iterations at 2025-06-08 14:07:40. Total running time: 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00005 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.38194 |\n","| time_total_s                                  0.38194 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.60836 |\n","| f1                                            0.48533 |\n","| precision                                     0.48096 |\n","| recall                                        0.51959 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00007 completed after 1 iterations at 2025-06-08 14:07:40. Total running time: 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00007 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.63045 |\n","| time_total_s                                  0.63045 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.61003 |\n","| f1                                            0.49214 |\n","| precision                                     0.47967 |\n","| recall                                        0.52099 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00003 completed after 1 iterations at 2025-06-08 14:07:40. Total running time: 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00003 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.41021 |\n","| time_total_s                                  0.41021 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.56212 |\n","| f1                                            0.44731 |\n","| precision                                     0.44156 |\n","| recall                                        0.48357 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00000 completed after 1 iterations at 2025-06-08 14:07:40. Total running time: 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00000 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               0.3301 |\n","| time_total_s                                   0.3301 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.3337 |\n","| f1                                            0.20825 |\n","| precision                                      0.2911 |\n","| recall                                        0.32503 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00002 completed after 1 iterations at 2025-06-08 14:07:40. Total running time: 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00002 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.35896 |\n","| time_total_s                                  0.35896 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.38997 |\n","| f1                                            0.23741 |\n","| precision                                     0.30677 |\n","| recall                                        0.32773 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00012 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00012 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                          |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00009 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00009 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                       10 |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00015 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00015 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        1 |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00013 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00013 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                              |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00011 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00011 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                          10 |\n","| n_estimators                                       10 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00014 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00014 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                             |\n","| n_estimators                                       10 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00008 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00008 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           5 |\n","| n_estimators                                       10 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00010 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00010 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                           10 |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00009 completed after 1 iterations at 2025-06-08 14:07:46. Total running time: 12s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00009 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.56636 |\n","| time_total_s                                  0.56636 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62507 |\n","| f1                                             0.5165 |\n","| precision                                      0.5236 |\n","| recall                                        0.53875 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00012 completed after 1 iterations at 2025-06-08 14:07:46. Total running time: 12s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00012 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.69086 |\n","| time_total_s                                  0.69086 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6078 |\n","| f1                                            0.50416 |\n","| precision                                     0.49924 |\n","| recall                                        0.52293 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00015 completed after 1 iterations at 2025-06-08 14:07:46. Total running time: 12s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00015 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.57843 |\n","| time_total_s                                  0.57843 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.41281 |\n","| f1                                            0.28485 |\n","| precision                                     0.35872 |\n","| recall                                        0.36167 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00008 completed after 1 iterations at 2025-06-08 14:07:46. Total running time: 12s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00008 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.50439 |\n","| time_total_s                                  0.50439 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6117 |\n","| f1                                             0.4977 |\n","| precision                                     0.48247 |\n","| recall                                        0.52473 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00011 completed after 1 iterations at 2025-06-08 14:07:46. Total running time: 12s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00011 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.70838 |\n","| time_total_s                                  0.70838 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.61838 |\n","| f1                                            0.50949 |\n","| precision                                     0.50974 |\n","| recall                                        0.53042 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=6467)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(train_model_tune pid=6467)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 8x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00013 completed after 1 iterations at 2025-06-08 14:07:46. Total running time: 12s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00013 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.77127 |\n","| time_total_s                                  0.77127 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.61671 |\n","| f1                                            0.51444 |\n","| precision                                     0.51408 |\n","| recall                                        0.53238 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00014 completed after 1 iterations at 2025-06-08 14:07:46. Total running time: 12s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00014 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.77638 |\n","| time_total_s                                  0.77638 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.60724 |\n","| f1                                            0.51904 |\n","| precision                                     0.52238 |\n","| recall                                        0.53257 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00010 completed after 1 iterations at 2025-06-08 14:07:47. Total running time: 13s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00010 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.58771 |\n","| time_total_s                                  0.58771 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.61281 |\n","| f1                                            0.50185 |\n","| precision                                      0.4997 |\n","| recall                                        0.52601 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00016 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00016 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            1 |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00016 completed after 1 iterations at 2025-06-08 14:07:52. Total running time: 18s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00016 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.56586 |\n","| time_total_s                                  0.56586 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.42674 |\n","| f1                                            0.28608 |\n","| precision                                     0.43417 |\n","| recall                                        0.37124 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=6884)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=6884)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00019 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00019 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            3 |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00018 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00018 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        3 |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00020 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00020 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           3 |\n","| n_estimators                                       50 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00017 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00017 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           1 |\n","| n_estimators                                       50 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00021 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00021 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        5 |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00017 completed after 1 iterations at 2025-06-08 14:07:53. Total running time: 19s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00017 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.66836 |\n","| time_total_s                                  0.66836 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.41003 |\n","| f1                                            0.26691 |\n","| precision                                     0.34361 |\n","| recall                                        0.35714 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00023 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00023 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           5 |\n","| n_estimators                                       50 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00022 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00022 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            5 |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00019 completed after 1 iterations at 2025-06-08 14:07:53. Total running time: 19s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00019 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.89919 |\n","| time_total_s                                  0.89919 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.57994 |\n","| f1                                            0.46457 |\n","| precision                                     0.45298 |\n","| recall                                        0.49611 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00020 completed after 1 iterations at 2025-06-08 14:07:53. Total running time: 19s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00020 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.89744 |\n","| time_total_s                                  0.89744 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.57939 |\n","| f1                                            0.46335 |\n","| precision                                     0.45335 |\n","| recall                                         0.4933 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00018 completed after 1 iterations at 2025-06-08 14:07:53. Total running time: 19s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00018 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.91889 |\n","| time_total_s                                  0.91889 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.58607 |\n","| f1                                            0.47262 |\n","| precision                                     0.46068 |\n","| recall                                        0.50327 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00021 completed after 1 iterations at 2025-06-08 14:07:54. Total running time: 20s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00021 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.92934 |\n","| time_total_s                                  0.92934 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62563 |\n","| f1                                            0.50709 |\n","| precision                                     0.49156 |\n","| recall                                        0.53311 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00023 completed after 1 iterations at 2025-06-08 14:07:54. Total running time: 20s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00023 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.85344 |\n","| time_total_s                                  0.85344 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62563 |\n","| f1                                            0.50614 |\n","| precision                                     0.49119 |\n","| recall                                        0.53276 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00022 completed after 1 iterations at 2025-06-08 14:07:54. Total running time: 20s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00022 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.87187 |\n","| time_total_s                                  0.87187 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.60724 |\n","| f1                                            0.49044 |\n","| precision                                     0.47746 |\n","| recall                                        0.52269 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00024 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00024 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                       10 |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00025 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00025 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                           10 |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00026 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00026 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                          10 |\n","| n_estimators                                       50 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00028 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00028 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                              |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00027 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00027 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                          |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00029 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00029 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                             |\n","| n_estimators                                       50 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00030 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00030 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        1 |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00024 completed after 1 iterations at 2025-06-08 14:08:00. Total running time: 26s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00024 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.78366 |\n","| time_total_s                                  1.78366 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63733 |\n","| f1                                            0.51909 |\n","| precision                                     0.50337 |\n","| recall                                        0.54459 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00031 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00031 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            1 |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00030 completed after 1 iterations at 2025-06-08 14:08:00. Total running time: 26s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00030 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.77148 |\n","| time_total_s                                  0.77148 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.36323 |\n","| f1                                            0.25442 |\n","| precision                                     0.38095 |\n","| recall                                        0.34174 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00031 completed after 1 iterations at 2025-06-08 14:08:01. Total running time: 27s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00031 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.78184 |\n","| time_total_s                                  0.78184 |\n","| training_iteration                                  1 |\n","| accuracy                                          0.4 |\n","| f1                                            0.26007 |\n","| precision                                     0.37972 |\n","| recall                                        0.35253 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=7627)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=7627)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 8x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00025 completed after 1 iterations at 2025-06-08 14:08:01. Total running time: 27s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00025 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.09893 |\n","| time_total_s                                  2.09893 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64568 |\n","| f1                                            0.52958 |\n","| precision                                     0.55276 |\n","| recall                                        0.55424 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00026 completed after 1 iterations at 2025-06-08 14:08:01. Total running time: 27s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00026 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.13045 |\n","| time_total_s                                  2.13045 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63733 |\n","| f1                                            0.52044 |\n","| precision                                     0.54391 |\n","| recall                                        0.54605 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00027 completed after 1 iterations at 2025-06-08 14:08:02. Total running time: 28s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00027 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.05625 |\n","| time_total_s                                  2.05625 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63398 |\n","| f1                                            0.53334 |\n","| precision                                     0.54745 |\n","| recall                                        0.54909 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00028 completed after 1 iterations at 2025-06-08 14:08:02. Total running time: 28s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00028 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.40987 |\n","| time_total_s                                  2.40987 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63955 |\n","| f1                                            0.53193 |\n","| precision                                     0.54523 |\n","| recall                                        0.55252 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00029 completed after 1 iterations at 2025-06-08 14:08:02. Total running time: 28s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00029 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.35817 |\n","| time_total_s                                  2.35817 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63621 |\n","| f1                                            0.53228 |\n","| precision                                     0.54712 |\n","| recall                                        0.55024 |\n","+-------------------------------------------------------+\n","\n","Trial status: 32 TERMINATED | 58 PENDING\n","Current time: 2025-06-08 14:08:05. Total running time: 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: ec733_00027 with f1=0.5333381759499427 and params={'n_estimators': 50, 'max_depth': None, 'criterion': 'gini'}\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   criterion       iter     total time (s)     accuracy         f1     precision     recall |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_ec733_00000   TERMINATED               10             1   gini               1           0.330098     0.333705   0.208251      0.291098   0.325031 |\n","| train_model_tune_ec733_00001   TERMINATED               10             1   log_loss           1           0.404408     0.308635   0.165711      0.235452   0.304094 |\n","| train_model_tune_ec733_00002   TERMINATED               10             1   entropy            1           0.35896      0.389972   0.237412      0.306769   0.327731 |\n","| train_model_tune_ec733_00003   TERMINATED               10             3   gini               1           0.410213     0.562117   0.447309      0.44156    0.483568 |\n","| train_model_tune_ec733_00004   TERMINATED               10             3   log_loss           1           0.527525     0.593872   0.477106      0.46461    0.502398 |\n","| train_model_tune_ec733_00032   PENDING                  75             1   entropy                                                                                  |\n","| train_model_tune_ec733_00033   PENDING                  75             3   gini                                                                                     |\n","| train_model_tune_ec733_00034   PENDING                  75             3   log_loss                                                                                 |\n","| train_model_tune_ec733_00035   PENDING                  75             3   entropy                                                                                  |\n","| train_model_tune_ec733_00036   PENDING                  75             5   gini                                                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","27 more TERMINATED, 53 more PENDING\n","\n","Trial train_model_tune_ec733_00032 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00032 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           1 |\n","| n_estimators                                       75 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00032 completed after 1 iterations at 2025-06-08 14:08:06. Total running time: 32s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00032 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.72461 |\n","| time_total_s                                  0.72461 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.41838 |\n","| f1                                            0.27606 |\n","| precision                                     0.38484 |\n","| recall                                        0.36195 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00034 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00034 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            3 |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00036 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00036 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        5 |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00033 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00033 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        3 |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=8091)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=8091)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00035 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00035 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           3 |\n","| n_estimators                                       75 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00037 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00037 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            5 |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00038 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00038 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           5 |\n","| n_estimators                                       75 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00039 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00039 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                       10 |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00034 completed after 1 iterations at 2025-06-08 14:08:07. Total running time: 33s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00034 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.05873 |\n","| time_total_s                                  1.05873 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.60613 |\n","| f1                                            0.48434 |\n","| precision                                     0.47556 |\n","| recall                                        0.51822 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00033 completed after 1 iterations at 2025-06-08 14:08:07. Total running time: 33s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00033 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.98383 |\n","| time_total_s                                  0.98383 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6039 |\n","| f1                                            0.48824 |\n","| precision                                     0.47543 |\n","| recall                                        0.51785 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00035 completed after 1 iterations at 2025-06-08 14:08:08. Total running time: 34s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00035 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.09011 |\n","| time_total_s                                  1.09011 |\n","| training_iteration                                  1 |\n","| accuracy                                          0.6 |\n","| f1                                            0.48435 |\n","| precision                                     0.47307 |\n","| recall                                        0.51314 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00036 completed after 1 iterations at 2025-06-08 14:08:08. Total running time: 34s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00036 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.26799 |\n","| time_total_s                                  1.26799 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62953 |\n","| f1                                            0.51394 |\n","| precision                                     0.49767 |\n","| recall                                        0.54074 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00038 completed after 1 iterations at 2025-06-08 14:08:08. Total running time: 34s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00038 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.25272 |\n","| time_total_s                                  1.25272 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62563 |\n","| f1                                            0.50848 |\n","| precision                                     0.49469 |\n","| recall                                        0.53614 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00037 completed after 1 iterations at 2025-06-08 14:08:08. Total running time: 34s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00037 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.33045 |\n","| time_total_s                                  1.33045 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62173 |\n","| f1                                            0.50472 |\n","| precision                                     0.49034 |\n","| recall                                        0.53332 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00039 completed after 1 iterations at 2025-06-08 14:08:09. Total running time: 35s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00039 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.72228 |\n","| time_total_s                                  1.72228 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.65014 |\n","| f1                                            0.53182 |\n","| precision                                     0.55487 |\n","| recall                                        0.55445 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00040 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00040 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                           10 |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00041 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00041 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                          10 |\n","| n_estimators                                       75 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00042 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00042 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                          |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00043 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00043 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                              |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00045 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00045 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        1 |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00044 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00044 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                             |\n","| n_estimators                                       75 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00046 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00046 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            1 |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00047 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00047 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           1 |\n","| n_estimators                                      100 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00045 completed after 1 iterations at 2025-06-08 14:08:15. Total running time: 41s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00045 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.89283 |\n","| time_total_s                                  0.89283 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.36323 |\n","| f1                                            0.25692 |\n","| precision                                     0.39175 |\n","| recall                                        0.33975 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=8865)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 7x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=8865)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 7x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00046 completed after 1 iterations at 2025-06-08 14:08:15. Total running time: 41s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00046 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.93936 |\n","| time_total_s                                  0.93936 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.40669 |\n","| f1                                            0.27261 |\n","| precision                                     0.36749 |\n","| recall                                        0.35872 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00040 completed after 1 iterations at 2025-06-08 14:08:16. Total running time: 42s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00040 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.10577 |\n","| time_total_s                                  3.10577 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64067 |\n","| f1                                            0.52361 |\n","| precision                                     0.56046 |\n","| recall                                        0.54791 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00047 completed after 1 iterations at 2025-06-08 14:08:16. Total running time: 42s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00047 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.91642 |\n","| time_total_s                                  0.91642 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.35376 |\n","| f1                                             0.2382 |\n","| precision                                      0.3423 |\n","| recall                                        0.33023 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00041 completed after 1 iterations at 2025-06-08 14:08:17. Total running time: 43s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00041 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.12338 |\n","| time_total_s                                  3.12338 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63565 |\n","| f1                                            0.52023 |\n","| precision                                     0.54311 |\n","| recall                                        0.54525 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00042 completed after 1 iterations at 2025-06-08 14:08:17. Total running time: 43s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00042 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.10663 |\n","| time_total_s                                  3.10663 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.53376 |\n","| precision                                     0.56014 |\n","| recall                                        0.55529 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00044 completed after 1 iterations at 2025-06-08 14:08:19. Total running time: 45s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00044 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.17907 |\n","| time_total_s                                  4.17907 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.53419 |\n","| precision                                     0.56361 |\n","| recall                                        0.55367 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00043 completed after 1 iterations at 2025-06-08 14:08:19. Total running time: 45s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00043 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.71057 |\n","| time_total_s                                  4.71057 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63231 |\n","| f1                                            0.52348 |\n","| precision                                     0.54903 |\n","| recall                                        0.54292 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00048 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00048 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        3 |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00049 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00049 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            3 |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00051 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00051 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        5 |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00050 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00050 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           3 |\n","| n_estimators                                      100 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00052 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00052 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            5 |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00048 completed after 1 iterations at 2025-06-08 14:08:22. Total running time: 48s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00048 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.23596 |\n","| time_total_s                                  1.23596 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.59833 |\n","| f1                                            0.48323 |\n","| precision                                     0.47605 |\n","| recall                                        0.51875 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=9342)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=9342)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 3x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00053 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00053 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           5 |\n","| n_estimators                                      100 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00049 completed after 1 iterations at 2025-06-08 14:08:23. Total running time: 49s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00049 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.39023 |\n","| time_total_s                                  1.39023 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.58774 |\n","| f1                                            0.47204 |\n","| precision                                     0.46062 |\n","| recall                                        0.50462 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00050 completed after 1 iterations at 2025-06-08 14:08:23. Total running time: 49s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00050 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.43659 |\n","| time_total_s                                  1.43659 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.59109 |\n","| f1                                            0.47581 |\n","| precision                                     0.46545 |\n","| recall                                        0.50827 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00051 completed after 1 iterations at 2025-06-08 14:08:23. Total running time: 49s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00051 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.68904 |\n","| time_total_s                                  1.68904 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63287 |\n","| f1                                            0.51523 |\n","| precision                                     0.49937 |\n","| recall                                         0.5423 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00054 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00054 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                       10 |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00055 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00055 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                           10 |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00052 completed after 1 iterations at 2025-06-08 14:08:24. Total running time: 50s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00052 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.89348 |\n","| time_total_s                                  1.89348 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63621 |\n","| f1                                            0.51545 |\n","| precision                                     0.50138 |\n","| recall                                        0.54241 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00053 completed after 1 iterations at 2025-06-08 14:08:24. Total running time: 50s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00053 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.78869 |\n","| time_total_s                                  1.78869 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62396 |\n","| f1                                            0.50732 |\n","| precision                                     0.49124 |\n","| recall                                        0.53489 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00054 completed after 1 iterations at 2025-06-08 14:08:27. Total running time: 53s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00054 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.67728 |\n","| time_total_s                                  3.67728 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64457 |\n","| f1                                            0.52562 |\n","| precision                                     0.50961 |\n","| recall                                        0.55075 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00056 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00056 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                          10 |\n","| n_estimators                                      100 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00055 completed after 1 iterations at 2025-06-08 14:08:28. Total running time: 54s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00055 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.58062 |\n","| time_total_s                                  4.58062 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64735 |\n","| f1                                            0.53265 |\n","| precision                                     0.57842 |\n","| recall                                        0.55572 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00057 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00057 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                          |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00058 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00058 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                              |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00059 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00059 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                             |\n","| n_estimators                                      100 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00060 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00060 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        1 |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00061 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00061 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            1 |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00060 completed after 1 iterations at 2025-06-08 14:08:30. Total running time: 56s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00060 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.09522 |\n","| time_total_s                                  1.09522 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.35543 |\n","| f1                                            0.24333 |\n","| precision                                     0.40451 |\n","| recall                                        0.34113 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=9987)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=9987)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 6x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00061 completed after 1 iterations at 2025-06-08 14:08:30. Total running time: 56s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00061 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.08853 |\n","| time_total_s                                  1.08853 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.39944 |\n","| f1                                            0.26606 |\n","| precision                                     0.39863 |\n","| recall                                        0.35246 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00056 completed after 1 iterations at 2025-06-08 14:08:31. Total running time: 57s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00056 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               3.5488 |\n","| time_total_s                                   3.5488 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64735 |\n","| f1                                            0.52623 |\n","| precision                                     0.51181 |\n","| recall                                        0.55219 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00062 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00062 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           1 |\n","| n_estimators                                      150 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00057 completed after 1 iterations at 2025-06-08 14:08:33. Total running time: 59s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00057 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.45324 |\n","| time_total_s                                  4.45324 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63955 |\n","| f1                                            0.53189 |\n","| precision                                     0.53818 |\n","| recall                                        0.54849 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00059 completed after 1 iterations at 2025-06-08 14:08:34. Total running time: 1min 0s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00059 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              5.18277 |\n","| time_total_s                                  5.18277 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64401 |\n","| f1                                            0.53451 |\n","| precision                                     0.54544 |\n","| recall                                        0.55267 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00058 completed after 1 iterations at 2025-06-08 14:08:34. Total running time: 1min 0s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00058 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               5.3998 |\n","| time_total_s                                   5.3998 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64345 |\n","| f1                                            0.53109 |\n","| precision                                     0.54076 |\n","| recall                                         0.5532 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00063 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00063 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        3 |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00062 completed after 1 iterations at 2025-06-08 14:08:34. Total running time: 1min 0s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00062 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.19677 |\n","| time_total_s                                  1.19677 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.41337 |\n","| f1                                            0.27687 |\n","| precision                                     0.37798 |\n","| recall                                        0.36203 |\n","+-------------------------------------------------------+\n","\n","Trial status: 63 TERMINATED | 1 RUNNING | 26 PENDING\n","Current time: 2025-06-08 14:08:35. Total running time: 1min 1s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: ec733_00059 with f1=0.5345079512806958 and params={'n_estimators': 100, 'max_depth': None, 'criterion': 'entropy'}\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   criterion       iter     total time (s)     accuracy         f1     precision     recall |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_ec733_00063   RUNNING                 150             3   gini                                                                                     |\n","| train_model_tune_ec733_00000   TERMINATED               10             1   gini               1           0.330098     0.333705   0.208251      0.291098   0.325031 |\n","| train_model_tune_ec733_00001   TERMINATED               10             1   log_loss           1           0.404408     0.308635   0.165711      0.235452   0.304094 |\n","| train_model_tune_ec733_00002   TERMINATED               10             1   entropy            1           0.35896      0.389972   0.237412      0.306769   0.327731 |\n","| train_model_tune_ec733_00003   TERMINATED               10             3   gini               1           0.410213     0.562117   0.447309      0.44156    0.483568 |\n","| train_model_tune_ec733_00004   TERMINATED               10             3   log_loss           1           0.527525     0.593872   0.477106      0.46461    0.502398 |\n","| train_model_tune_ec733_00064   PENDING                 150             3   log_loss                                                                                 |\n","| train_model_tune_ec733_00065   PENDING                 150             3   entropy                                                                                  |\n","| train_model_tune_ec733_00066   PENDING                 150             5   gini                                                                                     |\n","| train_model_tune_ec733_00067   PENDING                 150             5   log_loss                                                                                 |\n","| train_model_tune_ec733_00068   PENDING                 150             5   entropy                                                                                  |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","58 more TERMINATED, 21 more PENDING\n","\n","Trial train_model_tune_ec733_00065 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00065 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           3 |\n","| n_estimators                                      150 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00066 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00066 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        5 |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00064 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00064 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            3 |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00063 completed after 1 iterations at 2025-06-08 14:08:36. Total running time: 1min 2s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00063 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.70245 |\n","| time_total_s                                  1.70245 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.58942 |\n","| f1                                            0.47402 |\n","| precision                                     0.46361 |\n","| recall                                        0.50746 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=10426)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=10426)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 3x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00065 completed after 1 iterations at 2025-06-08 14:08:38. Total running time: 1min 4s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00065 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.30322 |\n","| time_total_s                                  2.30322 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.59944 |\n","| f1                                            0.48325 |\n","| precision                                     0.47113 |\n","| recall                                        0.51382 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00064 completed after 1 iterations at 2025-06-08 14:08:38. Total running time: 1min 4s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00064 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.31298 |\n","| time_total_s                                  2.31298 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.59499 |\n","| f1                                            0.47884 |\n","| precision                                     0.46664 |\n","| recall                                        0.51093 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00067 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00067 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            5 |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00066 completed after 1 iterations at 2025-06-08 14:08:38. Total running time: 1min 4s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00066 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.65624 |\n","| time_total_s                                  2.65624 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62674 |\n","| f1                                            0.51073 |\n","| precision                                      0.4947 |\n","| recall                                        0.53722 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00070 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00070 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                           10 |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00068 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00068 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           5 |\n","| n_estimators                                      150 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00069 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00069 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                       10 |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00067 completed after 1 iterations at 2025-06-08 14:08:41. Total running time: 1min 7s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00067 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.00398 |\n","| time_total_s                                  3.00398 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63454 |\n","| f1                                            0.51498 |\n","| precision                                      0.4994 |\n","| recall                                        0.54191 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=10729)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=10729)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 4x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00071 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00071 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                          10 |\n","| n_estimators                                      150 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00068 completed after 1 iterations at 2025-06-08 14:08:42. Total running time: 1min 8s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00068 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.98503 |\n","| time_total_s                                  2.98503 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62897 |\n","| f1                                             0.5087 |\n","| precision                                      0.4942 |\n","| recall                                        0.53705 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00074 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00074 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                             |\n","| n_estimators                                      150 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00072 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00072 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                          |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00073 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00073 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                              |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00069 completed after 1 iterations at 2025-06-08 14:08:44. Total running time: 1min 10s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00069 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.29757 |\n","| time_total_s                                  4.29757 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.52392 |\n","| precision                                     0.56083 |\n","| recall                                        0.54684 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00070 completed after 1 iterations at 2025-06-08 14:08:45. Total running time: 1min 11s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00070 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              6.06449 |\n","| time_total_s                                  6.06449 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64624 |\n","| f1                                            0.52927 |\n","| precision                                     0.56674 |\n","| recall                                        0.55391 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00075 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00075 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        1 |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00075 completed after 1 iterations at 2025-06-08 14:08:47. Total running time: 1min 13s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00075 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.20201 |\n","| time_total_s                                  1.20201 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.36992 |\n","| f1                                            0.26458 |\n","| precision                                     0.38542 |\n","| recall                                        0.34247 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00071 completed after 1 iterations at 2025-06-08 14:08:47. Total running time: 1min 13s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00071 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              5.48644 |\n","| time_total_s                                  5.48644 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64234 |\n","| f1                                            0.52129 |\n","| precision                                     0.50638 |\n","| recall                                        0.54774 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00076 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00076 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            1 |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=11248)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=11248)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00076 completed after 1 iterations at 2025-06-08 14:08:49. Total running time: 1min 15s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00076 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.79604 |\n","| time_total_s                                  1.79604 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.41114 |\n","| f1                                            0.27068 |\n","| precision                                     0.37727 |\n","| recall                                        0.35644 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00072 completed after 1 iterations at 2025-06-08 14:08:49. Total running time: 1min 15s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00072 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                                5.604 |\n","| time_total_s                                    5.604 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64178 |\n","| f1                                            0.52801 |\n","| precision                                     0.53328 |\n","| recall                                        0.54792 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00077 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00077 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           1 |\n","| n_estimators                                      200 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00073 completed after 1 iterations at 2025-06-08 14:08:50. Total running time: 1min 16s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00073 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               7.0671 |\n","| time_total_s                                   7.0671 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64735 |\n","| f1                                            0.53808 |\n","| precision                                     0.56326 |\n","| recall                                        0.55651 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00077 completed after 1 iterations at 2025-06-08 14:08:50. Total running time: 1min 16s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00077 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.34929 |\n","| time_total_s                                  1.34929 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.39889 |\n","| f1                                             0.2634 |\n","| precision                                     0.34683 |\n","| recall                                        0.34966 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00074 completed after 1 iterations at 2025-06-08 14:08:50. Total running time: 1min 16s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00074 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.36005 |\n","| time_total_s                                  7.36005 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.53295 |\n","| precision                                     0.53932 |\n","| recall                                          0.553 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00080 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00080 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           3 |\n","| n_estimators                                      200 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00078 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00078 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        3 |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00079 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00079 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            3 |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00080 completed after 1 iterations at 2025-06-08 14:08:54. Total running time: 1min 20s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00080 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.55045 |\n","| time_total_s                                  2.55045 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6039 |\n","| f1                                            0.48529 |\n","| precision                                      0.4761 |\n","| recall                                        0.51636 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00078 completed after 1 iterations at 2025-06-08 14:08:54. Total running time: 1min 20s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00078 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               2.6372 |\n","| time_total_s                                   2.6372 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.59443 |\n","| f1                                            0.47918 |\n","| precision                                     0.46874 |\n","| recall                                        0.51146 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=11431)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=11431)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 3x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00082 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00082 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                            5 |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00081 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00081 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                        5 |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00079 completed after 1 iterations at 2025-06-08 14:08:55. Total running time: 1min 21s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00079 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.38964 |\n","| time_total_s                                  3.38964 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.60334 |\n","| f1                                            0.48545 |\n","| precision                                     0.47363 |\n","| recall                                        0.51435 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00084 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00084 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                       10 |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00083 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00083 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                           5 |\n","| n_estimators                                      200 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00085 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00085 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                           10 |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00081 completed after 1 iterations at 2025-06-08 14:08:58. Total running time: 1min 24s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00081 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.25801 |\n","| time_total_s                                  3.25801 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62563 |\n","| f1                                            0.50959 |\n","| precision                                     0.49389 |\n","| recall                                        0.53683 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00082 completed after 1 iterations at 2025-06-08 14:08:58. Total running time: 1min 24s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00082 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.90857 |\n","| time_total_s                                  3.90857 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62061 |\n","| f1                                            0.50348 |\n","| precision                                     0.48883 |\n","| recall                                        0.53298 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00087 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_ec733_00087 config          |\n","+----------------------------------------------------+\n","| criterion                                     gini |\n","| max_depth                                          |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00083 completed after 1 iterations at 2025-06-08 14:08:59. Total running time: 1min 25s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00083 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.91672 |\n","| time_total_s                                  3.91672 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62173 |\n","| f1                                            0.50506 |\n","| precision                                     0.48904 |\n","| recall                                        0.53297 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00086 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00086 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                          10 |\n","| n_estimators                                      200 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=11746)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=11746)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\u001b[32m [repeated 5x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00088 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_ec733_00088 config              |\n","+--------------------------------------------------------+\n","| criterion                                     log_loss |\n","| max_depth                                              |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00084 completed after 1 iterations at 2025-06-08 14:09:01. Total running time: 1min 27s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00084 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               5.5356 |\n","| time_total_s                                   5.5356 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64568 |\n","| f1                                            0.52794 |\n","| precision                                     0.59236 |\n","| recall                                        0.55101 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00085 completed after 1 iterations at 2025-06-08 14:09:02. Total running time: 1min 28s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00085 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              6.51314 |\n","| time_total_s                                  6.51314 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64735 |\n","| f1                                            0.52841 |\n","| precision                                     0.56585 |\n","| recall                                        0.55221 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00089 started with configuration:\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00089 config             |\n","+-------------------------------------------------------+\n","| criterion                                     entropy |\n","| max_depth                                             |\n","| n_estimators                                      200 |\n","+-------------------------------------------------------+\n","\n","Trial status: 86 TERMINATED | 4 RUNNING\n","Current time: 2025-06-08 14:09:05. Total running time: 1min 31s\n","Logical resource usage: 4.0/8 CPUs, 0/0 GPUs\n","Current best trial: ec733_00073 with f1=0.5380782832330152 and params={'n_estimators': 150, 'max_depth': None, 'criterion': 'log_loss'}\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   criterion       iter     total time (s)     accuracy         f1     precision     recall |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_ec733_00086   RUNNING                 200            10   entropy                                                                                  |\n","| train_model_tune_ec733_00087   RUNNING                 200                 gini                                                                                     |\n","| train_model_tune_ec733_00088   RUNNING                 200                 log_loss                                                                                 |\n","| train_model_tune_ec733_00089   RUNNING                 200                 entropy                                                                                  |\n","| train_model_tune_ec733_00000   TERMINATED               10             1   gini               1           0.330098     0.333705   0.208251      0.291098   0.325031 |\n","| train_model_tune_ec733_00001   TERMINATED               10             1   log_loss           1           0.404408     0.308635   0.165711      0.235452   0.304094 |\n","| train_model_tune_ec733_00002   TERMINATED               10             1   entropy            1           0.35896      0.389972   0.237412      0.306769   0.327731 |\n","| train_model_tune_ec733_00003   TERMINATED               10             3   gini               1           0.410213     0.562117   0.447309      0.44156    0.483568 |\n","| train_model_tune_ec733_00004   TERMINATED               10             3   log_loss           1           0.527525     0.593872   0.477106      0.46461    0.502398 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","81 more TERMINATED\n","\n","Trial train_model_tune_ec733_00086 completed after 1 iterations at 2025-06-08 14:09:05. Total running time: 1min 31s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00086 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              5.73058 |\n","| time_total_s                                  5.73058 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64457 |\n","| f1                                            0.52639 |\n","| precision                                     0.59173 |\n","| recall                                        0.55073 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00087 completed after 1 iterations at 2025-06-08 14:09:05. Total running time: 1min 31s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00087 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              6.06666 |\n","| time_total_s                                  6.06666 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64791 |\n","| f1                                            0.53806 |\n","| precision                                     0.55061 |\n","| recall                                         0.5571 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_ec733_00088 completed after 1 iterations at 2025-06-08 14:09:07. Total running time: 1min 33s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00088 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              6.71588 |\n","| time_total_s                                  6.71588 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64958 |\n","| f1                                            0.54052 |\n","| precision                                     0.57452 |\n","| recall                                        0.55957 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-08 14:09:09,093\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_model_tune_2025-06-08_14-07-29' in 0.0279s.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_ec733_00089 completed after 1 iterations at 2025-06-08 14:09:09. Total running time: 1min 35s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_ec733_00089 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              6.31216 |\n","| time_total_s                                  6.31216 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64513 |\n","| f1                                            0.53135 |\n","| precision                                     0.55765 |\n","| recall                                         0.5537 |\n","+-------------------------------------------------------+\n","\n","Trial status: 90 TERMINATED\n","Current time: 2025-06-08 14:09:09. Total running time: 1min 35s\n","Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n","Current best trial: ec733_00088 with f1=0.54052233562401 and params={'n_estimators': 200, 'max_depth': None, 'criterion': 'log_loss'}\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   criterion       iter     total time (s)     accuracy         f1     precision     recall |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_ec733_00000   TERMINATED               10             1   gini               1           0.330098     0.333705   0.208251      0.291098   0.325031 |\n","| train_model_tune_ec733_00001   TERMINATED               10             1   log_loss           1           0.404408     0.308635   0.165711      0.235452   0.304094 |\n","| train_model_tune_ec733_00002   TERMINATED               10             1   entropy            1           0.35896      0.389972   0.237412      0.306769   0.327731 |\n","| train_model_tune_ec733_00003   TERMINATED               10             3   gini               1           0.410213     0.562117   0.447309      0.44156    0.483568 |\n","| train_model_tune_ec733_00004   TERMINATED               10             3   log_loss           1           0.527525     0.593872   0.477106      0.46461    0.502398 |\n","| train_model_tune_ec733_00005   TERMINATED               10             3   entropy            1           0.381939     0.608357   0.485332      0.480964   0.519593 |\n","| train_model_tune_ec733_00006   TERMINATED               10             5   gini               1           0.616803     0.598329   0.483267      0.479047   0.523524 |\n","| train_model_tune_ec733_00007   TERMINATED               10             5   log_loss           1           0.630446     0.610028   0.49214       0.47967    0.520992 |\n","| train_model_tune_ec733_00008   TERMINATED               10             5   entropy            1           0.504386     0.611699   0.497695      0.48247    0.524727 |\n","| train_model_tune_ec733_00009   TERMINATED               10            10   gini               1           0.566355     0.62507    0.516498      0.523597   0.538752 |\n","| train_model_tune_ec733_00010   TERMINATED               10            10   log_loss           1           0.587712     0.612813   0.50185       0.499697   0.526006 |\n","| train_model_tune_ec733_00011   TERMINATED               10            10   entropy            1           0.708385     0.618384   0.50949       0.50974    0.530422 |\n","| train_model_tune_ec733_00012   TERMINATED               10                 gini               1           0.690864     0.607799   0.50416       0.499243   0.522928 |\n","| train_model_tune_ec733_00013   TERMINATED               10                 log_loss           1           0.771271     0.616713   0.514443      0.514078   0.532376 |\n","| train_model_tune_ec733_00014   TERMINATED               10                 entropy            1           0.776377     0.607242   0.51904       0.522385   0.53257  |\n","| train_model_tune_ec733_00015   TERMINATED               50             1   gini               1           0.578432     0.412813   0.284849      0.358719   0.361666 |\n","| train_model_tune_ec733_00016   TERMINATED               50             1   log_loss           1           0.565856     0.426741   0.28608       0.434174   0.371235 |\n","| train_model_tune_ec733_00017   TERMINATED               50             1   entropy            1           0.668364     0.410028   0.266914      0.34361    0.357145 |\n","| train_model_tune_ec733_00018   TERMINATED               50             3   gini               1           0.918886     0.586072   0.472623      0.460677   0.503274 |\n","| train_model_tune_ec733_00019   TERMINATED               50             3   log_loss           1           0.899191     0.579944   0.464569      0.452976   0.496107 |\n","| train_model_tune_ec733_00020   TERMINATED               50             3   entropy            1           0.897444     0.579387   0.463353      0.453349   0.493304 |\n","| train_model_tune_ec733_00021   TERMINATED               50             5   gini               1           0.929336     0.625627   0.507092      0.49156    0.533106 |\n","| train_model_tune_ec733_00022   TERMINATED               50             5   log_loss           1           0.871867     0.607242   0.490442      0.477459   0.522685 |\n","| train_model_tune_ec733_00023   TERMINATED               50             5   entropy            1           0.853445     0.625627   0.506137      0.491194   0.532758 |\n","| train_model_tune_ec733_00024   TERMINATED               50            10   gini               1           1.78366      0.637326   0.519092      0.503365   0.544589 |\n","| train_model_tune_ec733_00025   TERMINATED               50            10   log_loss           1           2.09893      0.645682   0.529582      0.55276    0.554243 |\n","| train_model_tune_ec733_00026   TERMINATED               50            10   entropy            1           2.13045      0.637326   0.52044       0.543914   0.546055 |\n","| train_model_tune_ec733_00027   TERMINATED               50                 gini               1           2.05625      0.633983   0.533338      0.547448   0.549094 |\n","| train_model_tune_ec733_00028   TERMINATED               50                 log_loss           1           2.40987      0.639554   0.531934      0.545229   0.552516 |\n","| train_model_tune_ec733_00029   TERMINATED               50                 entropy            1           2.35817      0.636212   0.532281      0.547124   0.550239 |\n","| train_model_tune_ec733_00030   TERMINATED               75             1   gini               1           0.771479     0.363231   0.254423      0.380947   0.341741 |\n","| train_model_tune_ec733_00031   TERMINATED               75             1   log_loss           1           0.781838     0.4        0.260066      0.379716   0.35253  |\n","| train_model_tune_ec733_00032   TERMINATED               75             1   entropy            1           0.724606     0.418384   0.276061      0.384836   0.361953 |\n","| train_model_tune_ec733_00033   TERMINATED               75             3   gini               1           0.983835     0.6039     0.488236      0.475426   0.51785  |\n","| train_model_tune_ec733_00034   TERMINATED               75             3   log_loss           1           1.05873      0.606128   0.484337      0.475563   0.518223 |\n","| train_model_tune_ec733_00035   TERMINATED               75             3   entropy            1           1.09011      0.6        0.484351      0.473075   0.513143 |\n","| train_model_tune_ec733_00036   TERMINATED               75             5   gini               1           1.26799      0.629526   0.513944      0.497672   0.540744 |\n","| train_model_tune_ec733_00037   TERMINATED               75             5   log_loss           1           1.33045      0.621727   0.504717      0.490338   0.53332  |\n","| train_model_tune_ec733_00038   TERMINATED               75             5   entropy            1           1.25272      0.625627   0.508475      0.494686   0.536137 |\n","| train_model_tune_ec733_00039   TERMINATED               75            10   gini               1           1.72228      0.650139   0.531815      0.554866   0.554445 |\n","| train_model_tune_ec733_00040   TERMINATED               75            10   log_loss           1           3.10577      0.640669   0.523607      0.560461   0.547909 |\n","| train_model_tune_ec733_00041   TERMINATED               75            10   entropy            1           3.12338      0.635655   0.520232      0.543115   0.545252 |\n","| train_model_tune_ec733_00042   TERMINATED               75                 gini               1           3.10663      0.642897   0.533755      0.560142   0.55529  |\n","| train_model_tune_ec733_00043   TERMINATED               75                 log_loss           1           4.71057      0.632312   0.523482      0.549026   0.542924 |\n","| train_model_tune_ec733_00044   TERMINATED               75                 entropy            1           4.17907      0.642897   0.534185      0.56361    0.553674 |\n","| train_model_tune_ec733_00045   TERMINATED              100             1   gini               1           0.892826     0.363231   0.256922      0.391752   0.339754 |\n","| train_model_tune_ec733_00046   TERMINATED              100             1   log_loss           1           0.939357     0.406685   0.272615      0.367491   0.358722 |\n","| train_model_tune_ec733_00047   TERMINATED              100             1   entropy            1           0.916419     0.35376    0.238203      0.342304   0.330233 |\n","| train_model_tune_ec733_00048   TERMINATED              100             3   gini               1           1.23596      0.598329   0.483232      0.476054   0.518753 |\n","| train_model_tune_ec733_00049   TERMINATED              100             3   log_loss           1           1.39023      0.587744   0.472044      0.460617   0.504623 |\n","| train_model_tune_ec733_00050   TERMINATED              100             3   entropy            1           1.43659      0.591086   0.475805      0.465452   0.508266 |\n","| train_model_tune_ec733_00051   TERMINATED              100             5   gini               1           1.68904      0.632869   0.515228      0.499366   0.542299 |\n","| train_model_tune_ec733_00052   TERMINATED              100             5   log_loss           1           1.89348      0.636212   0.515447      0.501385   0.542414 |\n","| train_model_tune_ec733_00053   TERMINATED              100             5   entropy            1           1.78869      0.623955   0.507321      0.49124    0.534887 |\n","| train_model_tune_ec733_00054   TERMINATED              100            10   gini               1           3.67728      0.644568   0.525619      0.509607   0.550751 |\n","| train_model_tune_ec733_00055   TERMINATED              100            10   log_loss           1           4.58062      0.647354   0.532646      0.578424   0.555716 |\n","| train_model_tune_ec733_00056   TERMINATED              100            10   entropy            1           3.5488       0.647354   0.526231      0.511814   0.552189 |\n","| train_model_tune_ec733_00057   TERMINATED              100                 gini               1           4.45324      0.639554   0.531892      0.538177   0.54849  |\n","| train_model_tune_ec733_00058   TERMINATED              100                 log_loss           1           5.3998       0.643454   0.53109       0.540762   0.553197 |\n","| train_model_tune_ec733_00059   TERMINATED              100                 entropy            1           5.18277      0.644011   0.534508      0.545445   0.552668 |\n","| train_model_tune_ec733_00060   TERMINATED              150             1   gini               1           1.09522      0.355432   0.243333      0.404508   0.341129 |\n","| train_model_tune_ec733_00061   TERMINATED              150             1   log_loss           1           1.08853      0.399443   0.266061      0.398634   0.352462 |\n","| train_model_tune_ec733_00062   TERMINATED              150             1   entropy            1           1.19677      0.41337    0.276867      0.377977   0.362032 |\n","| train_model_tune_ec733_00063   TERMINATED              150             3   gini               1           1.70245      0.589415   0.474018      0.463615   0.507464 |\n","| train_model_tune_ec733_00064   TERMINATED              150             3   log_loss           1           2.31298      0.594986   0.478843      0.466644   0.510934 |\n","| train_model_tune_ec733_00065   TERMINATED              150             3   entropy            1           2.30322      0.599443   0.483251      0.471133   0.51382  |\n","| train_model_tune_ec733_00066   TERMINATED              150             5   gini               1           2.65624      0.626741   0.510732      0.494704   0.537219 |\n","| train_model_tune_ec733_00067   TERMINATED              150             5   log_loss           1           3.00398      0.63454    0.514982      0.499398   0.541909 |\n","| train_model_tune_ec733_00068   TERMINATED              150             5   entropy            1           2.98503      0.628969   0.5087        0.494198   0.537046 |\n","| train_model_tune_ec733_00069   TERMINATED              150            10   gini               1           4.29757      0.642897   0.523924      0.560833   0.546842 |\n","| train_model_tune_ec733_00070   TERMINATED              150            10   log_loss           1           6.06449      0.64624    0.529273      0.566742   0.553914 |\n","| train_model_tune_ec733_00071   TERMINATED              150            10   entropy            1           5.48644      0.64234    0.521286      0.50638    0.547742 |\n","| train_model_tune_ec733_00072   TERMINATED              150                 gini               1           5.604        0.641783   0.528013      0.533275   0.547921 |\n","| train_model_tune_ec733_00073   TERMINATED              150                 log_loss           1           7.0671       0.647354   0.538078      0.563261   0.556511 |\n","| train_model_tune_ec733_00074   TERMINATED              150                 entropy            1           7.36005      0.642897   0.532945      0.53932    0.553004 |\n","| train_model_tune_ec733_00075   TERMINATED              200             1   gini               1           1.20201      0.369916   0.264584      0.385423   0.342466 |\n","| train_model_tune_ec733_00076   TERMINATED              200             1   log_loss           1           1.79604      0.411142   0.270683      0.377273   0.356438 |\n","| train_model_tune_ec733_00077   TERMINATED              200             1   entropy            1           1.34929      0.398886   0.263395      0.346828   0.349659 |\n","| train_model_tune_ec733_00078   TERMINATED              200             3   gini               1           2.6372       0.594429   0.47918       0.468742   0.511463 |\n","| train_model_tune_ec733_00079   TERMINATED              200             3   log_loss           1           3.38964      0.603343   0.485451      0.473628   0.514351 |\n","| train_model_tune_ec733_00080   TERMINATED              200             3   entropy            1           2.55045      0.6039     0.485288      0.476099   0.516358 |\n","| train_model_tune_ec733_00081   TERMINATED              200             5   gini               1           3.25801      0.625627   0.50959       0.49389    0.536833 |\n","| train_model_tune_ec733_00082   TERMINATED              200             5   log_loss           1           3.90857      0.620613   0.503479      0.488833   0.532983 |\n","| train_model_tune_ec733_00083   TERMINATED              200             5   entropy            1           3.91672      0.621727   0.505058      0.489037   0.532972 |\n","| train_model_tune_ec733_00084   TERMINATED              200            10   gini               1           5.5356       0.645682   0.527944      0.592361   0.551013 |\n","| train_model_tune_ec733_00085   TERMINATED              200            10   log_loss           1           6.51314      0.647354   0.528407      0.565852   0.552213 |\n","| train_model_tune_ec733_00086   TERMINATED              200            10   entropy            1           5.73058      0.644568   0.52639       0.591733   0.550726 |\n","| train_model_tune_ec733_00087   TERMINATED              200                 gini               1           6.06666      0.647911   0.538057      0.550611   0.557102 |\n","| train_model_tune_ec733_00088   TERMINATED              200                 log_loss           1           6.71588      0.649582   0.540522      0.574516   0.559569 |\n","| train_model_tune_ec733_00089   TERMINATED              200                 entropy            1           6.31216      0.645125   0.53135       0.557654   0.553702 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n","Best params: {'n_estimators': 200, 'max_depth': None, 'criterion': 'log_loss'}\n","accuracy: 0.6496\n","f1: 0.5405\n","precision: 0.5745\n","recall: 0.5596\n","timestamp: 1749391747\n","checkpoint_dir_name: None\n","done: True\n","training_iteration: 1\n","trial_id: ec733_00088\n","date: 2025-06-08_14-09-07\n","time_this_iter_s: 6.7159\n","time_total_s: 6.7159\n","pid: 12042\n","hostname: 23346c329519\n","node_ip: 172.28.0.12\n","config: {'n_estimators': 200, 'max_depth': None, 'criterion': 'log_loss'}\n","time_since_restore: 6.7159\n","iterations_since_restore: 1\n","experiment_tag: 88_criterion=log_loss,max_depth=None,n_estimators=200\n"]}],"id":"HbLJ8i2OLErF"},{"cell_type":"code","execution_count":null,"metadata":{"id":"973810c7","outputId":"895241b6-5428-4ae0-a0c4-aff77939f310","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749391789561,"user_tz":-120,"elapsed":34829,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'sklearn.ensemble._forest.RandomForestClassifier'> & 0.6443 ± 0.0016 & 0.5352 ± 0.0020 & 0.5548 ± 0.0138 & 0.5525 ± 0.0017 \\\\\n","[5.976006031036377, 5.948693513870239, 5.825795412063599, 5.819310188293457, 5.777020454406738]\n","5.8694 ± 0.0782\n"]}],"source":["run_classic_model(\n","    RandomForestClassifier,\n","    results.get_best_result().config,\n","    X_train=X_train_bal,\n","    y_train=y_train_bal,\n","    X_val=X_val_bal,\n","    y_val=y_val_bal,\n","    X_test=X_test_bal,\n","    y_test=y_test_bal,\n",")"],"id":"973810c7"},{"cell_type":"code","source":["model = train_classic_model(\n","    XGBClassifier,\n","    {\n","        \"n_estimators\": 200,\n","        \"max_depth\": None,\n","        \"criterion\": 'log_loss'\n","    },\n","    X_train=X_train_bal,\n","    y_train=y_train_bal,\n",")\n","\n","y_test_pred = predict_classic_model(model, X_test_bal)\n","cm = confusion_matrix(y_test_bal, y_test_pred)\n","print(cm)\n","disp = ConfusionMatrixDisplay(\n","    confusion_matrix=cm,\n","    display_labels=[\n","        \"<500\", \"500-1000\", \"1000-2000\", \"2000-5000\", \"5000-10000\", \">10000\"\n","    ]\n",")\n","disp.plot(\n","    values_format=\"d\",\n","    xticks_rotation=45,\n","    cmap=\"Blues\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":721},"id":"0Rmd2PpcSKm5","executionInfo":{"status":"ok","timestamp":1749499381730,"user_tz":-120,"elapsed":4043,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"00052c23-8a31-4463-c0ad-b2df097396b9"},"id":"0Rmd2PpcSKm5","execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:02:57] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"criterion\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[[779  39  98  34  33  17]\n"," [116  21  50  34  24  18]\n"," [109  28 239  85  46  29]\n"," [ 50  12 158 479 236  65]\n"," [ 15   2  12 155 634 182]\n"," [  3   0   3  10 123 861]]\n"]},{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7e69289a1d90>"]},"metadata":{},"execution_count":49},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## XGB"],"metadata":{"id":"0Xu68eIFL3yy"},"id":"0Xu68eIFL3yy"},{"cell_type":"code","source":["tuner = tune.Tuner(\n","    tune.with_parameters(\n","        train_model_tune,\n","        model_cls=XGBClassifier,\n","        X_train=X_train_bal,\n","        y_train=y_train_bal,\n","        X_val=X_val_bal,\n","        y_val=y_val_bal,\n","    ),\n","    param_space={\n","        \"n_estimators\": tune.grid_search([10, 50, 75, 100, 150, 200]),\n","        \"max_depth\": tune.grid_search([1, 3, 5, 10, None]),\n","        \"booster\": tune.grid_search(['gbtree', 'gblinear', 'dart'])\n","    },\n","    tune_config=tune.TuneConfig(\n","        num_samples=1,\n","        metric=\"f1\",\n","        mode=\"max\"\n","    )\n",")\n","\n","results = tuner.fit()\n","best_metrics = results.get_best_result().metrics\n","print(f\"Best params: {results.get_best_result().config}\")\n","for k, v in best_metrics.items():\n","  if isinstance(v, float):\n","    print(f\"{k}: {v:.4f}\")\n","  else:\n","    print(f\"{k}: {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gE-IT4-GL6Qt","executionInfo":{"status":"ok","timestamp":1749394513530,"user_tz":-120,"elapsed":2704698,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"e0106787-1f0f-4ea7-b42e-89dfa8126a7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------------------------------------------+\n","| Configuration for experiment     train_model_tune_2025-06-08_14-10-09   |\n","+-------------------------------------------------------------------------+\n","| Search algorithm                 BasicVariantGenerator                  |\n","| Scheduler                        FIFOScheduler                          |\n","| Number of trials                 90                                     |\n","+-------------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/train_model_tune_2025-06-08_14-10-09\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-08_14-07-29_471419_2985/artifacts/2025-06-08_14-10-09/train_model_tune_2025-06-08_14-10-09/driver_artifacts`\n","\n","Trial status: 90 PENDING\n","Current time: 2025-06-08 14:10:10. Total running time: 0s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","+------------------------------------------------------------------------------------+\n","| Trial name                     status       n_estimators     max_depth   booster   |\n","+------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00000   PENDING                10             1   gbtree    |\n","| train_model_tune_496cf_00001   PENDING                10             1   gblinear  |\n","| train_model_tune_496cf_00002   PENDING                10             1   dart      |\n","| train_model_tune_496cf_00003   PENDING                10             3   gbtree    |\n","| train_model_tune_496cf_00004   PENDING                10             3   gblinear  |\n","+------------------------------------------------------------------------------------+\n","85 more PENDING\n","\n","Trial train_model_tune_496cf_00001 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00001 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            1 |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00003 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00003 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          3 |\n","| n_estimators                                      10 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00000 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00000 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          1 |\n","| n_estimators                                      10 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00002 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00002 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        1 |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=12581)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:10:14] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=12581)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=12581)\u001b[0m \n","\u001b[36m(train_model_tune pid=12581)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00005 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00005 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        3 |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00006 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00006 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          5 |\n","| n_estimators                                      10 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00000 completed after 1 iterations at 2025-06-08 14:10:15. Total running time: 5s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00000 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.43947 |\n","| time_total_s                                  0.43947 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63788 |\n","| f1                                            0.51695 |\n","| precision                                     0.50587 |\n","| recall                                        0.54272 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00007 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00007 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            5 |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00004 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00004 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            3 |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00003 completed after 1 iterations at 2025-06-08 14:10:15. Total running time: 5s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00003 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.64119 |\n","| time_total_s                                  0.64119 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64791 |\n","| f1                                            0.53698 |\n","| precision                                     0.55511 |\n","| recall                                        0.55273 |\n","+-------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=12582)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_model_tune pid=12582)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\u001b[36m(train_model_tune pid=12583)\u001b[0m \n","\u001b[36m(train_model_tune pid=12579)\u001b[0m \n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00001 completed after 1 iterations at 2025-06-08 14:10:15. Total running time: 5s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00001 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.77539 |\n","| time_total_s                                  0.77539 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.58552 |\n","| f1                                            0.47134 |\n","| precision                                     0.45735 |\n","| recall                                        0.49779 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00004 completed after 1 iterations at 2025-06-08 14:10:16. Total running time: 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00004 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               0.6716 |\n","| time_total_s                                   0.6716 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.58552 |\n","| f1                                            0.47134 |\n","| precision                                     0.45735 |\n","| recall                                        0.49779 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00007 completed after 1 iterations at 2025-06-08 14:10:16. Total running time: 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00007 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.78149 |\n","| time_total_s                                  0.78149 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.58552 |\n","| f1                                            0.47134 |\n","| precision                                     0.45735 |\n","| recall                                        0.49779 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00006 completed after 1 iterations at 2025-06-08 14:10:16. Total running time: 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00006 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.04683 |\n","| time_total_s                                  1.04683 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.65181 |\n","| f1                                             0.5613 |\n","| precision                                     0.57086 |\n","| recall                                        0.56747 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00002 completed after 1 iterations at 2025-06-08 14:10:19. Total running time: 10s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00002 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.77278 |\n","| time_total_s                                  4.77278 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63788 |\n","| f1                                            0.51695 |\n","| precision                                     0.50587 |\n","| recall                                        0.54272 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00005 completed after 1 iterations at 2025-06-08 14:10:19. Total running time: 10s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00005 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               4.7783 |\n","| time_total_s                                   4.7783 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64791 |\n","| f1                                            0.53698 |\n","| precision                                     0.55511 |\n","| recall                                        0.55273 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00008 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00008 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        5 |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00010 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00010 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                           10 |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=13084)\u001b[0m \n","\u001b[36m(train_model_tune pid=13084)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:10:21] WARNING: /workspace/src/learner.cc:740: \u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=13084)\u001b[0m Parameters: { \"max_depth\" } are not used.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=13084)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=12576)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\u001b[36m(train_model_tune pid=12576)\u001b[0m   _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00009 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00009 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                         10 |\n","| n_estimators                                      10 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00010 completed after 1 iterations at 2025-06-08 14:10:21. Total running time: 11s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00010 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.73184 |\n","| time_total_s                                  0.73184 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.58552 |\n","| f1                                            0.47134 |\n","| precision                                     0.45735 |\n","| recall                                        0.49779 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00011 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00011 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                       10 |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00012 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00012 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                            |\n","| n_estimators                                      10 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00013 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00013 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                              |\n","| n_estimators                                        10 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00013 completed after 1 iterations at 2025-06-08 14:10:22. Total running time: 13s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00013 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.76843 |\n","| time_total_s                                  0.76843 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.58552 |\n","| f1                                            0.47134 |\n","| precision                                     0.45735 |\n","| recall                                        0.49779 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00012 completed after 1 iterations at 2025-06-08 14:10:23. Total running time: 13s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00012 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               1.7004 |\n","| time_total_s                                   1.7004 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64401 |\n","| f1                                            0.54823 |\n","| precision                                     0.54851 |\n","| recall                                        0.55873 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00009 completed after 1 iterations at 2025-06-08 14:10:24. Total running time: 14s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00009 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               3.3558 |\n","| time_total_s                                   3.3558 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6312 |\n","| f1                                            0.53648 |\n","| precision                                     0.53474 |\n","| recall                                        0.54723 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00014 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00014 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                          |\n","| n_estimators                                    10 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00015 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00015 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          1 |\n","| n_estimators                                      50 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00016 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00016 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            1 |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=13413)\u001b[0m \n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00008 completed after 1 iterations at 2025-06-08 14:10:26. Total running time: 16s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00008 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              5.62786 |\n","| time_total_s                                  5.62786 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.65181 |\n","| f1                                             0.5613 |\n","| precision                                     0.57086 |\n","| recall                                        0.56747 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00015 completed after 1 iterations at 2025-06-08 14:10:26. Total running time: 16s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00015 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              0.77139 |\n","| time_total_s                                  0.77139 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64513 |\n","| f1                                            0.53061 |\n","| precision                                     0.53411 |\n","| recall                                        0.55094 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00017 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00017 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        1 |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00018 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00018 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          3 |\n","| n_estimators                                      50 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00016 completed after 1 iterations at 2025-06-08 14:10:28. Total running time: 18s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00016 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               2.6244 |\n","| time_total_s                                   2.6244 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63621 |\n","| f1                                            0.52204 |\n","| precision                                     0.51973 |\n","| recall                                        0.54651 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00011 completed after 1 iterations at 2025-06-08 14:10:28. Total running time: 19s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00011 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.18448 |\n","| time_total_s                                  7.18448 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6312 |\n","| f1                                            0.53648 |\n","| precision                                     0.53474 |\n","| recall                                        0.54723 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00019 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00019 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            3 |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=13717)\u001b[0m \n","\u001b[36m(train_model_tune pid=13717)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:10:29] WARNING: /workspace/src/learner.cc:740: \u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=13717)\u001b[0m Parameters: { \"max_depth\" } are not used.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=13717)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00014 completed after 1 iterations at 2025-06-08 14:10:29. Total running time: 19s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00014 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.75219 |\n","| time_total_s                                  4.75219 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64401 |\n","| f1                                            0.54823 |\n","| precision                                     0.54851 |\n","| recall                                        0.55873 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00018 completed after 1 iterations at 2025-06-08 14:10:29. Total running time: 20s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00018 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.67564 |\n","| time_total_s                                  1.67564 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64791 |\n","| f1                                            0.56244 |\n","| precision                                     0.57176 |\n","| recall                                        0.56848 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00021 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00021 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          5 |\n","| n_estimators                                      50 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00020 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00020 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        3 |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00019 completed after 1 iterations at 2025-06-08 14:10:32. Total running time: 22s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00019 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.66363 |\n","| time_total_s                                  2.66363 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63621 |\n","| f1                                            0.52204 |\n","| precision                                     0.51973 |\n","| recall                                        0.54651 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00022 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00022 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            5 |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00023 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00023 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        5 |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00024 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00024 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                         10 |\n","| n_estimators                                      50 |\n","+------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=13916)\u001b[0m \n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00021 completed after 1 iterations at 2025-06-08 14:10:34. Total running time: 25s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00021 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.35831 |\n","| time_total_s                                  3.35831 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64903 |\n","| f1                                            0.56123 |\n","| precision                                     0.56424 |\n","| recall                                        0.56755 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00025 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00025 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                           10 |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=14093)\u001b[0m \n","\u001b[36m(train_model_tune pid=14093)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:10:35] WARNING: /workspace/src/learner.cc:740: \u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=14093)\u001b[0m Parameters: { \"max_depth\" } are not used.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(train_model_tune pid=14093)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00022 completed after 1 iterations at 2025-06-08 14:10:36. Total running time: 26s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00022 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.09264 |\n","| time_total_s                                  3.09264 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63621 |\n","| f1                                            0.52204 |\n","| precision                                     0.51973 |\n","| recall                                        0.54651 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00026 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00026 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                       10 |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00025 completed after 1 iterations at 2025-06-08 14:10:38. Total running time: 28s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00025 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.73748 |\n","| time_total_s                                  2.73748 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63621 |\n","| f1                                            0.52204 |\n","| precision                                     0.51973 |\n","| recall                                        0.54651 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00027 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00027 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                            |\n","| n_estimators                                      50 |\n","+------------------------------------------------------+\n","\n","Trial status: 22 TERMINATED | 6 RUNNING | 62 PENDING\n","Current time: 2025-06-08 14:10:40. Total running time: 30s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00018 with f1=0.5624438066183667 and params={'n_estimators': 50, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00017   RUNNING                  50             1   dart                                                                                   |\n","| train_model_tune_496cf_00020   RUNNING                  50             3   dart                                                                                   |\n","| train_model_tune_496cf_00023   RUNNING                  50             5   dart                                                                                   |\n","| train_model_tune_496cf_00024   RUNNING                  50            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00026   RUNNING                  50            10   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00028   PENDING                  50                 gblinear                                                                               |\n","| train_model_tune_496cf_00029   PENDING                  50                 dart                                                                                   |\n","| train_model_tune_496cf_00030   PENDING                  75             1   gbtree                                                                                 |\n","| train_model_tune_496cf_00031   PENDING                  75             1   gblinear                                                                               |\n","| train_model_tune_496cf_00032   PENDING                  75             1   dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","1 more RUNNING, 17 more TERMINATED, 57 more PENDING\n","\n","Trial train_model_tune_496cf_00028 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00028 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                              |\n","| n_estimators                                        50 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00024 completed after 1 iterations at 2025-06-08 14:10:42. Total running time: 32s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00024 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                                8.657 |\n","| time_total_s                                    8.657 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63008 |\n","| f1                                            0.53945 |\n","| precision                                     0.54164 |\n","| recall                                        0.54866 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00029 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00029 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                          |\n","| n_estimators                                    50 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00028 completed after 1 iterations at 2025-06-08 14:10:44. Total running time: 34s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00028 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.63229 |\n","| time_total_s                                  2.63229 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63621 |\n","| f1                                            0.52204 |\n","| precision                                     0.51973 |\n","| recall                                        0.54651 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00027 completed after 1 iterations at 2025-06-08 14:10:45. Total running time: 35s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00027 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.30226 |\n","| time_total_s                                  4.30226 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64345 |\n","| f1                                            0.55017 |\n","| precision                                     0.55042 |\n","| recall                                        0.55916 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00030 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00030 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          1 |\n","| n_estimators                                      75 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00031 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00031 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            1 |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=14481)\u001b[0m \n","\u001b[36m(train_model_tune pid=14481)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:10:48] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=14481)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=14481)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00030 completed after 1 iterations at 2025-06-08 14:10:48. Total running time: 38s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00030 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.23956 |\n","| time_total_s                                  1.23956 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64457 |\n","| f1                                            0.53515 |\n","| precision                                     0.54527 |\n","| recall                                        0.55167 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00032 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00032 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        1 |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00031 completed after 1 iterations at 2025-06-08 14:10:52. Total running time: 42s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00031 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               4.0337 |\n","| time_total_s                                   4.0337 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.52884 |\n","| precision                                      0.5242 |\n","| recall                                        0.55261 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00033 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00033 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          3 |\n","| n_estimators                                      75 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00033 completed after 1 iterations at 2025-06-08 14:10:56. Total running time: 46s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00033 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.47244 |\n","| time_total_s                                  2.47244 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64401 |\n","| f1                                            0.55985 |\n","| precision                                     0.56586 |\n","| recall                                        0.56653 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00034 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00034 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            3 |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=14780)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:10:57] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=14780)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=14780)\u001b[0m \n","\u001b[36m(train_model_tune pid=14780)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00034 completed after 1 iterations at 2025-06-08 14:11:01. Total running time: 51s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00034 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.62458 |\n","| time_total_s                                  3.62458 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.52884 |\n","| precision                                      0.5242 |\n","| recall                                        0.55261 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00035 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00035 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        3 |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00036 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00036 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          5 |\n","| n_estimators                                      75 |\n","+------------------------------------------------------+\n","\n","Trial status: 29 TERMINATED | 8 RUNNING | 53 PENDING\n","Current time: 2025-06-08 14:11:10. Total running time: 1min 0s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00018 with f1=0.5624438066183667 and params={'n_estimators': 50, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00017   RUNNING                  50             1   dart                                                                                   |\n","| train_model_tune_496cf_00020   RUNNING                  50             3   dart                                                                                   |\n","| train_model_tune_496cf_00023   RUNNING                  50             5   dart                                                                                   |\n","| train_model_tune_496cf_00026   RUNNING                  50            10   dart                                                                                   |\n","| train_model_tune_496cf_00029   RUNNING                  50                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00037   PENDING                  75             5   gblinear                                                                               |\n","| train_model_tune_496cf_00038   PENDING                  75             5   dart                                                                                   |\n","| train_model_tune_496cf_00039   PENDING                  75            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00040   PENDING                  75            10   gblinear                                                                               |\n","| train_model_tune_496cf_00041   PENDING                  75            10   dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 24 more TERMINATED, 48 more PENDING\n","\n","Trial train_model_tune_496cf_00036 completed after 1 iterations at 2025-06-08 14:11:11. Total running time: 1min 1s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00036 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               4.9725 |\n","| time_total_s                                   4.9725 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64011 |\n","| f1                                            0.55385 |\n","| precision                                      0.5569 |\n","| recall                                        0.56041 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00037 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00037 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            5 |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=15116)\u001b[0m \n","\u001b[36m(train_model_tune pid=15116)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:11:16] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=15116)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=15116)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00037 completed after 1 iterations at 2025-06-08 14:11:20. Total running time: 1min 10s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00037 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.66797 |\n","| time_total_s                                  3.66797 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.52884 |\n","| precision                                      0.5242 |\n","| recall                                        0.55261 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00038 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00038 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        5 |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial status: 31 TERMINATED | 8 RUNNING | 51 PENDING\n","Current time: 2025-06-08 14:11:40. Total running time: 1min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00018 with f1=0.5624438066183667 and params={'n_estimators': 50, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00017   RUNNING                  50             1   dart                                                                                   |\n","| train_model_tune_496cf_00020   RUNNING                  50             3   dart                                                                                   |\n","| train_model_tune_496cf_00023   RUNNING                  50             5   dart                                                                                   |\n","| train_model_tune_496cf_00026   RUNNING                  50            10   dart                                                                                   |\n","| train_model_tune_496cf_00029   RUNNING                  50                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00039   PENDING                  75            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00040   PENDING                  75            10   gblinear                                                                               |\n","| train_model_tune_496cf_00041   PENDING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00042   PENDING                  75                 gbtree                                                                                 |\n","| train_model_tune_496cf_00043   PENDING                  75                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 26 more TERMINATED, 46 more PENDING\n","Trial status: 31 TERMINATED | 8 RUNNING | 51 PENDING\n","Current time: 2025-06-08 14:12:10. Total running time: 2min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00018 with f1=0.5624438066183667 and params={'n_estimators': 50, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00017   RUNNING                  50             1   dart                                                                                   |\n","| train_model_tune_496cf_00020   RUNNING                  50             3   dart                                                                                   |\n","| train_model_tune_496cf_00023   RUNNING                  50             5   dart                                                                                   |\n","| train_model_tune_496cf_00026   RUNNING                  50            10   dart                                                                                   |\n","| train_model_tune_496cf_00029   RUNNING                  50                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00039   PENDING                  75            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00040   PENDING                  75            10   gblinear                                                                               |\n","| train_model_tune_496cf_00041   PENDING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00042   PENDING                  75                 gbtree                                                                                 |\n","| train_model_tune_496cf_00043   PENDING                  75                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 26 more TERMINATED, 46 more PENDING\n","\n","Trial train_model_tune_496cf_00017 completed after 1 iterations at 2025-06-08 14:12:23. Total running time: 2min 13s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00017 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              115.654 |\n","| time_total_s                                  115.654 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64513 |\n","| f1                                            0.53061 |\n","| precision                                     0.53411 |\n","| recall                                        0.55094 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00020 completed after 1 iterations at 2025-06-08 14:12:28. Total running time: 2min 18s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00020 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              116.637 |\n","| time_total_s                                  116.637 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64791 |\n","| f1                                            0.56244 |\n","| precision                                     0.57176 |\n","| recall                                        0.56848 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00039 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00039 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                         10 |\n","| n_estimators                                      75 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00023 completed after 1 iterations at 2025-06-08 14:12:32. Total running time: 2min 22s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00023 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               118.37 |\n","| time_total_s                                   118.37 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64903 |\n","| f1                                            0.56123 |\n","| precision                                     0.56424 |\n","| recall                                        0.56755 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00040 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00040 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                           10 |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=15685)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:12:33] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=15685)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=15685)\u001b[0m \n","\u001b[36m(train_model_tune pid=15685)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00040 completed after 1 iterations at 2025-06-08 14:12:37. Total running time: 2min 27s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00040 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               3.7202 |\n","| time_total_s                                   3.7202 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.52884 |\n","| precision                                      0.5242 |\n","| recall                                        0.55261 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00041 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00041 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                       10 |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00039 completed after 1 iterations at 2025-06-08 14:12:38. Total running time: 2min 29s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00039 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              10.1123 |\n","| time_total_s                                  10.1123 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62897 |\n","| f1                                            0.53595 |\n","| precision                                     0.53798 |\n","| recall                                        0.54703 |\n","+-------------------------------------------------------+\n","\n","Trial status: 36 TERMINATED | 6 RUNNING | 48 PENDING\n","Current time: 2025-06-08 14:12:40. Total running time: 2min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00018 with f1=0.5624438066183667 and params={'n_estimators': 50, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00026   RUNNING                  50            10   dart                                                                                   |\n","| train_model_tune_496cf_00029   RUNNING                  50                 dart                                                                                   |\n","| train_model_tune_496cf_00032   RUNNING                  75             1   dart                                                                                   |\n","| train_model_tune_496cf_00035   RUNNING                  75             3   dart                                                                                   |\n","| train_model_tune_496cf_00038   RUNNING                  75             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00042   PENDING                  75                 gbtree                                                                                 |\n","| train_model_tune_496cf_00043   PENDING                  75                 gblinear                                                                               |\n","| train_model_tune_496cf_00044   PENDING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00045   PENDING                 100             1   gbtree                                                                                 |\n","| train_model_tune_496cf_00046   PENDING                 100             1   gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","1 more RUNNING, 31 more TERMINATED, 43 more PENDING\n","\n","Trial train_model_tune_496cf_00026 completed after 1 iterations at 2025-06-08 14:12:42. Total running time: 2min 33s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00026 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              124.924 |\n","| time_total_s                                  124.924 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63008 |\n","| f1                                            0.53945 |\n","| precision                                     0.54164 |\n","| recall                                        0.54866 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00042 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00042 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                            |\n","| n_estimators                                      75 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00043 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00043 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                              |\n","| n_estimators                                        75 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00029 completed after 1 iterations at 2025-06-08 14:12:45. Total running time: 2min 35s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00029 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              121.661 |\n","| time_total_s                                  121.661 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64345 |\n","| f1                                            0.55017 |\n","| precision                                     0.55042 |\n","| recall                                        0.55916 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00043 completed after 1 iterations at 2025-06-08 14:12:47. Total running time: 2min 37s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00043 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.77348 |\n","| time_total_s                                  3.77348 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.52884 |\n","| precision                                      0.5242 |\n","| recall                                        0.55261 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00042 completed after 1 iterations at 2025-06-08 14:12:48. Total running time: 2min 39s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00042 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              5.73945 |\n","| time_total_s                                  5.73945 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6351 |\n","| f1                                            0.54665 |\n","| precision                                     0.54884 |\n","| recall                                        0.55497 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00044 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00044 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                          |\n","| n_estimators                                    75 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00045 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00045 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          1 |\n","| n_estimators                                     100 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00045 completed after 1 iterations at 2025-06-08 14:12:51. Total running time: 2min 41s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00045 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1.47076 |\n","| time_total_s                                  1.47076 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64513 |\n","| f1                                            0.54244 |\n","| precision                                     0.55999 |\n","| recall                                        0.55534 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00046 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00046 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            1 |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=16196)\u001b[0m \n","\u001b[36m(train_model_tune pid=16196)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:12:52] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=16196)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=16196)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00047 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00047 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        1 |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00048 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00048 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          3 |\n","| n_estimators                                     100 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00046 completed after 1 iterations at 2025-06-08 14:12:57. Total running time: 2min 47s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00046 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.94884 |\n","| time_total_s                                  4.94884 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64624 |\n","| f1                                             0.5357 |\n","| precision                                     0.53515 |\n","| recall                                        0.55717 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00048 completed after 1 iterations at 2025-06-08 14:12:59. Total running time: 2min 50s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00048 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               3.2051 |\n","| time_total_s                                   3.2051 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64401 |\n","| f1                                            0.56339 |\n","| precision                                     0.56936 |\n","| recall                                        0.56869 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00049 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00049 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            3 |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=16457)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:13:03] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=16457)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=16457)\u001b[0m \n","\u001b[36m(train_model_tune pid=16457)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00050 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00050 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        3 |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00049 completed after 1 iterations at 2025-06-08 14:13:07. Total running time: 2min 57s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00049 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.71345 |\n","| time_total_s                                  4.71345 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64624 |\n","| f1                                             0.5357 |\n","| precision                                     0.53515 |\n","| recall                                        0.55717 |\n","+-------------------------------------------------------+\n","\n","Trial status: 44 TERMINATED | 7 RUNNING | 39 PENDING\n","Current time: 2025-06-08 14:13:10. Total running time: 3min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00032   RUNNING                  75             1   dart                                                                                   |\n","| train_model_tune_496cf_00035   RUNNING                  75             3   dart                                                                                   |\n","| train_model_tune_496cf_00038   RUNNING                  75             5   dart                                                                                   |\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00051   PENDING                 100             5   gbtree                                                                                 |\n","| train_model_tune_496cf_00052   PENDING                 100             5   gblinear                                                                               |\n","| train_model_tune_496cf_00053   PENDING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00054   PENDING                 100            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00055   PENDING                 100            10   gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 39 more TERMINATED, 34 more PENDING\n","\n","Trial train_model_tune_496cf_00051 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00051 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          5 |\n","| n_estimators                                     100 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00051 completed after 1 iterations at 2025-06-08 14:13:18. Total running time: 3min 8s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00051 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              5.95472 |\n","| time_total_s                                  5.95472 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63677 |\n","| f1                                            0.54653 |\n","| precision                                     0.54906 |\n","| recall                                        0.55456 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00052 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00052 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            5 |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=16762)\u001b[0m \n","\u001b[36m(train_model_tune pid=16762)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:13:23] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=16762)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=16762)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00052 completed after 1 iterations at 2025-06-08 14:13:28. Total running time: 3min 18s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00052 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               4.6695 |\n","| time_total_s                                   4.6695 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64624 |\n","| f1                                             0.5357 |\n","| precision                                     0.53515 |\n","| recall                                        0.55717 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00053 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00053 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        5 |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial status: 46 TERMINATED | 8 RUNNING | 36 PENDING\n","Current time: 2025-06-08 14:13:40. Total running time: 3min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00032   RUNNING                  75             1   dart                                                                                   |\n","| train_model_tune_496cf_00035   RUNNING                  75             3   dart                                                                                   |\n","| train_model_tune_496cf_00038   RUNNING                  75             5   dart                                                                                   |\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00054   PENDING                 100            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00055   PENDING                 100            10   gblinear                                                                               |\n","| train_model_tune_496cf_00056   PENDING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00057   PENDING                 100                 gbtree                                                                                 |\n","| train_model_tune_496cf_00058   PENDING                 100                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 41 more TERMINATED, 31 more PENDING\n","Trial status: 46 TERMINATED | 8 RUNNING | 36 PENDING\n","Current time: 2025-06-08 14:14:11. Total running time: 4min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00032   RUNNING                  75             1   dart                                                                                   |\n","| train_model_tune_496cf_00035   RUNNING                  75             3   dart                                                                                   |\n","| train_model_tune_496cf_00038   RUNNING                  75             5   dart                                                                                   |\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00054   PENDING                 100            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00055   PENDING                 100            10   gblinear                                                                               |\n","| train_model_tune_496cf_00056   PENDING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00057   PENDING                 100                 gbtree                                                                                 |\n","| train_model_tune_496cf_00058   PENDING                 100                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 41 more TERMINATED, 31 more PENDING\n","Trial status: 46 TERMINATED | 8 RUNNING | 36 PENDING\n","Current time: 2025-06-08 14:14:41. Total running time: 4min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00032   RUNNING                  75             1   dart                                                                                   |\n","| train_model_tune_496cf_00035   RUNNING                  75             3   dart                                                                                   |\n","| train_model_tune_496cf_00038   RUNNING                  75             5   dart                                                                                   |\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00054   PENDING                 100            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00055   PENDING                 100            10   gblinear                                                                               |\n","| train_model_tune_496cf_00056   PENDING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00057   PENDING                 100                 gbtree                                                                                 |\n","| train_model_tune_496cf_00058   PENDING                 100                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 41 more TERMINATED, 31 more PENDING\n","Trial status: 46 TERMINATED | 8 RUNNING | 36 PENDING\n","Current time: 2025-06-08 14:15:11. Total running time: 5min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00032   RUNNING                  75             1   dart                                                                                   |\n","| train_model_tune_496cf_00035   RUNNING                  75             3   dart                                                                                   |\n","| train_model_tune_496cf_00038   RUNNING                  75             5   dart                                                                                   |\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00054   PENDING                 100            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00055   PENDING                 100            10   gblinear                                                                               |\n","| train_model_tune_496cf_00056   PENDING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00057   PENDING                 100                 gbtree                                                                                 |\n","| train_model_tune_496cf_00058   PENDING                 100                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 41 more TERMINATED, 31 more PENDING\n","\n","Trial train_model_tune_496cf_00032 completed after 1 iterations at 2025-06-08 14:15:12. Total running time: 5min 2s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00032 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               261.05 |\n","| time_total_s                                   261.05 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64457 |\n","| f1                                            0.53515 |\n","| precision                                     0.54527 |\n","| recall                                        0.55167 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00054 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00054 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                         10 |\n","| n_estimators                                     100 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00035 completed after 1 iterations at 2025-06-08 14:15:21. Total running time: 5min 11s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00035 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               259.91 |\n","| time_total_s                                   259.91 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64401 |\n","| f1                                            0.55985 |\n","| precision                                     0.56586 |\n","| recall                                        0.56653 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00055 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00055 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                           10 |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=17524)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:15:26] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=17524)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=17524)\u001b[0m \n","\u001b[36m(train_model_tune pid=17524)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00054 completed after 1 iterations at 2025-06-08 14:15:30. Total running time: 5min 20s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00054 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               12.489 |\n","| time_total_s                                   12.489 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63175 |\n","| f1                                            0.53906 |\n","| precision                                     0.54254 |\n","| recall                                        0.54864 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00055 completed after 1 iterations at 2025-06-08 14:15:31. Total running time: 5min 21s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00055 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               4.7372 |\n","| time_total_s                                   4.7372 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64624 |\n","| f1                                             0.5357 |\n","| precision                                     0.53515 |\n","| recall                                        0.55717 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00056 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00056 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                       10 |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00057 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00057 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                            |\n","| n_estimators                                     100 |\n","+------------------------------------------------------+\n","\n","Trial status: 50 TERMINATED | 8 RUNNING | 32 PENDING\n","Current time: 2025-06-08 14:15:41. Total running time: 5min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00038   RUNNING                  75             5   dart                                                                                   |\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00058   PENDING                 100                 gblinear                                                                               |\n","| train_model_tune_496cf_00059   PENDING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00060   PENDING                 150             1   gbtree                                                                                 |\n","| train_model_tune_496cf_00061   PENDING                 150             1   gblinear                                                                               |\n","| train_model_tune_496cf_00062   PENDING                 150             1   dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 45 more TERMINATED, 27 more PENDING\n","\n","Trial train_model_tune_496cf_00057 completed after 1 iterations at 2025-06-08 14:15:44. Total running time: 5min 35s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00057 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.87554 |\n","| time_total_s                                  7.87554 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63844 |\n","| f1                                            0.55169 |\n","| precision                                     0.55499 |\n","| recall                                        0.56013 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00038 completed after 1 iterations at 2025-06-08 14:15:48. Total running time: 5min 38s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00038 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              263.013 |\n","| time_total_s                                  263.013 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64011 |\n","| f1                                            0.55385 |\n","| precision                                      0.5569 |\n","| recall                                        0.56041 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00058 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00058 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                              |\n","| n_estimators                                       100 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00059 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00059 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                          |\n","| n_estimators                                   100 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00058 completed after 1 iterations at 2025-06-08 14:15:54. Total running time: 5min 45s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00058 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              4.97719 |\n","| time_total_s                                  4.97719 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64624 |\n","| f1                                             0.5357 |\n","| precision                                     0.53515 |\n","| recall                                        0.55717 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00060 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00060 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          1 |\n","| n_estimators                                     150 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00060 completed after 1 iterations at 2025-06-08 14:16:01. Total running time: 5min 52s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00060 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.08195 |\n","| time_total_s                                  2.08195 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64568 |\n","| f1                                            0.54691 |\n","| precision                                     0.56064 |\n","| recall                                        0.55961 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00061 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00061 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            1 |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=18168)\u001b[0m \n","\u001b[36m(train_model_tune pid=18168)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:16:07] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=18168)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=18168)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 54 TERMINATED | 8 RUNNING | 28 PENDING\n","Current time: 2025-06-08 14:16:11. Total running time: 6min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00062   PENDING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00063   PENDING                 150             3   gbtree                                                                                 |\n","| train_model_tune_496cf_00064   PENDING                 150             3   gblinear                                                                               |\n","| train_model_tune_496cf_00065   PENDING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00066   PENDING                 150             5   gbtree                                                                                 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 49 more TERMINATED, 23 more PENDING\n","\n","Trial train_model_tune_496cf_00061 completed after 1 iterations at 2025-06-08 14:16:14. Total running time: 6min 5s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00061 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.38779 |\n","| time_total_s                                  7.38779 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64903 |\n","| f1                                            0.53754 |\n","| precision                                     0.53697 |\n","| recall                                        0.55826 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00062 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00062 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        1 |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial status: 55 TERMINATED | 8 RUNNING | 27 PENDING\n","Current time: 2025-06-08 14:16:41. Total running time: 6min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00063   PENDING                 150             3   gbtree                                                                                 |\n","| train_model_tune_496cf_00064   PENDING                 150             3   gblinear                                                                               |\n","| train_model_tune_496cf_00065   PENDING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00066   PENDING                 150             5   gbtree                                                                                 |\n","| train_model_tune_496cf_00067   PENDING                 150             5   gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 50 more TERMINATED, 22 more PENDING\n","Trial status: 55 TERMINATED | 8 RUNNING | 27 PENDING\n","Current time: 2025-06-08 14:17:11. Total running time: 7min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00041   RUNNING                  75            10   dart                                                                                   |\n","| train_model_tune_496cf_00044   RUNNING                  75                 dart                                                                                   |\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00063   PENDING                 150             3   gbtree                                                                                 |\n","| train_model_tune_496cf_00064   PENDING                 150             3   gblinear                                                                               |\n","| train_model_tune_496cf_00065   PENDING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00066   PENDING                 150             5   gbtree                                                                                 |\n","| train_model_tune_496cf_00067   PENDING                 150             5   gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 50 more TERMINATED, 22 more PENDING\n","\n","Trial train_model_tune_496cf_00041 completed after 1 iterations at 2025-06-08 14:17:11. Total running time: 7min 1s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00041 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              273.792 |\n","| time_total_s                                  273.792 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62897 |\n","| f1                                            0.53595 |\n","| precision                                     0.53798 |\n","| recall                                        0.54703 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00063 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00063 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          3 |\n","| n_estimators                                     150 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00044 completed after 1 iterations at 2025-06-08 14:17:19. Total running time: 7min 9s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00044 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              270.231 |\n","| time_total_s                                  270.231 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6351 |\n","| f1                                            0.54665 |\n","| precision                                     0.54884 |\n","| recall                                        0.55497 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00063 completed after 1 iterations at 2025-06-08 14:17:20. Total running time: 7min 10s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00063 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              3.97579 |\n","| time_total_s                                  3.97579 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64178 |\n","| f1                                            0.55909 |\n","| precision                                     0.56408 |\n","| recall                                        0.56432 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00064 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00064 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            3 |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=18741)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:17:24] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=18741)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=18741)\u001b[0m \n","\u001b[36m(train_model_tune pid=18741)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00065 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00065 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        3 |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00064 completed after 1 iterations at 2025-06-08 14:17:31. Total running time: 7min 22s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00064 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.06563 |\n","| time_total_s                                  7.06563 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64903 |\n","| f1                                            0.53754 |\n","| precision                                     0.53697 |\n","| recall                                        0.55826 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00066 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00066 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          5 |\n","| n_estimators                                     150 |\n","+------------------------------------------------------+\n","\n","Trial status: 59 TERMINATED | 8 RUNNING | 23 PENDING\n","Current time: 2025-06-08 14:17:41. Total running time: 7min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00067   PENDING                 150             5   gblinear                                                                               |\n","| train_model_tune_496cf_00068   PENDING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00069   PENDING                 150            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00070   PENDING                 150            10   gblinear                                                                               |\n","| train_model_tune_496cf_00071   PENDING                 150            10   dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 54 more TERMINATED, 18 more PENDING\n","\n","Trial train_model_tune_496cf_00066 completed after 1 iterations at 2025-06-08 14:17:44. Total running time: 7min 35s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00066 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              8.24675 |\n","| time_total_s                                  8.24675 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6312 |\n","| f1                                            0.53638 |\n","| precision                                     0.53939 |\n","| recall                                        0.54522 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00067 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00067 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            5 |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=19061)\u001b[0m \n","\u001b[36m(train_model_tune pid=19061)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:17:49] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=19061)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=19061)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00067 completed after 1 iterations at 2025-06-08 14:17:56. Total running time: 7min 46s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00067 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              6.95877 |\n","| time_total_s                                  6.95877 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64903 |\n","| f1                                            0.53754 |\n","| precision                                     0.53697 |\n","| recall                                        0.55826 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00068 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00068 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        5 |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial status: 61 TERMINATED | 8 RUNNING | 21 PENDING\n","Current time: 2025-06-08 14:18:11. Total running time: 8min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00069   PENDING                 150            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00070   PENDING                 150            10   gblinear                                                                               |\n","| train_model_tune_496cf_00071   PENDING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00072   PENDING                 150                 gbtree                                                                                 |\n","| train_model_tune_496cf_00073   PENDING                 150                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 56 more TERMINATED, 16 more PENDING\n","Trial status: 61 TERMINATED | 8 RUNNING | 21 PENDING\n","Current time: 2025-06-08 14:18:41. Total running time: 8min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00069   PENDING                 150            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00070   PENDING                 150            10   gblinear                                                                               |\n","| train_model_tune_496cf_00071   PENDING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00072   PENDING                 150                 gbtree                                                                                 |\n","| train_model_tune_496cf_00073   PENDING                 150                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 56 more TERMINATED, 16 more PENDING\n","Trial status: 61 TERMINATED | 8 RUNNING | 21 PENDING\n","Current time: 2025-06-08 14:19:11. Total running time: 9min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00069   PENDING                 150            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00070   PENDING                 150            10   gblinear                                                                               |\n","| train_model_tune_496cf_00071   PENDING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00072   PENDING                 150                 gbtree                                                                                 |\n","| train_model_tune_496cf_00073   PENDING                 150                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 56 more TERMINATED, 16 more PENDING\n","Trial status: 61 TERMINATED | 8 RUNNING | 21 PENDING\n","Current time: 2025-06-08 14:19:41. Total running time: 9min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00069   PENDING                 150            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00070   PENDING                 150            10   gblinear                                                                               |\n","| train_model_tune_496cf_00071   PENDING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00072   PENDING                 150                 gbtree                                                                                 |\n","| train_model_tune_496cf_00073   PENDING                 150                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 56 more TERMINATED, 16 more PENDING\n","Trial status: 61 TERMINATED | 8 RUNNING | 21 PENDING\n","Current time: 2025-06-08 14:20:11. Total running time: 10min 1s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00047   RUNNING                 100             1   dart                                                                                   |\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00069   PENDING                 150            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00070   PENDING                 150            10   gblinear                                                                               |\n","| train_model_tune_496cf_00071   PENDING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00072   PENDING                 150                 gbtree                                                                                 |\n","| train_model_tune_496cf_00073   PENDING                 150                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 56 more TERMINATED, 16 more PENDING\n","\n","Trial train_model_tune_496cf_00047 completed after 1 iterations at 2025-06-08 14:20:33. Total running time: 10min 24s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00047 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              460.378 |\n","| time_total_s                                  460.378 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64513 |\n","| f1                                            0.54244 |\n","| precision                                     0.55999 |\n","| recall                                        0.55534 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00069 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00069 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                         10 |\n","| n_estimators                                     150 |\n","+------------------------------------------------------+\n","\n","Trial status: 62 TERMINATED | 8 RUNNING | 20 PENDING\n","Current time: 2025-06-08 14:20:41. Total running time: 10min 31s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00050   RUNNING                 100             3   dart                                                                                   |\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00070   PENDING                 150            10   gblinear                                                                               |\n","| train_model_tune_496cf_00071   PENDING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00072   PENDING                 150                 gbtree                                                                                 |\n","| train_model_tune_496cf_00073   PENDING                 150                 gblinear                                                                               |\n","| train_model_tune_496cf_00074   PENDING                 150                 dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 57 more TERMINATED, 15 more PENDING\n","\n","Trial train_model_tune_496cf_00050 completed after 1 iterations at 2025-06-08 14:20:49. Total running time: 10min 39s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00050 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              465.632 |\n","| time_total_s                                  465.632 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64401 |\n","| f1                                            0.56339 |\n","| precision                                     0.56936 |\n","| recall                                        0.56869 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00069 completed after 1 iterations at 2025-06-08 14:20:53. Total running time: 10min 44s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00069 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              14.9721 |\n","| time_total_s                                  14.9721 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6273 |\n","| f1                                            0.53396 |\n","| precision                                     0.53538 |\n","| recall                                        0.54384 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00070 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00070 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                           10 |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=20078)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:20:55] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=20078)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=20078)\u001b[0m \n","\u001b[36m(train_model_tune pid=20078)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00071 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00071 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                       10 |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00070 completed after 1 iterations at 2025-06-08 14:21:01. Total running time: 10min 52s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00070 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              7.01597 |\n","| time_total_s                                  7.01597 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64903 |\n","| f1                                            0.53754 |\n","| precision                                     0.53697 |\n","| recall                                        0.55826 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00072 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00072 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                            |\n","| n_estimators                                     150 |\n","+------------------------------------------------------+\n","\n","Trial status: 65 TERMINATED | 8 RUNNING | 17 PENDING\n","Current time: 2025-06-08 14:21:11. Total running time: 11min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00053   RUNNING                 100             5   dart                                                                                   |\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00073   PENDING                 150                 gblinear                                                                               |\n","| train_model_tune_496cf_00074   PENDING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00075   PENDING                 200             1   gbtree                                                                                 |\n","| train_model_tune_496cf_00076   PENDING                 200             1   gblinear                                                                               |\n","| train_model_tune_496cf_00077   PENDING                 200             1   dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 60 more TERMINATED, 12 more PENDING\n","\n","Trial train_model_tune_496cf_00072 completed after 1 iterations at 2025-06-08 14:21:17. Total running time: 11min 7s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00072 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              10.3884 |\n","| time_total_s                                  10.3884 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64178 |\n","| f1                                            0.55177 |\n","| precision                                     0.55449 |\n","| recall                                        0.56109 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00053 completed after 1 iterations at 2025-06-08 14:21:21. Total running time: 11min 11s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00053 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              467.907 |\n","| time_total_s                                  467.907 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63677 |\n","| f1                                            0.54653 |\n","| precision                                     0.54906 |\n","| recall                                        0.55456 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00073 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00073 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                              |\n","| n_estimators                                       150 |\n","+--------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00074 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00074 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                          |\n","| n_estimators                                   150 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00073 completed after 1 iterations at 2025-06-08 14:21:30. Total running time: 11min 20s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00073 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               7.8294 |\n","| time_total_s                                   7.8294 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64903 |\n","| f1                                            0.53754 |\n","| precision                                     0.53697 |\n","| recall                                        0.55826 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00075 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00075 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          1 |\n","| n_estimators                                     200 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00075 completed after 1 iterations at 2025-06-08 14:21:38. Total running time: 11min 28s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00075 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              2.60958 |\n","| time_total_s                                  2.60958 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6468 |\n","| f1                                            0.54543 |\n","| precision                                      0.5544 |\n","| recall                                        0.55927 |\n","+-------------------------------------------------------+\n","\n","Trial status: 69 TERMINATED | 7 RUNNING | 14 PENDING\n","Current time: 2025-06-08 14:21:41. Total running time: 11min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00076   PENDING                 200             1   gblinear                                                                               |\n","| train_model_tune_496cf_00077   PENDING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00078   PENDING                 200             3   gbtree                                                                                 |\n","| train_model_tune_496cf_00079   PENDING                 200             3   gblinear                                                                               |\n","| train_model_tune_496cf_00080   PENDING                 200             3   dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 64 more TERMINATED, 9 more PENDING\n","\n","Trial train_model_tune_496cf_00076 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00076 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            1 |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=20793)\u001b[0m \n","\u001b[36m(train_model_tune pid=20793)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:21:44] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=20793)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=20793)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00076 completed after 1 iterations at 2025-06-08 14:21:53. Total running time: 11min 43s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00076 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              9.53478 |\n","| time_total_s                                  9.53478 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.65237 |\n","| f1                                            0.54009 |\n","| precision                                     0.54266 |\n","| recall                                        0.56066 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00077 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00077 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        1 |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial status: 70 TERMINATED | 8 RUNNING | 12 PENDING\n","Current time: 2025-06-08 14:22:11. Total running time: 12min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00078   PENDING                 200             3   gbtree                                                                                 |\n","| train_model_tune_496cf_00079   PENDING                 200             3   gblinear                                                                               |\n","| train_model_tune_496cf_00080   PENDING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00081   PENDING                 200             5   gbtree                                                                                 |\n","| train_model_tune_496cf_00082   PENDING                 200             5   gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 65 more TERMINATED, 7 more PENDING\n","Trial status: 70 TERMINATED | 8 RUNNING | 12 PENDING\n","Current time: 2025-06-08 14:22:41. Total running time: 12min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00078   PENDING                 200             3   gbtree                                                                                 |\n","| train_model_tune_496cf_00079   PENDING                 200             3   gblinear                                                                               |\n","| train_model_tune_496cf_00080   PENDING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00081   PENDING                 200             5   gbtree                                                                                 |\n","| train_model_tune_496cf_00082   PENDING                 200             5   gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 65 more TERMINATED, 7 more PENDING\n","Trial status: 70 TERMINATED | 8 RUNNING | 12 PENDING\n","Current time: 2025-06-08 14:23:11. Total running time: 13min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00056   RUNNING                 100            10   dart                                                                                   |\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00078   PENDING                 200             3   gbtree                                                                                 |\n","| train_model_tune_496cf_00079   PENDING                 200             3   gblinear                                                                               |\n","| train_model_tune_496cf_00080   PENDING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00081   PENDING                 200             5   gbtree                                                                                 |\n","| train_model_tune_496cf_00082   PENDING                 200             5   gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 65 more TERMINATED, 7 more PENDING\n","\n","Trial train_model_tune_496cf_00056 completed after 1 iterations at 2025-06-08 14:23:32. Total running time: 13min 22s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00056 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              476.999 |\n","| time_total_s                                  476.999 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63175 |\n","| f1                                            0.53906 |\n","| precision                                     0.54254 |\n","| recall                                        0.54864 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00078 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00078 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          3 |\n","| n_estimators                                     200 |\n","+------------------------------------------------------+\n","\n","Trial status: 71 TERMINATED | 8 RUNNING | 11 PENDING\n","Current time: 2025-06-08 14:23:42. Total running time: 13min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00059   RUNNING                 100                 dart                                                                                   |\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00079   PENDING                 200             3   gblinear                                                                               |\n","| train_model_tune_496cf_00080   PENDING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00081   PENDING                 200             5   gbtree                                                                                 |\n","| train_model_tune_496cf_00082   PENDING                 200             5   gblinear                                                                               |\n","| train_model_tune_496cf_00083   PENDING                 200             5   dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 66 more TERMINATED, 6 more PENDING\n","\n","Trial train_model_tune_496cf_00078 completed after 1 iterations at 2025-06-08 14:23:42. Total running time: 13min 33s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00078 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              5.13474 |\n","| time_total_s                                  5.13474 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.55616 |\n","| precision                                      0.5595 |\n","| recall                                        0.56217 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00079 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00079 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            3 |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=21553)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:23:48] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=21553)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=21553)\u001b[0m \n","\u001b[36m(train_model_tune pid=21553)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00059 completed after 1 iterations at 2025-06-08 14:23:48. Total running time: 13min 38s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00059 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              475.005 |\n","| time_total_s                                  475.005 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63844 |\n","| f1                                            0.55169 |\n","| precision                                     0.55499 |\n","| recall                                        0.56013 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00080 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00080 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        3 |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00079 completed after 1 iterations at 2025-06-08 14:23:57. Total running time: 13min 48s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00079 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              9.48534 |\n","| time_total_s                                  9.48534 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.65237 |\n","| f1                                            0.54009 |\n","| precision                                     0.54266 |\n","| recall                                        0.56066 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00081 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00081 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                          5 |\n","| n_estimators                                     200 |\n","+------------------------------------------------------+\n","\n","Trial status: 74 TERMINATED | 8 RUNNING | 8 PENDING\n","Current time: 2025-06-08 14:24:12. Total running time: 14min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00082   PENDING                 200             5   gblinear                                                                               |\n","| train_model_tune_496cf_00083   PENDING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 69 more TERMINATED, 3 more PENDING\n","\n","Trial train_model_tune_496cf_00081 completed after 1 iterations at 2025-06-08 14:24:13. Total running time: 14min 3s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00081 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              10.3768 |\n","| time_total_s                                  10.3768 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63175 |\n","| f1                                            0.54274 |\n","| precision                                     0.54497 |\n","| recall                                        0.55033 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00082 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00082 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                            5 |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=21938)\u001b[0m \n","\u001b[36m(train_model_tune pid=21938)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:24:19] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=21938)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=21938)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00082 completed after 1 iterations at 2025-06-08 14:24:28. Total running time: 14min 18s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00082 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              9.49911 |\n","| time_total_s                                  9.49911 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.65237 |\n","| f1                                            0.54009 |\n","| precision                                     0.54266 |\n","| recall                                        0.56066 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00083 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00083 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                        5 |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:24:42. Total running time: 14min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:25:12. Total running time: 15min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:25:42. Total running time: 15min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:26:12. Total running time: 16min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:26:42. Total running time: 16min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:27:12. Total running time: 17min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:27:42. Total running time: 17min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:28:12. Total running time: 18min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:28:42. Total running time: 18min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:29:12. Total running time: 19min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:29:42. Total running time: 19min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:30:12. Total running time: 20min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:30:42. Total running time: 20min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:31:12. Total running time: 21min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:31:42. Total running time: 21min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:32:12. Total running time: 22min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:32:42. Total running time: 22min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","Trial status: 76 TERMINATED | 8 RUNNING | 6 PENDING\n","Current time: 2025-06-08 14:33:12. Total running time: 23min 2s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00062   RUNNING                 150             1   dart                                                                                   |\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00084   PENDING                 200            10   gbtree                                                                                 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 71 more TERMINATED, 1 more PENDING\n","\n","Trial train_model_tune_496cf_00062 completed after 1 iterations at 2025-06-08 14:33:17. Total running time: 23min 7s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00062 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               1016.9 |\n","| time_total_s                                   1016.9 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64568 |\n","| f1                                            0.54691 |\n","| precision                                     0.56064 |\n","| recall                                        0.55961 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00084 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00084 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                         10 |\n","| n_estimators                                     200 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00084 completed after 1 iterations at 2025-06-08 14:33:40. Total running time: 23min 30s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00084 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              17.2185 |\n","| time_total_s                                  17.2185 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62618 |\n","| f1                                            0.53141 |\n","| precision                                      0.5316 |\n","| recall                                        0.54219 |\n","+-------------------------------------------------------+\n","\n","Trial status: 78 TERMINATED | 7 RUNNING | 5 PENDING\n","Current time: 2025-06-08 14:33:42. Total running time: 23min 32s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00085   PENDING                 200            10   gblinear                                                                               |\n","| train_model_tune_496cf_00086   PENDING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","| train_model_tune_496cf_00089   PENDING                 200                 dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 73 more TERMINATED\n","\n","Trial train_model_tune_496cf_00085 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00085 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                           10 |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(train_model_tune pid=24516)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:33:45] WARNING: /workspace/src/learner.cc:740: \n","\u001b[36m(train_model_tune pid=24516)\u001b[0m Parameters: { \"max_depth\" } are not used.\n","\u001b[36m(train_model_tune pid=24516)\u001b[0m \n","\u001b[36m(train_model_tune pid=24516)\u001b[0m   warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00085 completed after 1 iterations at 2025-06-08 14:33:55. Total running time: 23min 46s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00085 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              9.84489 |\n","| time_total_s                                  9.84489 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.65237 |\n","| f1                                            0.54009 |\n","| precision                                     0.54266 |\n","| recall                                        0.56066 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00086 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00086 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                       10 |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial status: 79 TERMINATED | 8 RUNNING | 3 PENDING\n","Current time: 2025-06-08 14:34:12. Total running time: 24min 3s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","| train_model_tune_496cf_00089   PENDING                 200                 dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 74 more TERMINATED\n","Trial status: 79 TERMINATED | 8 RUNNING | 3 PENDING\n","Current time: 2025-06-08 14:34:42. Total running time: 24min 33s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00065   RUNNING                 150             3   dart                                                                                   |\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00087   PENDING                 200                 gbtree                                                                                 |\n","| train_model_tune_496cf_00088   PENDING                 200                 gblinear                                                                               |\n","| train_model_tune_496cf_00089   PENDING                 200                 dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 74 more TERMINATED\n","\n","Trial train_model_tune_496cf_00065 completed after 1 iterations at 2025-06-08 14:34:45. Total running time: 24min 35s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00065 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1039.14 |\n","| time_total_s                                  1039.14 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64178 |\n","| f1                                            0.55909 |\n","| precision                                     0.56408 |\n","| recall                                        0.56432 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00087 started with configuration:\n","+------------------------------------------------------+\n","| Trial train_model_tune_496cf_00087 config            |\n","+------------------------------------------------------+\n","| booster                                       gbtree |\n","| max_depth                                            |\n","| n_estimators                                     200 |\n","+------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00087 completed after 1 iterations at 2025-06-08 14:35:02. Total running time: 24min 52s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00087 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              12.2823 |\n","| time_total_s                                  12.2823 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64067 |\n","| f1                                            0.55251 |\n","| precision                                     0.55377 |\n","| recall                                        0.56177 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00088 started with configuration:\n","+--------------------------------------------------------+\n","| Trial train_model_tune_496cf_00088 config              |\n","+--------------------------------------------------------+\n","| booster                                       gblinear |\n","| max_depth                                              |\n","| n_estimators                                       200 |\n","+--------------------------------------------------------+\n","\n","Trial status: 81 TERMINATED | 8 RUNNING | 1 PENDING\n","Current time: 2025-06-08 14:35:12. Total running time: 25min 3s\n","Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00068   RUNNING                 150             5   dart                                                                                   |\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00089   PENDING                 200                 dart                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","3 more RUNNING, 76 more TERMINATED\n","\n","Trial train_model_tune_496cf_00088 completed after 1 iterations at 2025-06-08 14:35:16. Total running time: 25min 6s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00088 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              9.33419 |\n","| time_total_s                                  9.33419 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.65237 |\n","| f1                                            0.54009 |\n","| precision                                     0.54266 |\n","| recall                                        0.56066 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00089 started with configuration:\n","+----------------------------------------------------+\n","| Trial train_model_tune_496cf_00089 config          |\n","+----------------------------------------------------+\n","| booster                                       dart |\n","| max_depth                                          |\n","| n_estimators                                   200 |\n","+----------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00068 completed after 1 iterations at 2025-06-08 14:35:37. Total running time: 25min 27s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00068 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1055.42 |\n","| time_total_s                                  1055.42 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6312 |\n","| f1                                            0.53638 |\n","| precision                                     0.53939 |\n","| recall                                        0.54522 |\n","+-------------------------------------------------------+\n","\n","Trial status: 83 TERMINATED | 7 RUNNING\n","Current time: 2025-06-08 14:35:42. Total running time: 25min 33s\n","Logical resource usage: 7.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 78 more TERMINATED\n","Trial status: 83 TERMINATED | 7 RUNNING\n","Current time: 2025-06-08 14:36:13. Total running time: 26min 3s\n","Logical resource usage: 7.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 78 more TERMINATED\n","Trial status: 83 TERMINATED | 7 RUNNING\n","Current time: 2025-06-08 14:36:43. Total running time: 26min 33s\n","Logical resource usage: 7.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 78 more TERMINATED\n","Trial status: 83 TERMINATED | 7 RUNNING\n","Current time: 2025-06-08 14:37:13. Total running time: 27min 3s\n","Logical resource usage: 7.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 78 more TERMINATED\n","Trial status: 83 TERMINATED | 7 RUNNING\n","Current time: 2025-06-08 14:37:43. Total running time: 27min 33s\n","Logical resource usage: 7.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 78 more TERMINATED\n","Trial status: 83 TERMINATED | 7 RUNNING\n","Current time: 2025-06-08 14:38:13. Total running time: 28min 3s\n","Logical resource usage: 7.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00071   RUNNING                 150            10   dart                                                                                   |\n","| train_model_tune_496cf_00074   RUNNING                 150                 dart                                                                                   |\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","2 more RUNNING, 78 more TERMINATED\n","\n","Trial train_model_tune_496cf_00071 completed after 1 iterations at 2025-06-08 14:38:23. Total running time: 28min 13s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00071 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1044.57 |\n","| time_total_s                                  1044.57 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6273 |\n","| f1                                            0.53396 |\n","| precision                                     0.53538 |\n","| recall                                        0.54384 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00074 completed after 1 iterations at 2025-06-08 14:38:38. Total running time: 28min 28s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00074 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1031.42 |\n","| time_total_s                                  1031.42 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64178 |\n","| f1                                            0.55177 |\n","| precision                                     0.55449 |\n","| recall                                        0.56109 |\n","+-------------------------------------------------------+\n","\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:38:43. Total running time: 28min 33s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:39:13. Total running time: 29min 3s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:39:43. Total running time: 29min 33s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:40:13. Total running time: 30min 3s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:40:43. Total running time: 30min 33s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:41:13. Total running time: 31min 3s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:41:43. Total running time: 31min 34s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:42:13. Total running time: 32min 4s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:42:43. Total running time: 32min 34s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:43:13. Total running time: 33min 4s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:43:44. Total running time: 33min 34s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:44:14. Total running time: 34min 4s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:44:44. Total running time: 34min 34s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:45:14. Total running time: 35min 4s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:45:44. Total running time: 35min 34s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:46:14. Total running time: 36min 4s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:46:44. Total running time: 36min 34s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:47:14. Total running time: 37min 4s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:47:44. Total running time: 37min 34s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:48:14. Total running time: 38min 4s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:48:44. Total running time: 38min 34s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","Trial status: 85 TERMINATED | 5 RUNNING\n","Current time: 2025-06-08 14:49:14. Total running time: 39min 4s\n","Logical resource usage: 5.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00080   RUNNING                 200             3   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","80 more TERMINATED\n","\n","Trial train_model_tune_496cf_00080 completed after 1 iterations at 2025-06-08 14:49:25. Total running time: 39min 15s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00080 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               1531.7 |\n","| time_total_s                                   1531.7 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6429 |\n","| f1                                            0.55616 |\n","| precision                                      0.5595 |\n","| recall                                        0.56217 |\n","+-------------------------------------------------------+\n","\n","Trial status: 86 TERMINATED | 4 RUNNING\n","Current time: 2025-06-08 14:49:44. Total running time: 39min 35s\n","Logical resource usage: 4.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00077   RUNNING                 200             1   dart                                                                                   |\n","| train_model_tune_496cf_00083   RUNNING                 200             5   dart                                                                                   |\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","81 more TERMINATED\n","\n","Trial train_model_tune_496cf_00083 completed after 1 iterations at 2025-06-08 14:49:46. Total running time: 39min 36s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00083 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1512.87 |\n","| time_total_s                                  1512.87 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.63175 |\n","| f1                                            0.54274 |\n","| precision                                     0.54497 |\n","| recall                                        0.55033 |\n","+-------------------------------------------------------+\n","\n","Trial train_model_tune_496cf_00077 completed after 1 iterations at 2025-06-08 14:49:52. Total running time: 39min 42s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00077 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                               1673.7 |\n","| time_total_s                                   1673.7 |\n","| training_iteration                                  1 |\n","| accuracy                                       0.6468 |\n","| f1                                            0.54543 |\n","| precision                                      0.5544 |\n","| recall                                        0.55927 |\n","+-------------------------------------------------------+\n","\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:50:14. Total running time: 40min 5s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:50:44. Total running time: 40min 35s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:51:14. Total running time: 41min 5s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:51:44. Total running time: 41min 35s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:52:14. Total running time: 42min 5s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:52:44. Total running time: 42min 35s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:53:14. Total running time: 43min 5s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:53:44. Total running time: 43min 35s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","Trial status: 88 TERMINATED | 2 RUNNING\n","Current time: 2025-06-08 14:54:15. Total running time: 44min 5s\n","Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00086   RUNNING                 200            10   dart                                                                                   |\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","83 more TERMINATED\n","\n","Trial train_model_tune_496cf_00086 completed after 1 iterations at 2025-06-08 14:54:41. Total running time: 44min 31s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00086 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1240.52 |\n","| time_total_s                                  1240.52 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.62618 |\n","| f1                                            0.53141 |\n","| precision                                      0.5316 |\n","| recall                                        0.54219 |\n","+-------------------------------------------------------+\n","\n","Trial status: 89 TERMINATED | 1 RUNNING\n","Current time: 2025-06-08 14:54:45. Total running time: 44min 35s\n","Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00089   RUNNING                 200                 dart                                                                                   |\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","84 more TERMINATED\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-08 14:55:10,012\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_model_tune_2025-06-08_14-10-09' in 0.0277s.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial train_model_tune_496cf_00089 completed after 1 iterations at 2025-06-08 14:55:09. Total running time: 45min 0s\n","+-------------------------------------------------------+\n","| Trial train_model_tune_496cf_00089 result             |\n","+-------------------------------------------------------+\n","| checkpoint_dir_name                                   |\n","| time_this_iter_s                              1187.79 |\n","| time_total_s                                  1187.79 |\n","| training_iteration                                  1 |\n","| accuracy                                      0.64067 |\n","| f1                                            0.55251 |\n","| precision                                     0.55377 |\n","| recall                                        0.56177 |\n","+-------------------------------------------------------+\n","\n","Trial status: 90 TERMINATED\n","Current time: 2025-06-08 14:55:10. Total running time: 45min 0s\n","Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n","Current best trial: 496cf_00048 with f1=0.5633897762245342 and params={'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                     status         n_estimators     max_depth   booster       iter     total time (s)     accuracy         f1     precision     recall |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| train_model_tune_496cf_00000   TERMINATED               10             1   gbtree           1           0.439474     0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00001   TERMINATED               10             1   gblinear         1           0.775391     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00002   TERMINATED               10             1   dart             1           4.77278      0.637883   0.516949      0.505874   0.54272  |\n","| train_model_tune_496cf_00003   TERMINATED               10             3   gbtree           1           0.641191     0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00004   TERMINATED               10             3   gblinear         1           0.671603     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00005   TERMINATED               10             3   dart             1           4.7783       0.647911   0.53698       0.555106   0.552729 |\n","| train_model_tune_496cf_00006   TERMINATED               10             5   gbtree           1           1.04683      0.651811   0.561301      0.570857   0.567469 |\n","| train_model_tune_496cf_00007   TERMINATED               10             5   gblinear         1           0.781488     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00008   TERMINATED               10             5   dart             1           5.62786      0.651811   0.561301      0.570857   0.567469 |\n","| train_model_tune_496cf_00009   TERMINATED               10            10   gbtree           1           3.3558       0.631198   0.536482      0.534742   0.547234 |\n","| train_model_tune_496cf_00010   TERMINATED               10            10   gblinear         1           0.731844     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00011   TERMINATED               10            10   dart             1           7.18448      0.631198   0.536482      0.534742   0.547234 |\n","| train_model_tune_496cf_00012   TERMINATED               10                 gbtree           1           1.7004       0.644011   0.548231      0.548512   0.558731 |\n","| train_model_tune_496cf_00013   TERMINATED               10                 gblinear         1           0.768428     0.585515   0.471342      0.457355   0.497788 |\n","| train_model_tune_496cf_00014   TERMINATED               10                 dart             1           4.75219      0.644011   0.548231      0.548512   0.558731 |\n","| train_model_tune_496cf_00015   TERMINATED               50             1   gbtree           1           0.771391     0.645125   0.530611      0.534107   0.550945 |\n","| train_model_tune_496cf_00016   TERMINATED               50             1   gblinear         1           2.6244       0.636212   0.522043      0.519732   0.546513 |\n","| train_model_tune_496cf_00017   TERMINATED               50             1   dart             1         115.654        0.645125   0.530611      0.534107   0.550945 |\n","| train_model_tune_496cf_00018   TERMINATED               50             3   gbtree           1           1.67564      0.647911   0.562444      0.571757   0.568478 |\n","| train_model_tune_496cf_00019   TERMINATED               50             3   gblinear         1           2.66363      0.636212   0.522043      0.519732   0.546513 |\n","| train_model_tune_496cf_00020   TERMINATED               50             3   dart             1         116.637        0.647911   0.562444      0.571757   0.568478 |\n","| train_model_tune_496cf_00021   TERMINATED               50             5   gbtree           1           3.35831      0.649025   0.561226      0.56424    0.567547 |\n","| train_model_tune_496cf_00022   TERMINATED               50             5   gblinear         1           3.09264      0.636212   0.522043      0.519732   0.546513 |\n","| train_model_tune_496cf_00023   TERMINATED               50             5   dart             1         118.37         0.649025   0.561226      0.56424    0.567547 |\n","| train_model_tune_496cf_00024   TERMINATED               50            10   gbtree           1           8.657        0.630084   0.539451      0.541638   0.54866  |\n","| train_model_tune_496cf_00025   TERMINATED               50            10   gblinear         1           2.73748      0.636212   0.522043      0.519732   0.546513 |\n","| train_model_tune_496cf_00026   TERMINATED               50            10   dart             1         124.924        0.630084   0.539451      0.541638   0.54866  |\n","| train_model_tune_496cf_00027   TERMINATED               50                 gbtree           1           4.30226      0.643454   0.550174      0.550418   0.559158 |\n","| train_model_tune_496cf_00028   TERMINATED               50                 gblinear         1           2.63229      0.636212   0.522043      0.519732   0.546513 |\n","| train_model_tune_496cf_00029   TERMINATED               50                 dart             1         121.661        0.643454   0.550174      0.550418   0.559158 |\n","| train_model_tune_496cf_00030   TERMINATED               75             1   gbtree           1           1.23956      0.644568   0.535151      0.545269   0.55167  |\n","| train_model_tune_496cf_00031   TERMINATED               75             1   gblinear         1           4.0337       0.642897   0.528844      0.524197   0.552607 |\n","| train_model_tune_496cf_00032   TERMINATED               75             1   dart             1         261.05         0.644568   0.535151      0.545269   0.55167  |\n","| train_model_tune_496cf_00033   TERMINATED               75             3   gbtree           1           2.47244      0.644011   0.559848      0.565858   0.56653  |\n","| train_model_tune_496cf_00034   TERMINATED               75             3   gblinear         1           3.62458      0.642897   0.528844      0.524197   0.552607 |\n","| train_model_tune_496cf_00035   TERMINATED               75             3   dart             1         259.91         0.644011   0.559848      0.565858   0.56653  |\n","| train_model_tune_496cf_00036   TERMINATED               75             5   gbtree           1           4.9725       0.640111   0.553847      0.556905   0.560408 |\n","| train_model_tune_496cf_00037   TERMINATED               75             5   gblinear         1           3.66797      0.642897   0.528844      0.524197   0.552607 |\n","| train_model_tune_496cf_00038   TERMINATED               75             5   dart             1         263.013        0.640111   0.553847      0.556905   0.560408 |\n","| train_model_tune_496cf_00039   TERMINATED               75            10   gbtree           1          10.1123       0.628969   0.535945      0.537981   0.547033 |\n","| train_model_tune_496cf_00040   TERMINATED               75            10   gblinear         1           3.7202       0.642897   0.528844      0.524197   0.552607 |\n","| train_model_tune_496cf_00041   TERMINATED               75            10   dart             1         273.792        0.628969   0.535945      0.537981   0.547033 |\n","| train_model_tune_496cf_00042   TERMINATED               75                 gbtree           1           5.73945      0.635097   0.546654      0.548838   0.554969 |\n","| train_model_tune_496cf_00043   TERMINATED               75                 gblinear         1           3.77348      0.642897   0.528844      0.524197   0.552607 |\n","| train_model_tune_496cf_00044   TERMINATED               75                 dart             1         270.231        0.635097   0.546654      0.548838   0.554969 |\n","| train_model_tune_496cf_00045   TERMINATED              100             1   gbtree           1           1.47076      0.645125   0.542443      0.559991   0.555341 |\n","| train_model_tune_496cf_00046   TERMINATED              100             1   gblinear         1           4.94884      0.64624    0.535704      0.535149   0.557169 |\n","| train_model_tune_496cf_00047   TERMINATED              100             1   dart             1         460.378        0.645125   0.542443      0.559991   0.555341 |\n","| train_model_tune_496cf_00048   TERMINATED              100             3   gbtree           1           3.2051       0.644011   0.56339       0.569357   0.56869  |\n","| train_model_tune_496cf_00049   TERMINATED              100             3   gblinear         1           4.71345      0.64624    0.535704      0.535149   0.557169 |\n","| train_model_tune_496cf_00050   TERMINATED              100             3   dart             1         465.632        0.644011   0.56339       0.569357   0.56869  |\n","| train_model_tune_496cf_00051   TERMINATED              100             5   gbtree           1           5.95472      0.636769   0.546534      0.549058   0.554555 |\n","| train_model_tune_496cf_00052   TERMINATED              100             5   gblinear         1           4.6695       0.64624    0.535704      0.535149   0.557169 |\n","| train_model_tune_496cf_00053   TERMINATED              100             5   dart             1         467.907        0.636769   0.546534      0.549058   0.554555 |\n","| train_model_tune_496cf_00054   TERMINATED              100            10   gbtree           1          12.489        0.631755   0.539062      0.542539   0.548643 |\n","| train_model_tune_496cf_00055   TERMINATED              100            10   gblinear         1           4.7372       0.64624    0.535704      0.535149   0.557169 |\n","| train_model_tune_496cf_00056   TERMINATED              100            10   dart             1         476.999        0.631755   0.539062      0.542539   0.548643 |\n","| train_model_tune_496cf_00057   TERMINATED              100                 gbtree           1           7.87554      0.63844    0.551693      0.554989   0.560127 |\n","| train_model_tune_496cf_00058   TERMINATED              100                 gblinear         1           4.97719      0.64624    0.535704      0.535149   0.557169 |\n","| train_model_tune_496cf_00059   TERMINATED              100                 dart             1         475.005        0.63844    0.551693      0.554989   0.560127 |\n","| train_model_tune_496cf_00060   TERMINATED              150             1   gbtree           1           2.08195      0.645682   0.546909      0.560636   0.559609 |\n","| train_model_tune_496cf_00061   TERMINATED              150             1   gblinear         1           7.38779      0.649025   0.537543      0.536969   0.558258 |\n","| train_model_tune_496cf_00062   TERMINATED              150             1   dart             1        1016.9          0.645682   0.546909      0.560636   0.559609 |\n","| train_model_tune_496cf_00063   TERMINATED              150             3   gbtree           1           3.97579      0.641783   0.559092      0.564075   0.564315 |\n","| train_model_tune_496cf_00064   TERMINATED              150             3   gblinear         1           7.06563      0.649025   0.537543      0.536969   0.558258 |\n","| train_model_tune_496cf_00065   TERMINATED              150             3   dart             1        1039.14         0.641783   0.559092      0.564075   0.564315 |\n","| train_model_tune_496cf_00066   TERMINATED              150             5   gbtree           1           8.24675      0.631198   0.536384      0.53939    0.54522  |\n","| train_model_tune_496cf_00067   TERMINATED              150             5   gblinear         1           6.95877      0.649025   0.537543      0.536969   0.558258 |\n","| train_model_tune_496cf_00068   TERMINATED              150             5   dart             1        1055.42         0.631198   0.536384      0.53939    0.54522  |\n","| train_model_tune_496cf_00069   TERMINATED              150            10   gbtree           1          14.9721       0.627298   0.533959      0.535378   0.543845 |\n","| train_model_tune_496cf_00070   TERMINATED              150            10   gblinear         1           7.01597      0.649025   0.537543      0.536969   0.558258 |\n","| train_model_tune_496cf_00071   TERMINATED              150            10   dart             1        1044.57         0.627298   0.533959      0.535378   0.543845 |\n","| train_model_tune_496cf_00072   TERMINATED              150                 gbtree           1          10.3884       0.641783   0.551774      0.554491   0.561088 |\n","| train_model_tune_496cf_00073   TERMINATED              150                 gblinear         1           7.8294       0.649025   0.537543      0.536969   0.558258 |\n","| train_model_tune_496cf_00074   TERMINATED              150                 dart             1        1031.42         0.641783   0.551774      0.554491   0.561088 |\n","| train_model_tune_496cf_00075   TERMINATED              200             1   gbtree           1           2.60958      0.646797   0.545433      0.554396   0.559274 |\n","| train_model_tune_496cf_00076   TERMINATED              200             1   gblinear         1           9.53478      0.652368   0.540088      0.542662   0.560659 |\n","| train_model_tune_496cf_00077   TERMINATED              200             1   dart             1        1673.7          0.646797   0.545433      0.554396   0.559274 |\n","| train_model_tune_496cf_00078   TERMINATED              200             3   gbtree           1           5.13474      0.642897   0.556157      0.559497   0.562167 |\n","| train_model_tune_496cf_00079   TERMINATED              200             3   gblinear         1           9.48534      0.652368   0.540088      0.542662   0.560659 |\n","| train_model_tune_496cf_00080   TERMINATED              200             3   dart             1        1531.7          0.642897   0.556157      0.559497   0.562167 |\n","| train_model_tune_496cf_00081   TERMINATED              200             5   gbtree           1          10.3768       0.631755   0.542744      0.544973   0.550332 |\n","| train_model_tune_496cf_00082   TERMINATED              200             5   gblinear         1           9.49911      0.652368   0.540088      0.542662   0.560659 |\n","| train_model_tune_496cf_00083   TERMINATED              200             5   dart             1        1512.87         0.631755   0.542744      0.544973   0.550332 |\n","| train_model_tune_496cf_00084   TERMINATED              200            10   gbtree           1          17.2185       0.626184   0.531412      0.531601   0.542192 |\n","| train_model_tune_496cf_00085   TERMINATED              200            10   gblinear         1           9.84489      0.652368   0.540088      0.542662   0.560659 |\n","| train_model_tune_496cf_00086   TERMINATED              200            10   dart             1        1240.52         0.626184   0.531412      0.531601   0.542192 |\n","| train_model_tune_496cf_00087   TERMINATED              200                 gbtree           1          12.2823       0.640669   0.552511      0.55377    0.56177  |\n","| train_model_tune_496cf_00088   TERMINATED              200                 gblinear         1           9.33419      0.652368   0.540088      0.542662   0.560659 |\n","| train_model_tune_496cf_00089   TERMINATED              200                 dart             1        1187.79         0.640669   0.552511      0.55377    0.56177  |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n","Best params: {'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","accuracy: 0.6440\n","f1: 0.5634\n","precision: 0.5694\n","recall: 0.5687\n","timestamp: 1749391979\n","checkpoint_dir_name: None\n","done: True\n","training_iteration: 1\n","trial_id: 496cf_00048\n","date: 2025-06-08_14-12-59\n","time_this_iter_s: 3.2051\n","time_total_s: 3.2051\n","pid: 16343\n","hostname: 23346c329519\n","node_ip: 172.28.0.12\n","config: {'n_estimators': 100, 'max_depth': 3, 'booster': 'gbtree'}\n","time_since_restore: 3.2051\n","iterations_since_restore: 1\n","experiment_tag: 48_booster=gbtree,max_depth=3,n_estimators=100\n"]}],"id":"gE-IT4-GL6Qt"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f42a7d28","outputId":"f2659736-3848-47ee-d059-71b6cebd35cd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749394513580,"user_tz":-120,"elapsed":16,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'xgboost.sklearn.XGBClassifier'> & 0.6445 ± 0.0000 & 0.5539 ± 0.0000 & 0.5650 ± 0.0000 & 0.5602 ± 0.0000 \\\\\n","[0.9973106384277344, 0.6532695293426514, 0.6704707145690918, 0.7184817790985107, 0.7537915706634521]\n","0.7587 ± 0.1245\n"]}],"source":["run_classic_model(\n","    XGBClassifier,\n","    results.get_best_result().config,\n","    X_train=X_train_bal,\n","    y_train=y_train_bal,\n","    X_val=X_val_bal,\n","    y_val=y_val_bal,\n","    X_test=X_test_bal,\n","    y_test=y_test_bal,\n",")"],"id":"f42a7d28"},{"cell_type":"code","source":["model = train_classic_model(\n","    XGBClassifier,\n","    {\n","        \"n_estimators\": 100,\n","        \"max_depth\": 3,\n","        \"booster\": 'gbtree'\n","    },\n","    X_train=X_train_bal,\n","    y_train=y_train_bal,\n",")\n","\n","y_test_pred = predict_classic_model(model, X_test_bal)\n","cm = confusion_matrix(y_test_bal, y_test_pred)\n","print(cm)\n","disp = ConfusionMatrixDisplay(\n","    confusion_matrix=cm,\n","    display_labels=[\n","        \"<500\", \"500-1000\", \"1000-2000\", \"2000-5000\", \"5000-10000\", \">10000\"\n","    ]\n",")\n","disp.plot(\n","    values_format=\"d\",\n","    xticks_rotation=45,\n","    cmap=\"Blues\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":629},"id":"nPbOGmW7DKq0","executionInfo":{"status":"ok","timestamp":1749499413742,"user_tz":-120,"elapsed":1119,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"6c074f67-2d1e-4823-ef48-b13582ef42ff"},"id":"nPbOGmW7DKq0","execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["[[784  27  96  38  37  18]\n"," [112  18  58  31  28  16]\n"," [100  32 232  96  47  29]\n"," [ 43  11 168 472 234  72]\n"," [ 14   4  10 160 634 178]\n"," [  3   1   2   8 120 866]]\n"]},{"output_type":"execute_result","data":{"text/plain":["<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7e6928af3c10>"]},"metadata":{},"execution_count":50},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["cm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vap92ISCEU1j","executionInfo":{"status":"ok","timestamp":1749495665450,"user_tz":-120,"elapsed":17,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"2d007320-1210-4fa1-c18b-a558c59d3327"},"id":"vap92ISCEU1j","execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[784,  27,  96,  38,  37,  18],\n","       [112,  18,  58,  31,  28,  16],\n","       [100,  32, 232,  96,  47,  29],\n","       [ 43,  11, 168, 472, 234,  72],\n","       [ 14,   4,  10, 160, 634, 178],\n","       [  3,   1,   2,   8, 120, 866]])"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["## Naiva Bayes"],"metadata":{"id":"GADh808BMoi3"},"id":"GADh808BMoi3"},{"cell_type":"code","source":["# tuner = tune.Tuner(\n","#     tune.with_parameters(\n","#         train_model_tune,\n","#         model_cls=GaussianNB,\n","#         X_train=X_train_bal,\n","#         y_train=y_train_bal,\n","#         X_val=X_val_bal,\n","#         y_val=y_val_bal,\n","#     ),\n","#     param_space={\n","#         \"n_estimators\": tune.grid_search([10, 50, 75, 100, 150, 200]),\n","#         \"max_depth\": tune.grid_search([1, 3, 5, 10, None]),\n","#         \"booster\": tune.grid_search(['gbtree', 'gblinear', 'dart'])\n","#     },\n","#     tune_config=tune.TuneConfig(\n","#         num_samples=3,\n","#         metric=\"accuracy\",\n","#         mode=\"max\"\n","#     )\n","# )\n","\n","# results = tuner.fit()\n","# best_metrics = results.get_best_result().metrics\n","# print(f\"Best params: {results.get_best_result().config}\")\n","# for k, v in best_metrics.items():\n","#   if isinstance(v, float):\n","#     print(f\"{k}: {v:.4f}\")\n","#   else:\n","#     print(f\"{k}: {v}\")"],"metadata":{"id":"3bLPITRWMr2x"},"execution_count":null,"outputs":[],"id":"3bLPITRWMr2x"},{"cell_type":"code","source":["run_classic_model(\n","    GaussianNB,\n","    # results.get_best_result().config,\n","    {},\n","    X_train=X_train_bal,\n","    y_train=y_train_bal,\n","    X_val=X_val_bal,\n","    y_val=y_val_bal,\n","    X_test=X_test_bal,\n","    y_test=y_test_bal,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjKb1BWyjuKh","executionInfo":{"status":"ok","timestamp":1749395503067,"user_tz":-120,"elapsed":187,"user":{"displayName":"Michał Skubek","userId":"16987204902500759515"}},"outputId":"b474d890-7f33-4294-8741-251a7cc1c6b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'sklearn.naive_bayes.GaussianNB'> & 0.4478 ± 0.0000 & 0.3575 ± 0.0000 & 0.3563 ± 0.0000 & 0.3757 ± 0.0000 \\\\\n","[0.009872674942016602, 0.007849454879760742, 0.007587432861328125, 0.007434368133544922, 0.007409334182739258]\n","0.0080 ± 0.0009\n"]}],"id":"wjKb1BWyjuKh"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[],"collapsed_sections":["V3Xstv5G2ZfG","5783352d","UvP5lRyZv7TD"],"toc_visible":true,"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":5}